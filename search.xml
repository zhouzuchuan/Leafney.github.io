<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[同一设备下多重SSH Keys管理]]></title>
    <url>%2F2018%2F05%2F14%2Fmultiple-ssh-keys-management-under-the-same-device%2F</url>
    <content type="text"><![CDATA[一般我们在自己的个人电脑上使用git时都会通过SSH的方式来连接代码管理站点如Github等。但有时候我们也会遇到多重SSH的问题。 需求最常见的情况就是一般的公司都会有自己的私有git仓库，比如用gitlab来搭建的git仓库站点。而公司里也会为每位员工设置一个个人专属的公司域名邮箱，这样的情况下就遇到问题了：我们在自己的电脑上已经配置了自己的邮箱账号作为主力的git账户，而在开发公司的项目时，用来提交git操作的时候就要切换为公司分配的邮箱账号了。虽然我们可以在项目目录内使用 git config user.name 和 git config user.email 来为该项目指定单独的git提交账户，但在 git pull 和 git push 时，每次都需要使用 http 的方式输入密码才行，非常的麻烦。 准备那么现在问题就来了，个人使用的git账户和公司分配的git账户应该如何在一台电脑上同时存在并保证都能分别使用SSH的方式来提交代码呢？ 首先，我们指定下面示例使用的git账户： 我的个人git账户: leafney leafney@gmail.com git仓库：github.com我的公司git账户: wuyazi wuyazi@company.com git仓库：111.206.223.205:8080 （公司配置的gitlab对应ip地址）我使用的Bash : iTerm2+zsh 我的需求是，因为我使用的是个人电脑，所以我希望的是在默认情况下，仍然使用我自己的git账户 leafney@gmail.com 作为全局账户来提交项目。对于公司的项目，则使用公司的git账户 wuyazi@company.com 作为局部账户来仅提交公司的项目。 之前在我的mac下已经设置了默认的git账号 leafney@gmail.com 对应的ssh密钥 。如果你还没有设置过SSH，可以参考我之前的文章：Linux下使用SSH密钥连接Github 新增SSH key现在要新增一个工作的账号，以 wuyazi wuyazi@company.com 为示例账户来添加。 查看已添加SSH密钥查看mac下已经添加的我的个人git账号信息: 123~/.ssh➜ lsid_rsa id_rsa.pub known_hosts 查看 id_rsa.pub 内容: 12➜ vim id_rsa.pubssh-ras xxxxxxxxxxxx leafney@gmail.com 新增SSH密钥创建新的 ssh key： 1234// 切换到 .ssh 目录下➜ cd ~/.ssh// 输入工作邮箱来创建新的ssh key,git唯一认证标准是邮箱➜ ssh-keygen -t rsa -C &quot;wuyazi@company.com&quot; 需要注意的一点是，当提示 Enter file in which to save the key (/Users/leafney/.ssh/id_rsa): 时，我们不使用默认的名称 id_rsa ，因为该名称我们之前在设置个人git账户时已经使用过了，所以这里新设置一个针对于公司git账户的名称 id_rsa_work。 操作记录： 123456789101112131415161718192021222324~/.ssh➜ ssh-keygen -t rsa -C &quot;wuyazi@company.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/Users/leafney/.ssh/id_rsa): id_rsa_workEnter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in id_rsa_work.Your public key has been saved in id_rsa_work.pub.The key fingerprint is:SHA256:gZO6tyeOrp0FLGT5q2kBn3+9Et+P1shzjuyv3rUXWY0 wuyazi@company.comThe key&apos;s randomart image is:+---[RSA 2048]----+| || o ||. + . . || o o . . E .|| B . S o . || o = ... o || . B oo.o o .. || = Ao.oo*++. . || +=B.o+.+BB=.. |+----[SHA256]-----+~/.ssh took 22s 将密钥添加到ssh agent管理通过ssh agent对密钥的管理我们可以实现免密码提交。使用 ssh-add 命令来将新增的密钥添加到 ssh-agent 的高速缓存中： 12345~/.ssh//添加之前所新生成的用于work的密钥➜ ssh-add ~/.ssh/id_rsa_workIdentity added: /Users/leafney/.ssh/id_rsa_work (/Users/leafney/.ssh/id_rsa_work) 可以通过命令 ssh-add -l 来查看存在于 ssh-agent 密钥管理器中所有的密钥列表： 1234~/.ssh➜ ssh-add -l2048 SHA256:gZO6tyeOrp0FLGT5q2kBn3+9Et+P1shzjuyv3rUXWY0 /Users/leafney/.ssh/id_rsa_work (RSA)2048 SHA256:My6EL2r7d20oq01x1PeuRiYJSK2aID3sQlR+xCagPnE /Users/leafney/.ssh/id_rsa (RSA) 这里如果发现之前的 id_rsa 的密钥不存在，可以重新添加一下。 如果要删除所有已添加的密钥，可以使用命令：ssh-add -D 。 配置ssh config编辑configSSH 程序可以从以下途径获取配置参数： 用户配置文件：~/.ssh/config系统配置文件：/etc/ssh/ssh_config 配置文件可分为多个配置区段，每个配置区段使用 Host 来区分。我们可以在命令行中输入不同的Host来加载不同的配置段。 在 ~/.ssh 目录下打开配置文件 config(没有则新增该文件)，如下是我的配置示例： 新增： 12➜ cd ~/.ssh/➜ touch config config 内容: 123456789Host work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_workHost github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa 配置项说明常用的SSH配置项： Host 别名 : Host myhost 表示自定义的host简称，以后连接远程服务器就可以使用命令 ssh myhost (注意下面有缩进) HostName 主机名 : 主机名可以是ip也可以是域名(如:github.com或者bitbucket.org);如果主机名中包含 %h ，则实际使用时会被命令行中的主机名替换。 Port 端口 : 表示服务器open-ssh端口，默认22，默认时一般不写此行 User 用户名 : User git 表示登录ssh的用户名，如 git IdentityFile ： 表示证书文件路径（如 ~/.ssh/id_rsa_*) 其他SSH配置项： IdentitiesOnly 只接受 SSH Key 登录 可选 yes or no PreferredAuthentications 强制使用Public Key验证 测试如上，我用别名 work 指代了公司gitlab的ip地址 111.206.223.205:8080 ，使用 ssh -T 命令来验证一下： 123456➜ ssh -T git@workThe authenticity of host &apos;111.206.223.205:8080 (111.206.223.205:8080)&apos; can&apos;t be established.RSA key fingerprint is SHA256:/UwiMSDZVkgF+3yLAxHwMJfYGxK2XGk5DU3txRr+LNg.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;111.206.223.205:8080&apos; (RSA) to the list of known hosts.Welcome to GitLab, 无崖子! 第一版示例项目clone如上的步骤配置完成后，我们就可以通过ssh别名的方式来区分使用不同的SSH Key了。 在 clone 项目到本地之前，我们需要进行一个小小的改动。 之前的clone命令： 1➜ git clone git@111.206.223.205:8080:how_to_use_multiple_git_ssh/you_can_by_this_way.git 更改后的clone命令： 1➜ git clone git@work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 即我们将原来ssh地址中的域名用我们在配置文件中的别名来代替了，而相应的别名又对应着ssh密钥文件。 当然，我们还可以更精简一下，因为我们在config 文件中已经指定了用户为 git ，所以可将路径中的用户名也省略掉： 1➜ git clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 这样，看起来是不是非常的舒服呢？ 而如果我要clone自己的个人项目，则仍然按照之前的操作即可： 1➜ git clone git@github.com:Leafney/docker-alpine-mysql.git 设置项目提交账户在将项目 clone 到本地之后，还要为该项目单独设置commit提交时使用的git账户。 因为我们在之前已经按照 Linux下使用SSH密钥连接Github 操作中的方法将我的个人账户 leafney leafney@gmail.com 设置为了全局的git账户，在提交项目时如果没有设置项目单独的git账户，就会使用全局的，那这样就不对了。 不加 --global 参数，为刚刚clone下来的公司项目设置公司分配的git账户： 12➜ git config user.name &quot;wuyazi&quot; # 双引号是为了防止name中含有空格而导致错误➜ git config user.email &quot;wuyazi@company.com&quot; 这样就配置完成了。 还能再快一点吗总结上面的操作步骤，无非是设置了如下两项： 指定git项目使用的SSH Key 指定git项目提交时使用的git账户 那么第一步我们已经在ssh的 config 中做了指定，貌似已经是最快的操作了。那就看看第二项如何优化呢？ 我们是在git项目clone到本地之后，再去为该项目添加了使用的git账户，那是否能将这两步合并为一步呢？ 答案当然是可以的。 设置Base/Zsh方便clone操作为了以后方便使用不同git账户 git clone 项目，我们在 bash 的 ~/.bashrc 或者 zsh 的 ~/.zshrc 内加入： 1alias work-git-clone=&apos;git clone --config user.name=&quot;wuyazi&quot; --config user.email=&quot;wuyazi@company.com&quot; $@&apos; 以后就只要输入 work-git-clone REPO-SSH-URL ，效果就相当于执行了如下的命令: 1234git clone REPO-SSH-URLcd REPOgit config user.name &quot;wuyazi&quot;git config user.email &quot;wuyazi@company.com&quot; 然后，更新 Bash/Zsh 的设置： 12345# 更新Bash设置➜ source ~/.bashrc# 更新zsh设置➜ source ~/.zshrc 参考自；多重 SSH Keys 與 Github 帳號 第二版示例经过上面的操作，我们在 git clone 公司的git项目时，只需要执行如下简单的两步即可： 第一步：更改SSH地址 1234# 将项目SSH地址：git@111.206.223.205:8080:how_to_use_multiple_git_ssh/you_can_by_this_way.git# 更改为:work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 第二步：执行 work-git-clone 1➜ work-git-clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 而操作个人的git项目，命令只需要一步： 1➜ git clone git@github.com:Leafney/docker-alpine-mysql.git 新的复杂需求上面的需求可能是相对来说比较常见而且普通的一种情况了，那么下面的需求算是一种稍微复杂的情况了。 因为在Github上发布私有的项目，是需要付费的，所以一般针对于个人的私有项目，我们一般会选择自己购买服务器来搭建属于自己的私有个人仓库，比如我自己的 gogit.itfanr.cc 就是我用开源项目 Gogs 来搭建的。有兴趣可查看我的开源项目：Docker Ubuntu-Gogs 用更简单的方式部署、升级或迁移Gogs服务。 。 那么，现在就出现了下面的四种情况： 对于我个人想要开源的代码项目，我会选择使用个人账户发布到 github.com 站点下； 对于我个人的私有代码项目，我会选择使用个人账户发布到我自己搭建的 gogit.itfanr.cc 仓库站点下； 对于公司的私有项目，我要选择使用公司分配的git账户发布到公司搭建的私有仓库 111.206.223.205:8080 站点下； 对于我在工作中的一些积累或私人的项目，我想使用公司分配的git账户发布到我个人的 gogit.itfanr.cc 仓库站点下； 修改ssh config经过上面的步骤，我们很容易的就知道想要实现上面的需求，只需要通过修改SSH的配置文件 config 中的配置即可实现。 对于公司的项目，针对于上面第3个情况，我们仍然如之前的配置即可： config : 12345# company repo accountHost work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_work 那么在clone项目时的操作如下： 更改项目SSH地址中的域名部分； 执行命令： 1➜ work-git-clone work:how_to_use_multiple_git_ssh/you_can_by_this_way.git 对于工作中的私人项目，我们要使用公司的git账户来发布到我的个人仓库站点 gogit.itfanr.cc。配置时我们还需要指定使用密钥 id_rsa_work ： config : 12345# wuyazi private repo accountHost wuyazigogit HostName gogit.itfanr.cc User git IdentityFile ~/.ssh/id_rsa_work 那么在clone项目时的操作如下： 更改项目SSH地址中的域名部分； 1234# 如将: ssh://git@gogit.itfanr.cc:9527/wuyazi/repo_for_myself.git# 更改为:ssh://git@wuyazigogit:9527/wuyazi/repo_for_myself.git 执行命令： 1work-git-clone ssh://git@wuyazigogit:9527/wuyazi/repo_for_myself.git 因为我的个人账户是作为全局账户来使用的，就是说在 config 文件中如果上面的 Host 部分没有匹配上，那么要保证最后一个 Host 匹配到我的个人git账户。再次回顾 config 配置项中的常用参数，我们发现 HostName 除了可以设置域名或ip地址之外，还可以设置为 %h ，表示实际使用时会被命令行中的主机名替换。 所以，为了实现上面的第1种和第2种情况，以及实现对未特殊说明的项目的默认匹配，我用如下的方式来配置： 12345# leafney default account for github.com or gogit.itfanr.ccHost github.com gogit.itfanr.cc HostName %h User git IdentityFile ~/.ssh/id_rsa 如上，针对于不同主机地址使用同一私钥进行登录的情况，可以在 Host 中指定多个别名来匹配，而 HostName 中的 %h 会自动匹配用户输入的ssh地址中的域名部分，来匹配到对应的密钥。 那么在clone项目时的操作如下： 1git clone git@github.com:Leafney/ubuntu-gogs.git 综上，我的 config 配置内容如下： 1234567891011121314151617# company repo accountHost work HostName 111.206.223.205:8080 User git IdentityFile ~/.ssh/id_rsa_work# wuyazi private repo accountHost wuyazigogit HostName gogit.itfanr.cc User git IdentityFile ~/.ssh/id_rsa_work# leafney default account for github.com or gogit.itfanr.ccHost github.com gogit.itfanr.cc HostName %h User git IdentityFile ~/.ssh/id_rsa 相关参考 同一设备多个git账号的ssh管理 Git多帐号配置 利用SSH的用户配置文件Config管理SSH会话 多重 SSH Keys 與 Github 帳號]]></content>
      <categories>
        <category>Git操作系列</category>
      </categories>
      <tags>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客功能优化二]]></title>
    <url>%2F2018%2F03%2F11%2Fhexo-blog-optimization-two%2F</url>
    <content type="text"><![CDATA[介绍Hexo博客功能优化项。 将“打赏”两字更改为“鼓励”一直觉得 “打赏” 两个字不太适合博客这种语境，搞得像是杂耍完了向围观群众要赏钱的感觉：“有钱的捧个钱场，没钱的捧个人场…” 。写作，本来就是在学习技术的路上一次次总结，亦或和志同道合的技术人的一次次讨论，无关金钱或其他。而“鼓励”则更适合这种语境。如果我的文章帮到了你，虽然不能改变世界，但也许为你节省了一些时间，亦或在你进入一个技术死角一直出不来的情况下，带来的一点点希望或是灵感。你觉得我的文章对你带来了帮助，送我一杯咖啡，我内心是非常高兴地。如果你还想多聊两句，我也会感到非常荣幸。 相应的修改方法是： 找到项目目录下 /themes/next/languages/zh-Hans.yml 文件，因为我的博客采用的是中文。这里可以按照自己的博客设置选择相应的语言文件。 12345reward: donate: 鼓励 #打赏 wechatpay: 微信支付 alipay: 支付宝 bitcoin: 比特币 找到 reward 部分，将 donate 的值修改为自己想要的内容即可。这里我测试了一下，最长是4个汉字，否则就要修改按钮的样式了。 关于评论自此评论插件 “多说” 关闭之后，我就把博客中的评论功能去掉了，因为确实没有找到一款心仪的评论插件。 目前的话，也只是在博客的 “关于” 页面加了一个 email 地址能够立即联系到我。 因为我的邮箱手机客户端是24小时在线的，让我感到高兴的是确实还有一些朋友通过邮件向我咨询技术问题，我都一一为他们做了解答。之前还觉得这个邮箱地址放在“关于” 页面会比较隐蔽，今天稍微改版了一下，在每篇文章的末尾都加上了 email 地址，以方便交流。 这段提示文字我是直接加在了 next 主题配置文件 _config.yml 中的 Reward 打赏功能 部分。 原来的打赏功能提示文字 reward_comment 参数，如果添加的字符太多的话，就会导致自动换行。所以这里我修改了一下页面文件。 找到目录下 /themes/next/layout/_macro/reward.swig 文件，找到第二行的 1&lt;div&gt;&#123;&#123; theme.reward_comment &#125;&#125;&lt;/div&gt; 部分再复制一行，如下： 123456789&lt;div style=&quot;padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;&quot;&gt; &lt;div&gt;&#123;&#123; theme.reward_comment &#125;&#125;&lt;/div&gt; &lt;div&gt;&#123;&#123; theme.reward_comment2 &#125;&#125;&lt;/div&gt; &lt;button id=&quot;rewardButton&quot; disable=&quot;enable&quot; onclick=&quot;var qr = document.getElementById(&apos;QR&apos;); if (qr.style.display === &apos;none&apos;) &#123;qr.style.display=&apos;block&apos;;&#125; else &#123;qr.style.display=&apos;none&apos;&#125;&quot;&gt; &lt;span&gt;&#123;&#123; __(&apos;reward.donate&apos;) &#125;&#125;&lt;/span&gt; &lt;/button&gt; &lt;div id=&quot;QR&quot; style=&quot;display: none;&quot;&gt;...... 我这里就直接改成了 theme.reward_comment2 。然后在主题的配置文件中也添加一个 reward_comment2 部分即可。 12345# Reward 打赏功能reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！reward_comment2: 如有疑问或需要技术讨论，请发邮件到 service@itfanr.ccwechatpay: /images/wechat-reward-image.jpg... 页面载入进度这个效果也是刚刚查看配置文件的时候偶然看到的。 之前就曾看别人的博客做的特别炫。页面头部可以显示一个加载进度条，非常的羡慕。 在 next 主题的配置文件 _config.yml 中 找到 pace: false 将其改为 pace: true 即可。 在下面可以选择不同的加载主题样式，通过 pace_theme 参数设置。 123456pace: true# Themes list:#pace-theme-big-counter#pace-theme-bounce# ...pace_theme: pace-theme-flash 感谢支持截止目前为止，共收到了3位朋友的扫码红包鼓励，在这里对他们表示感谢。也很高兴我的文章帮助到了他们。 不过由于微信扫码支付无法查看到支付者的微信账号信息，所以在这里就没有列出他们的昵称等信息。具体列表可查看 关于 页面。]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百万英雄，看程序员带你如何任性吃瓜(1)]]></title>
    <url>%2F2018%2F01%2F16%2Fchi-gua-qun-zhong-bu-chi-gua-one%2F</url>
    <content type="text"><![CDATA[今天中午的时候没事，随手打开掘金app打算看看最近有什么好文章。看到热门推荐下有一篇文章名为 qanswer：冲顶大会等游戏答题神器（Golang） 号称《冲顶大会》,《百万英雄》等答题游戏的答题神器，让人顺利吃鸡！ 因为我最近也一直在关注西瓜视频里的“百万英雄”这个“全民直播答题吃瓜”的活动，但无奈自己的知识储备量太少，最高的一次答到第9题就被kill了。看到这篇文章顿时来了兴趣，准备好好研究一番。 该项目的github地址为 silenceper/qanswer 。在 README.md 中也记录了如何来部署运行，下面把我的部署流程简单的记录如下。 qanswer部署我使用的设备是 MacBook Pro，手机是 红米Note4x 高通版，分辨率为1920x1080。 对于其他平台如 Win或Linux，我也会顺带提一下。 安装go环境配置golang运行环境，可以直接参考我之前写的博客文章来安装：Golang运行环境配置 安卓设备连接安卓设备时需要安装一个驱动类工具adb。adb全称为 Android Debug Bridge ,即Android调试桥。Android 调试桥 (adb) 是一个通用命令行工具，其允许您与模拟器实例或连接的 Android 设备进行通信。它可为各种设备操作提供便利，如安装和调试应用，并提供对 Unix shell（可用来在模拟器或连接的设备上运行各种命令）的访问。 Mac系统安装adb通过 homebrew 来安装，执行如下命令： 1$ brew cask install android-platform-tools 当看到提示 android-platform-tools was successfully installed! 信息，说明安装成功。 命令 adb devices 可以用来查看当前连接的安卓设备： 1234$ adb devicesList of devices attached* daemon not running; starting now at tcp:5037* daemon started successfully 可见当前并没有连接的设备。 Ubuntu安装adb使用如下的命令来安装： 123sudo add-apt-repository ppa:nilarimogard/webupd8sudo apt-get updatesudo apt-get install android-tools-adb Win安装adb直接下载解压后就可使用 Download the ADB ZIP file for Windows ios设备对于ios设备，需要安装WDA。 具体的安装方法可参考项目中给出的文章 iOS 真机如何安装 WebDriverAgent 开启小米手机 MIUI9 USB调试模式为了能够调试手机，需要打开小米手机或其他安卓手机的USB调试模式。 小米手机 MIUI9系统的开启方法： 打开 “设置” – “我的设备” – “全部参数” 页面 然后连续三次以上点击“MIUI版本”一栏，会出现 开发者模式已打开的提示信息 返回设置主界面，进入“更多设置”，在无障碍选项下面出现了“开发者选项”，点击进入 在开发者选项中就可以找到“USB调试”，启用即可 通过数据线连接手机，再次执行上面命令： 1234$ adb devicesList of devices attacheda1529b810604 device 可以看到发现了我的安卓手机，并连接上了。 文字识别对于文字图像识别，项目中实现了两种方式：百度ocr 和 tesseract。这里我采用百度ocr来实现。 从百度的文字识别接口网站 百度文字识别 中，登录百度云管理平台后，在左侧选择“产品服务”–“人工智能”–“文字识别” 一项，选择 “创建应用” 就可以获得需要的api key 和secret key。 百度的文字识别接口有 500次/天 的免费使用权限，一般也够用了。 运行将项目克隆到 gopath 目录下 git clone https://github.com/silenceper/qanswer.git，如我这里是 /Go/xgo_workspace/src 目录下，然后添加项目引用： 1$ go get github.com/silenceper/qanswer 执行编译： 123$ cd qanswer/cmd$ go build -o ../qanswer 然后会在 qanswer 目录下生成一个名为 qanswer 的执行文件。 执行该程序： 1$ ./qanswer 结果输出： 1234配置文件：./config.yml设备：ios; 图片识别方式：baidu请按空格键开始搜索答案... 设置配置文件程序运行用到的配置文件是在当前目录下的 config.yml 文件。 配置参数说明如下： 123456789101112131415161718192021# 是否开始调试模式debug: false# 对应的设备类型：ios or androiddevice: ios# 使用的ocr工具：baidu or tesseractocr_type: baidu# ios 设备连接wda的地址wda_address: &apos;127.0.0.1:8100&apos;# 截取题目的位置 ：question_x: 30question_y: 310question_w: 650question_h: 135# 截取答案的位置answer_x: 30answer_y: 500answer_w: 680answer_h: 370#当选用baidu ocr时，需要执行api_key和secret_keybaidu_api_key: &quot;xxx....&quot;baidu_secret_key: &quot;xxx....&quot; 成功的关键在上面的配置文件中，关键的一点就是配置文件中设置的对于不同手机类型及不同分辨率的坐标设定了。 你需要根据自己手机对直播问答页面进行截图后获取的坐标点及像素长度来设定。 12345678910# 截取题目的位置question_x: 30question_y: 310question_w: 650question_h: 135# 截取答案的位置answer_x: 30answer_y: 500answer_w: 680answer_h: 370 对直播答题界面截屏，然后通过Mac系统自带的图片预览可以得到该界面中题目左上角顶点的x坐标位置和y坐标位置以及题目区域的宽度和高度。同理能够获得答案部分的值。 这里要提一下的是，这里的坐标是向右为x轴正方向，向下为y轴正方向。所以值均为正数。 经过测量，我的手机的配置信息如下： 123456789101112131415# 百万英雄 红米Note4x 高通版 1920x1080debug: truedevice: androidocr_type: baiduwda_address: &apos;127.0.0.1:8100&apos;question_x: 80question_y: 270question_w: 920question_h: 400answer_x: 80answer_y: 680answer_w: 920answer_h: 580baidu_api_key: xxx...baidu_secret_key: xxx... 另外，baidu_api_key 和 baidu_secret_key 设置成在百度文本识别中创建应用的对应值。如果使用的是 tesseract 这两项则不用管。 执行效果1234567891011121314151617181920212223242526272829配置文件：./config.yml设备：android; 图片识别方式：baidu请按空格键开始搜索答案...正在开始搜索....2018/01/16 13:33:27 image.go:41: [debug] 保存question截图成功2018/01/16 13:33:27 image.go:51: [debug] 保存answer截图成功2018/01/16 13:33:27 image.go:22: [debug] 保存完整截图成功，./images/screenshot.png2018/01/16 13:33:28 qanswer.go:144: [debug] 斗杓东指,天下皆冬北斗一星为天权玉衡星是七星中最亮的星2018/01/16 13:33:28 qanswer.go:133: [debug] 2.关于北七斗七星,下列说法正确的是?识别题目：关于北七斗七星,下列说法正确的是?识别答案：[斗杓东指,天下皆冬 北斗一星为天权 玉衡星是七星中最亮的星]================百度搜索==============关于北七斗七星,下列说法正确的是?答案：斗杓东指,天下皆冬 : 结果总数 7400 ， 答案出现频率： 0北斗一星为天权 : 结果总数 189000 ， 答案出现频率： 0玉衡星是七星中最亮的星 : 结果总数 383000 ， 答案出现频率： 0======================================耗时：7.24113s请按空格键开始搜索答案... 另外附上一些执行过程截图： 出现的问题在实际的测试中，我也发现了该项目的一些问题。 判断逻辑的可行性目前该项目中使用的搜索引擎是百度。 而程序当前对问题答案获取的后台逻辑是：通过将问题和三个不同的答案拼接输出到搜索引擎中进行搜索查询，如使用百度，在搜索结果页面中会输出：“百度为您找到相关结果约487,000个” 类似这样的一段话。而答案的判断逻辑就是看三种答案对应的搜索结果的数据总条数来预测该答案可能为正确的答案。 但这样的方法并不一定能保证完全的正确，如下面的一个问题： 如果按照推荐的答案，要选 “探戈” 。而这道题的正确答案应该是 “森巴” 。 后来，我又对其他常用的搜索引擎做了对比。如我对比了 Baidu 、Bing国内版 、 Bing国际版 和 Google（需FQ） ，结果发现这四种搜索结果的正确率为： Google &gt; Bing国际版 &gt; Bing国内版 &gt; Baidu 但是后来我增加了问题的测试数量，发现Google对于答案的判断正确率也比较低。 例如其中的一个问题： 哪一种反应属于化学反应? 食物腐烂冰化水玻璃碎成块 通过百度测试，对于三个答案的搜索结果数量为： 可见，按照搜索数量结果来看的话，要选 “玻璃碎成块” ，但正确的答案应该是 “食物腐烂”。 后来我又使用 google 进行了测试: 食物腐烂 98400冰化水 483000玻璃碎成块 116000 可见在Google下这种方式得到的答案也不正确。 所以，我觉得这种判断逻辑只能给出70%的正确率，在答题过程中也仅仅作为参考答案，而不能一味的相信。 否定句如果遇到标题是否定句式的情况，通过上面这种搜索的形式就无法找到正确的答案了，一般搜索出来的也是“肯定句式”下的答案。 比如下面这个问题： 正确的答案应该是 爱如潮水。 文字识别出错还有一种情况就是图像文字没有识别出来的情况，最后也就不能给出相应的答案了。 其他方法实现个人认为类似这种问答类的题目，可行的方式比如对问题进行分词处理，然后对关键词去搜索匹配，通过词频来判断；或者弹出浏览器由用户自己去判断最终的答案，一般像搜索引擎的搜索结果页面，都会有标题和简短的内容，内容中的关键字会被标红显示，由用户自己去判断，准确性会更高一些，但这样耗费的时间也会特别长。应该还有其他的方法吧。 目前我也在用python来实现一种可能的方法，我会在后续的文章中详细说明，敬请期待吧！ 最后再说一句。如果看到这篇文章后你也对这种“答题吃瓜”的直播问题活动产生了兴趣，可以使用我的邀请码来获得一张复活卡的机会，输入下面的邀请码即可。 相关参考 qanswer How to Install ADB on Windows, macOS, and Linux Android 调试桥 在 MAC OS X 安装 ADB (Android调试桥)]]></content>
      <tags>
        <tag>直播问答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(三)-任务]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-third%2F</url>
    <content type="text"><![CDATA[在上一篇 Celery分布式任务队列入门(二)-环境配置 中介绍了一种简单任务的创建方法。 对于任务，在Celery中主要分为 异步任务 和 定时任务，下面详细的来说说。 配置Celery中的配置可以直接在应用上设置，也可以使用一个独立的配置模块。 直接配置例如你可以通过修改 CELERY_TASK_SERIALIZER 选项来配置序列化任务载荷的默认的序列化方式： 1app.conf.CELERY_TASK_SERIALIZER = &apos;json&apos; 一次性设置多个选项，你可以使用 update() 方法： 1234567app.conf.update( CELERY_TASK_SERIALIZER=&apos;json&apos;, CELERY_ACCEPT_CONTENT=[&apos;json&apos;], # Ignore other content CELERY_RESULT_SERIALIZER=&apos;json&apos;, CELERY_TIMEZONE=&apos;Europe/Oslo&apos;, CELERY_ENABLE_UTC=True,) 示例： 1234567891011121314151617181920212223242526from celery import CeleryCELERY_CONFIG = &#123; &apos;CELERY_TIMEZONE&apos;: &apos;Asia/Shanghai&apos;, &apos;CELERY_ENABLE_UTC&apos;: True, # content &apos;CELERY_TASK_SERIALIZER&apos;: &apos;json&apos;, &apos;CELERY_RESULT_SERIALIZER&apos;: &apos;json&apos;, &apos;CELERY_ACCEPT_CONTENT&apos;: [&apos;json&apos;], &apos;CELERYD_MAX_TASKS_PER_CHILD&apos;: 1&#125;SETTINGS = &#123; &apos;user&apos;: &apos;www-data&apos;, &apos;password&apos;: &apos;www-data&apos;, &apos;host&apos;: &apos;127.0.0.1&apos;, &apos;port&apos;: &apos;5672&apos;, &apos;vhost&apos;: &apos;t_celery&apos;&#125;app = Celery( &apos;test_celery&apos;, broker=&apos;amqp://&#123;user&#125;:&#123;password&#125;@&#123;host&#125;:&#123;port&#125;/&#123;vhost&#125;&apos;.format( **SETTINGS))app.conf.update(**CELERY_CONFIG) 独立配置模块对于大型项目，采用独立配置模块更为有效。 可以调用 config_from_object() 来让 Celery 实例加载配置模块： 1app.config_from_object(&apos;celeryconfig&apos;) 配置模块通常称为 celeryconfig ，你也可以使用任意的模块名。名为 celeryconfig.py 的模块必须可以从当前目录或 Python 路径加载。 celeryconfig.py 格式一般为： 12345678BROKER_URL = &apos;amqp://&apos;CELERY_RESULT_BACKEND = &apos;amqp://&apos;CELERY_TASK_SERIALIZER = &apos;json&apos;CELERY_RESULT_SERIALIZER = &apos;json&apos;CELERY_ACCEPT_CONTENT=[&apos;json&apos;]CELERY_TIMEZONE = &apos;Europe/Oslo&apos;CELERY_ENABLE_UTC = True 检查配置文件的语法错误，可以： 1$ python -m celeryconfig 更多配置参数参考：Configuration and defaults 有关配置的使用可以看我另一篇文章中的详细介绍。 异步任务在初级篇中我们创建的简单任务 tasks.py 就是一个异步任务。tasks.py ： 1234567891011121314#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.taskdef add(x, y): return x + y 创建了一个 Celery 实例 app ，指定名称为 tasks 指定消息中间件 broker 使用 RabbitMQ ，指定结果存储 backend 使用 RabbitMQ 创建了一个 Celery 任务 add，当函数被 @app.task 装饰后，就成为可被 Celery 调度的任务 运行 worker在 tasks.py 文件所在目录执行： 1$ celery -A tasks worker --loglevel=info 这个命令会开启一个在前台运行的 worker。 参数说明： worker : 运行 worker 模块 -A: –app=APP 指定使用的 Celery 实例所在的文件模块 -l: -–loglevel=INFO 指定日志级别，默认为 WARNING，可选：DEBUG, INFO, WARNING, ERROR, CRITICAL, FATAL 如果是创建任务模块，可以使用模块名称来启动： 1$ celery -A proj worker -l info 或者使用完整命令： 1$ celery worker --app=proj -l info 查看完整的帮助信息： 1$ celery worker --help 示例： 12345678910111213root@b792ae940e3e:/app# celery worker --helpusage: celery worker [options] Start worker instance.Examples: $ celery worker --app=proj -l info $ celery worker -A proj -l info -Q hipri,lopri $ celery worker -A proj --concurrency=4 $ celery worker -A proj --concurrency=1000 -P eventlet $ celery worker --autoscale=10,0 Workers Guide celery.bin.worker 扩展 对于参数 -A: –app=APP 表示指定使用的 Celery 实例。即指py文件的文件名（不包括扩展名.py）或项目的模块名 比如项目结构如下： 12345testcelery/ |- src/ |- __init__.py |- app.py |- task.py 那么启动worker任务 task.py 的命令即为： 1$ celery worker -A src.task -l info 调用 Taskdelay调用在异步调用方式中，可以通过 delay 或者 apply_async 来实现。 123from tasks import addadd.delay(3, 4) 示例，创建文件 client.py : 1234567#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import addif __name__ == &apos;__main__&apos;: add.delay(1, 5) 执行 $ python3 client.py 就能调用执行了。 apply_async12345678#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import addif __name__ == &apos;__main__&apos;: # add.delay(1, 5) add.apply_async(args=(5, 6)) delay 和 apply_async 这两种调用方式等价，delay 是 apply_async 的简写。用于一个任务消息（task message）。之前的示例中我们发现 add 任务并没有返回 “计算结果”，而是返回了一个对象 AsyncResult，它的作用是被用来检查任务状态，等待任务执行完毕或获取任务结果，如果任务失败，它会返回异常信息或者调用栈。 apply_async 参数 apply_async 相比 delay的优点就是，apply_async支持更多的参数。 1apply_async(args=(), kwargs=&#123;&#125;, route_name=None, **options) apply_async 常用的参数如下： countdown ：任务延迟执行的秒数，默认立即执行； 1task1.apply_async(args=(2, 3), countdown=5) # 5 秒后执行任务 eta ：任务被执行的绝对时间，参数类型是 datetime 1234from datetime import datetime, timedelta# 当前 UTC 时间再加 10 秒后执行任务task1.multiply.apply_async(args=[3, 7], eta=datetime.utcnow() + timedelta(seconds=10)) expires : 任务过期时间，参数类型可以是 int，也可以是 datetime 1task1.multiply.apply_async(args=[3, 7], expires=10) # 10 秒后过期 更多的参数列表可以在 官方文档 中查看。 send_task调用除了使用 delay 的方式，还已通过 send_task() 的方式来调用。同时 send_task() 也支持设置更多的参数。 示例，client.py : 123456789#!/usr/bin/env python3# -*- coding: utf-8 -*-from tasks import appif __name__ == &apos;__main__&apos;: # add.delay(1, 5) # add.apply_async(args=(5, 6)) app.send_task(&apos;tasks.add&apos;, args=(12, 23),) 注意，这里引入的是 app 实例。args 参数是一个元组类型。相应的执行结果为： 12[2017-12-10 07:11:38,057: INFO/MainProcess] Received task: tasks.add[83fd530f-d800-43c7-bcfe-920a176812e2] [2017-12-10 07:11:43,217: INFO/ForkPoolWorker-1] Task tasks.add[83fd530f-d800-43c7-bcfe-920a176812e2] succeeded in 5.1578904589996455s: 35 AsyncResult方法上一篇文章中我们提到过返回对象 AsyncResult 的 ready() 方法，继续来看一下其他的方法： ready 为 True 表示已经返回结果了 12&gt;&gt;&gt; result.ready()True status 表示任务执行状态，失败还是成功 12&gt;&gt;&gt; result.status&apos;SUCCESS&apos; result 和 get() 表示返回的结果 12345&gt;&gt;&gt; result.result7&gt;&gt;&gt; result.get() 7 id 用来查看任务的id属性： 12&gt;&gt;&gt; result.id&apos;c178619e-3af3-41ed-8d2c-6371de80a601&apos; 定时任务Celery Beat 进程通过读取配置文件的内容，周期性地将定时任务发往任务队列。 在Celery的定时任务中，重要的两个方法是 定时器 和 执行器： 定时器，也叫作 beater，也就是帮助我们计算什么时候执行什么操作 执行器，也叫作 worker，真正执行任务的地方，我们的任务都是通过这个运行的 创建Celery定时任务有多中方法。 通过配置文件方式可以在配置文件中通过 CELERYBEAT_SCHEDULE 设置定时。 简单定时任务创建一个Celery的任务 tasks.py： 1234567891011121314151617181920212223242526#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.update( # 配置定时任务 CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125; &#125;)@app.taskdef add(x, y): return x + y 然后，启动这个 worker 进程： 1# celery -A tasks worker -l info 接着，启动 Celery Beat 进程，定时将任务发送到 Broker ，在另一个命令行窗口下执行： 1# celery beat -A tasks -l info 可以看到提示信息： 123456789101112root@b792ae940e3e:/app# celery beat -A tasks -l infocelery beat v4.1.0 (latentcall) is starting.__ - ... __ - _LocalTime -&gt; 2017-12-10 08:48:29Configuration -&gt; . broker -&gt; amqp://myuser:**@localhost:5672/hellohost . loader -&gt; celery.loaders.app.AppLoader . scheduler -&gt; celery.beat.PersistentScheduler . db -&gt; celerybeat-schedule . logfile -&gt; [stderr]@%INFO . maxinterval -&gt; 5.00 minutes (300s)[2017-12-10 08:48:29,141: INFO/MainProcess] beat: Starting... 一段时间后，可以看到执行结果： beat 执行结果： 1234567[2017-12-10 08:49:29,277: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:50:29,289: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:51:29,322: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:52:29,334: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:53:29,375: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:54:29,411: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 08:55:29,426: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add) workder 执行结果： 1234567891011[2017-12-10 08:41:37,839: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 08:49:29,290: INFO/MainProcess] Received task: tasks.add[1667ee3b-58c8-4a1a-be9f-0c20c3086bde] [2017-12-10 08:49:29,321: INFO/ForkPoolWorker-1] Task tasks.add[1667ee3b-58c8-4a1a-be9f-0c20c3086bde] succeeded in 0.029423292000501533s: 56[2017-12-10 08:50:29,295: INFO/MainProcess] Received task: tasks.add[db2d9ead-c22f-4efe-8d1c-6995f0ce9148] [2017-12-10 08:50:29,345: INFO/ForkPoolWorker-1] Task tasks.add[db2d9ead-c22f-4efe-8d1c-6995f0ce9148] succeeded in 0.046812374001092394s: 56[2017-12-10 08:51:29,324: INFO/MainProcess] Received task: tasks.add[7b23af5f-a467-4263-9cd0-87486f2df25d] [2017-12-10 08:51:29,338: INFO/ForkPoolWorker-1] Task tasks.add[7b23af5f-a467-4263-9cd0-87486f2df25d] succeeded in 0.011024585000996012s: 56[2017-12-10 08:52:29,336: INFO/MainProcess] Received task: tasks.add[2f3489e4-625e-460a-bc57-3fdf13456d97] [2017-12-10 08:52:29,349: INFO/ForkPoolWorker-1] Task tasks.add[2f3489e4-625e-460a-bc57-3fdf13456d97] succeeded in 0.01185457899919129s: 56[2017-12-10 08:53:29,381: INFO/MainProcess] Received task: tasks.add[ec7377fb-1859-4980-861b-2592422aad8c] [2017-12-10 08:53:29,408: INFO/ForkPoolWorker-1] Task tasks.add[ec7377fb-1859-4980-861b-2592422aad8c] succeeded in 0.021194035000007716s: 56 上面定时任务的配置信息表示： 12345678# 配置定时任务CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;&#125; 其中： my_task 表示当前任务的名称，可以自定义指定 task 表示 tasks.py 模块下的 add 方法 schedule 表示 任务执行的间隔，如果使用 int 类型，则单位是秒；还可以使用 timedelta 类型 args 表示任务函数参数，注意参数类型为元组 如果不通过 update 来修改，还可以通过设置 beat_schedule 配置项来设置。 1234567891011121314151617181920212223#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.beat_schedule = &#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (1, 2), &#125;&#125;app.conf.timezone = &apos;UTC&apos;@app.taskdef add(x, y): return x + y 多项定时任务我们还可以在配置文件中同时定义多个定时任务，只需要在 CELERYBEAT_SCHEDULE 项中添加即可: 12345678910111213# 配置定时任务CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;, &apos;your_task&apos;:&#123; &apos;task&apos;:&apos;tasks,add&apos;, &apos;schedule&apos;:30, &apos;args&apos;:(1,4), &#125;&#125; 相应的执行结果： beat 执行结果： 12345678910root@b792ae940e3e:/app# celery beat -A tasks -l info[2017-12-10 09:34:50,113: INFO/MainProcess] beat: Starting...[2017-12-10 09:35:20,151: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:35:50,145: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:35:50,149: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 09:36:20,166: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:36:50,187: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 09:36:50,188: INFO/MainProcess] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 09:37:20,208: INFO/MainProcess] Scheduler: Sending due task your_task (tasks.add) worker 执行结果： 1234567891011121314151617root@b792ae940e3e:/app# celery worker -A tasks -l info[2017-12-10 09:34:45,833: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 09:35:20,165: INFO/MainProcess] Received task: tasks.add[2b236ccf-c4af-430c-8d4e-a5cbaf331123] [2017-12-10 09:35:20,213: INFO/ForkPoolWorker-1] Task tasks.add[2b236ccf-c4af-430c-8d4e-a5cbaf331123] succeeded in 0.04618659699917771s: 5[2017-12-10 09:35:50,151: INFO/MainProcess] Received task: tasks.add[01f843bc-8506-4d61-97ce-5f989c576509] [2017-12-10 09:35:50,159: INFO/MainProcess] Received task: tasks.add[f3230694-ce5a-4bc3-9c92-eea71b9c4949] [2017-12-10 09:35:50,187: INFO/ForkPoolWorker-1] Task tasks.add[01f843bc-8506-4d61-97ce-5f989c576509] succeeded in 0.03170933700130263s: 5[2017-12-10 09:35:50,214: INFO/ForkPoolWorker-2] Task tasks.add[f3230694-ce5a-4bc3-9c92-eea71b9c4949] succeeded in 0.04673135899975023s: 56[2017-12-10 09:36:20,168: INFO/MainProcess] Received task: tasks.add[410e86bf-2e06-4a7d-965d-92d2e6a72c12] [2017-12-10 09:36:20,186: INFO/ForkPoolWorker-1] Task tasks.add[410e86bf-2e06-4a7d-965d-92d2e6a72c12] succeeded in 0.01682951399925514s: 5[2017-12-10 09:36:50,191: INFO/MainProcess] Received task: tasks.add[d2b32ff2-8e8e-4903-ad8f-7d12da132739] [2017-12-10 09:36:50,193: INFO/MainProcess] Received task: tasks.add[dc7fc344-374e-438b-8a0f-85f9e9f08aac] [2017-12-10 09:36:50,207: INFO/ForkPoolWorker-1] Task tasks.add[d2b32ff2-8e8e-4903-ad8f-7d12da132739] succeeded in 0.013693080998564255s: 5[2017-12-10 09:36:50,211: INFO/ForkPoolWorker-2] Task tasks.add[dc7fc344-374e-438b-8a0f-85f9e9f08aac] succeeded in 0.017022554000504897s: 56[2017-12-10 09:37:20,213: INFO/MainProcess] Received task: tasks.add[49113d2d-a36d-44b0-92dc-9ad0382c26a2] [2017-12-10 09:37:20,246: INFO/ForkPoolWorker-1] Task tasks.add[49113d2d-a36d-44b0-92dc-9ad0382c26a2] succeeded in 0.027591496000241023s: 5 在上面，我们用两个命令启动了 Worker 进程和 Beat 进程，我们也可以将它们放在一个命令中： 1$ celery -B -A tasks worker --loglevel=info 相应的执行结果为： 123456789101112131415root@b792ae940e3e:/app# celery -B -A tasks worker -l info[2017-12-10 10:07:36,153: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 10:07:36,158: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:07:36,169: INFO/MainProcess] Received task: tasks.add[d92a952e-e3f6-4224-9e8b-dda771740fe2] [2017-12-10 10:07:36,221: INFO/ForkPoolWorker-2] Task tasks.add[d92a952e-e3f6-4224-9e8b-dda771740fe2] succeeded in 0.049944616001084796s: 5[2017-12-10 10:08:06,148: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:08:06,151: INFO/MainProcess] Received task: tasks.add[678c33ae-9d2d-40c1-b5ce-25ffbdf763d8] [2017-12-10 10:08:06,175: INFO/ForkPoolWorker-2] Task tasks.add[678c33ae-9d2d-40c1-b5ce-25ffbdf763d8] succeeded in 0.02311466900027881s: 5[2017-12-10 10:08:36,148: INFO/Beat] Scheduler: Sending due task your_task (tasks.add)[2017-12-10 10:08:36,149: INFO/Beat] Scheduler: Sending due task my_task (tasks.add)[2017-12-10 10:08:36,150: INFO/MainProcess] Received task: tasks.add[b05841b8-a382-4a1a-a583-3695e6d369d2] [2017-12-10 10:08:36,152: INFO/MainProcess] Received task: tasks.add[baebd820-4a22-496c-8c39-6b9f52d2f22b] [2017-12-10 10:08:36,195: INFO/ForkPoolWorker-2] Task tasks.add[b05841b8-a382-4a1a-a583-3695e6d369d2] succeeded in 0.04302837300019746s: 5[2017-12-10 10:08:36,198: INFO/ForkPoolWorker-3] Task tasks.add[baebd820-4a22-496c-8c39-6b9f52d2f22b] succeeded in 0.0449830910001765s: 56 时区Celery定时任务默认使用UTC时区。我们可以在配置文件中来设置。最终的 tasks.py 文件： 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )app.conf.update( # 配置所在时区 CELERY_TIMEZONE=&apos;Asia/Shanghai&apos;, CELERY_ENABLE_UTC=True, # 官网推荐消息序列化方式为json CELERY_ACCEPT_CONTENT=[&apos;json&apos;], CELERY_TASK_SERIALIZER=&apos;json&apos;, CELERY_RESULT_SERIALIZER=&apos;json&apos;, # 配置定时任务 CELERYBEAT_SCHEDULE=&#123; &apos;my_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 60, &apos;args&apos;: (22, 34), &#125;, &apos;your_task&apos;: &#123; &apos;task&apos;: &apos;tasks.add&apos;, &apos;schedule&apos;: 30, &apos;args&apos;: (1, 4), &#125; &#125;)@app.taskdef add(x, y): return x + y 通过on_after_configure定义使用 on_after_configure 处理程序来装饰定时任务。如 tasks.py 文件： 123456789101112131415161718192021#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.on_after_configure.connectdef setup_periodic_tasks(sender, **kwargs): # Calls test(&apos;hello&apos;) every 10 seconds. sender.add_periodic_task(10.0, add.s(&apos;hello&apos;), name=&apos;add every 10&apos;)@app.taskdef add(arg): print(arg) return arg 执行示例： 123456789101112root@b792ae940e3e:/app# celery -B -A tasks worker -l info[2017-12-10 10:53:30,420: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-10 10:53:30,596: INFO/Beat] beat: Starting...[2017-12-10 10:53:30,620: INFO/Beat] Scheduler: Sending due task add every 10 (tasks.add)[2017-12-10 10:53:30,628: INFO/MainProcess] Received task: tasks.add[315383b8-5bd7-48ab-8dd2-c5d39e71f058] [2017-12-10 10:53:30,630: WARNING/ForkPoolWorker-3] hello[2017-12-10 10:53:30,667: INFO/ForkPoolWorker-3] Task tasks.add[315383b8-5bd7-48ab-8dd2-c5d39e71f058] succeeded in 0.03778552899893839s: &apos;hello&apos;[2017-12-10 10:53:40,602: INFO/Beat] Scheduler: Sending due task add every 10 (tasks.add)[2017-12-10 10:53:40,607: INFO/MainProcess] Received task: tasks.add[5f8ef21e-fbfd-4c82-8dbd-6fa2aeaf4fa4] [2017-12-10 10:53:40,610: WARNING/ForkPoolWorker-3] hello[2017-12-10 10:53:40,631: INFO/ForkPoolWorker-3] Task tasks.add[5f8ef21e-fbfd-4c82-8dbd-6fa2aeaf4fa4] succeeded in 0.022007824998581782s: &apos;hello&apos; 同时，add_periodic_task() 方法也能设置其他参数： 12# Calls test(&apos;world&apos;) every 30 secondssender.add_periodic_task(30.0, add.s(&apos;world&apos;), expires=10) 或者也能通过 crontab() 来应用 cron 表达式，实现多种时间的设定。 12345# Executes every Monday morning at 7:30 a.m.sender.add_periodic_task( crontab(hour=7, minute=30, day_of_week=1), add.s(&apos;Happy Mondays!&apos;),) 相关参考 Periodic Tasks 异步任务神器 Celery]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(二)-环境配置]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-second%2F</url>
    <content type="text"><![CDATA[实践在Docker容器中配置Celery运行环境。 创建Docker容器在容器 Ubuntu:16.04 系统中来搭建，创建容器： 1$ docker run -it --name celery1 -p 5672:5672 -p 15673:15672 -v /home/tiger/dckerfile/celery1:/app ubuntu /bin/bash 需要注意的是在Docker容器中不需要 sudo 命令，默认即是 root 权限。下面的命令请根据自己所在系统类型自行添加 sudo 操作。 更新软件源12345# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list# apt-get update 安装Erlang依赖Erlang可以通过包管理器来安装，或者直接从官方网站下载安装包来安装。 执行如下命令安装： 123456cd /tmpwget http://packages.erlang-solutions.com/ubuntu/erlang_solutions.asc# apt-key add erlang_solutions.asc# apt-get update# apt-get install erlang# apt-get install erlang-nox 或者直接从网站 Erlang Downloads 下载 .deb 安装包来安装。 安装RabbitMQ执行如下命令通过包管理器来安装： 123456# echo &quot;deb https://dl.bintray.com/rabbitmq/debian xenial main&quot; | tee /etc/apt/sources.list.d/bintray.rabbitmq.list# wget -O- https://www.rabbitmq.com/rabbitmq-release-signing-key.asc | apt-key add -# apt-get update# apt-get install rabbitmq-server 发现通过上面方法安装的 Erlang Version 为 Erlang/OTP 18 [erts-7.3] [source] [64-bit] [smp:2:2] ，RabbitMQ Version 为 &quot;RabbitMQ&quot;,&quot;3.5.7&quot; 都不是官网上的最新版本，但在软件源中来说已是可安装的最新版本。所以如果想要安装官方的最新版本，可以采用直接从官网获取安装包的方式来安装。 安装官方最新版在Ubuntu系统下直接下载 rabbitmq 的 *.deb 安装包： 从地址 Installing on Debian / Ubuntu 看到最新版本是 3.7.0 rabbitmq-server_3.7.0-1_all.deb 也可以从网址 Released Artifacts 选择其他指定版本。 下面以 rabbitmq-server_3.7.0-1_all.deb 为例安装： 12# wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.0/rabbitmq-server_3.7.0-1_all.deb# dpkg -i rabbitmq-server_3.7.0-1_all.deb 如果提示依赖其他的包，执行如下命令安装依赖包: 1# apt-get -f install 然后再次执行安装： 1# dpkg -i rabbitmq-server_3.7.0-1_all.deb 我在执行 apt-get -f install 时遇到问题，输出提示是要移除 rabbitmq-server ，并没有自动安装其他依赖： 123456789101112131415161718192021222324252627282930root@b792ae940e3e:/app# dpkg -i rabbitmq-server_3.7.0-1_all.deb Selecting previously unselected package rabbitmq-server.(Reading database ... 7744 files and directories currently installed.)Preparing to unpack rabbitmq-server_3.7.0-1_all.deb ...Unpacking rabbitmq-server (3.7.0-1) ...dpkg: dependency problems prevent configuration of rabbitmq-server: rabbitmq-server depends on erlang-nox (&gt;= 1:19.3) | esl-erlang (&gt;= 1:19.3); however: Package erlang-nox is not installed. Package esl-erlang is not installed. rabbitmq-server depends on logrotate; however: Package logrotate is not installed. rabbitmq-server depends on socat; however: Package socat is not installed.dpkg: error processing package rabbitmq-server (--install): dependency problems - leaving unconfiguredProcessing triggers for systemd (229-4ubuntu21) ...Errors were encountered while processing: rabbitmq-serverroot@b792ae940e3e:/app# apt-get -f installReading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following packages will be REMOVED: rabbitmq-server0 upgraded, 0 newly installed, 1 to remove and 2 not upgraded.1 not fully installed or removed.After this operation, 13.3 MB disk space will be freed.Do you want to continue? [Y/n] 所以，我选择手动安装 Erland 的 .deb 包。 从 网站 RabbitMQ Erlang Version Requirements 中可以看到RabbitMQ和Erlang版本之间的对应关系。这里上面的我按照的是RabbitMQ的 3.7.0 版本，所以我可以选择Erlang的最新版即 20.1.7 版本安装。下载地址见：Erlang Downloads 。 123# wget http://packages.erlang-solutions.com/site/esl/esl-erlang/FLAVOUR_1_general/esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 这次安装时也提示缺少依赖，所以我执行： 1# apt-get -f install 结果是找到了相关的依赖包，输入 y 进行安装。 12345678910111213141516171819202122232425262728293031root@b792ae940e3e:/app# lsesl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb rabbitmq-server_3.7.0-1_all.debroot@b792ae940e3e:/app# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb Selecting previously unselected package esl-erlang.(Reading database ... 7744 files and directories currently installed.)Preparing to unpack esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb ...Unpacking esl-erlang (1:20.1.7) ...dpkg: dependency problems prevent configuration of esl-erlang: esl-erlang depends on libwxbase2.8-0 | libwxbase3.0-0 | libwxbase3.0-0v5; however: Package libwxbase2.8-0 is not installed. Package libwxbase3.0-0 is not installed. Package libwxbase3.0-0v5 is not installed. esl-erlang depends on libwxgtk2.8-0 | libwxgtk3.0-0 | libwxgtk3.0-0v5; however: Package libwxgtk2.8-0 is not installed. Package libwxgtk3.0-0 is not installed. Package libwxgtk3.0-0v5 is not installed. esl-erlang depends on libsctp1; however: Package libsctp1 is not installed.dpkg: error processing package esl-erlang (--install): dependency problems - leaving unconfiguredErrors were encountered while processing: esl-erlangroot@b792ae940e3e:/app# apt-get -f installReading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following additional packages will be installed:............ 然后再次安装 esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 包： 1# dpkg -i esl-erlang_20.1.7-1~ubuntu~xenial_amd64.deb 最后，安装RabbitMQ的包： 1# dpkg -i rabbitmq-server_3.6.14-1_all.deb 如果中途再出现缺少依赖包的问题，通过 apt-get -f install 来解决。 1234567891011121314151617181920212223242526272829303132root@b792ae940e3e:/app# dpkg -i rabbitmq-server_3.7.0-1_all.deb Selecting previously unselected package rabbitmq-server.(Reading database ... 29232 files and directories currently installed.)Preparing to unpack rabbitmq-server_3.7.0-1_all.deb ...Unpacking rabbitmq-server (3.7.0-1) ...dpkg: dependency problems prevent configuration of rabbitmq-server: rabbitmq-server depends on logrotate; however: Package logrotate is not installed. rabbitmq-server depends on socat; however: Package socat is not installed.dpkg: error processing package rabbitmq-server (--install): dependency problems - leaving unconfiguredProcessing triggers for systemd (229-4ubuntu21) ...Errors were encountered while processing: rabbitmq-serverroot@b792ae940e3e:/app# apt-get -f install Reading package lists... DoneBuilding dependency tree Reading state information... DoneCorrecting dependencies... DoneThe following additional packages will be installed: cron libpopt0 libwrap0 logrotate socat tcpdSuggested packages: anacron checksecurity exim4 | postfix | mail-transport-agent mailxThe following NEW packages will be installed: cron libpopt0 libwrap0 logrotate socat tcpd0 upgraded, 6 newly installed, 0 to remove and 2 not upgraded.1 not fully installed or removed.Need to get 522 kB of archives.After this operation, 1674 kB of additional disk space will be used.Do you want to continue? [Y/n] Downloading and Installing RabbitMQ RabbitMQ安装方式及常用命令 ☆ Erlang Downloads Run RabbitMQ Server启动 RabbitMQ 服务:1# service rabbitmq-server start 安装 RabbitMQWeb 管理插件：12# rabbitmq-plugins enable rabbitmq_management # service rabbitmq-server restart 打开浏览器登录：http://127.0.0.1:15672，登录账号密码默认都是 guest 12345678910111213root@730778dc65bd:/app# rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@730778dc65bd... started 6 plugins.root@730778dc65bd:/app# service rabbitmq-server restart * Restarting RabbitMQ Messaging Server rabbitmq-server [ OK ] root@730778dc65bd:/app# 测试代码： 12345678910111213141516171819202122232425262728293031323334353637383940## 查看rabbitmq状态root@730778dc65bd:/app# rabbitmqctl statusStatus of node rabbit@730778dc65bd ...Error: unable to connect to node rabbit@730778dc65bd: nodedownDIAGNOSTICS===========attempted to contact: [rabbit@730778dc65bd]rabbit@730778dc65bd: * connected to epmd (port 4369) on 730778dc65bd * epmd reports: node &apos;rabbit&apos; not running at all no other nodes on 730778dc65bd * suggestion: start the nodecurrent node details:- node name: &apos;rabbitmq-cli-9223@730778dc65bd&apos;- home dir: /var/lib/rabbitmq- cookie hash: MwPrvM8WUeAkWCiIWYw2fg==root@730778dc65bd:/app# root@730778dc65bd:/app# service rabbitmq-server start * Starting RabbitMQ Messaging Server rabbitmq-server [ OK ] root@730778dc65bd:/app# rabbitmqctl statusStatus of node rabbit@730778dc65bd ...[&#123;pid,9527&#125;, &#123;running_applications,[&#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.5.7&quot;&#125;, &#123;mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.13.3&quot;&#125;, &#123;xmerl,&quot;XML parser&quot;,&quot;1.3.10&quot;&#125;, &#123;os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.4&quot;&#125;, &#123;sasl,&quot;SASL CXC 138 11&quot;,&quot;2.7&quot;&#125;, &#123;stdlib,&quot;ERTS CXC 138 10&quot;,&quot;2.8&quot;&#125;, &#123;kernel,&quot;ERTS CXC 138 10&quot;,&quot;4.2&quot;&#125;]&#125;, &#123;os,&#123;unix,linux&#125;&#125;, &#123;erlang_version,&quot;Erlang/OTP 18 [erts-7.3] [source] [64-bit] [smp:2:2] [async-threads:64] [kernel-poll:true]\n&quot;&#125;, &#123;memory,[&#123;total,83922208&#125;, &#123;connection_readers,0&#125;, &#123;connection_writers,0&#125;, RabbitMQ中的vitrual hostVirtual host，是起到隔离作用的。每一个 vhost 都有自己的 exchanges 和 queues，它们互不影响。不同的应用可以跑在相同的 rabbitmq 上，使用 vhost 把它们隔离开就行。默认情况下，rabbitmq 安装后，默认的 vhost 是 /。 创建用户并设置虚拟主机可以发现上面我们通过 guest 用户在其他电脑上或外网段访问时，会提示 User can only log in via localhost ，这是因为 guest 是仅允许在 localhost 下才能登陆的。如果我们想在外部访问，可以创建一个新的账户。 创建用户的同时为该用户指定允许访问的虚拟主机 myvhost 123# rabbitmqctl add_user myuser mypassword# rabbitmqctl add_vhost myvhost# rabbitmqctl set_permissions -p myvhost myuser &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; 此时，新创建的账户 myuser 也并没有权限在外网访问，可以用 set_user_tags 为用户设置角色： 1# rabbitmqctl set_user_tags myuser administrator 然后我们就能在外网通过地址 http://192.168.5.107:15673/ 来访问管理端了。 示例： 1234567891011# User: myuser # UserPwd: hello# VHost: hellohostroot@b792ae940e3e:/app# rabbitmqctl add_user myuser helloAdding user &quot;myuser&quot; ...root@b792ae940e3e:/app# rabbitmqctl add_vhost hellohostAdding vhost &quot;hellohost&quot; ...root@b792ae940e3e:/app# rabbitmqctl set_permissions -p hellohost myuser &quot;.*&quot; &quot;.*&quot; &quot;.*&quot;Setting permissions for user &quot;myuser&quot; in vhost &quot;hellohost&quot; ...root@b792ae940e3e:/app# 然后重启服务： 1# service rabbitmq-server restart CeleryCelery官方推荐使用 RabbitMQ 或 Redis 来作为中间件。设置也很简单，通过 broker 和 backend 参数即可绑定。 broker 和 backend可以用RabbitMQ和Redis来作为broker或backend： 1app = Celery(&apos;tasks&apos;, backend=&apos;amqp&apos;, broker=&apos;amqp://&apos;) 1app = Celery(&apos;tasks&apos;, backend=&apos;redis://localhost&apos;, broker=&apos;amqp://&apos;) 注意，虽然推荐使用RabbitMQ来作为 broker，但不推荐其作为 backend 。具体原因我会在后面的文章中说明。 中间人RabbitMQRabbitMQ 功能完备、稳定，是一个非常可靠的选择。 123BROKER_URL =transport://userid:password@hostname:port/virtual_hostBROKER_URL = &apos;amqp://guest:guest@localhost:5672//&apos; 完整的格式为： 1CELERY_BROKER_URL = &apos;amqp://[YOUR_NAME]:[PASSWORD]@localhost:[PORT]/[VHOST_NAME]&apos; 中间人Redis与 RabbitMQ 相比，使用 Redis 作为 broker 缺点是可能因为掉电或异常退出导致数据丢失，优点是使用简单。 以下命令可以同时安装 celery 和 redis 相关的依赖，但是 redis server 还是必须单独安装的。 1$ pip install -U celery[redis] # -U 的意思是把所有指定的包都升级到最新的版本 1BROKER_URL = &apos;redis://localhost:6379//&apos; 安装celery先安装 python3 pip3 等依赖: 1# apt-get install -y python3 python3-pip 123# pip3 install celery# 或者：# pip3 install -U Celery 创建一个 tasks.py 文件: 1234567from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://guest@localhost//&apos;)@app.taskdef add(x, y): return x + y 注意，其中的： 1app = Celery(&apos;tasks&apos;, broker=&apos;amqp://guest@localhost//&apos;) 中 broker 要改为上面设置的RabbitMQ的信息，所以结果为： 1app = Celery(&apos;tasks&apos;,broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;) Celery 的第一个参数是当前模块的名称，这个参数是必须的，这样的话名称可以自动生成。第二个参数是中间人关键字参数，指定你所使用的消息中间人的 URL。 保存结果执行完成后的结果，Celery 需要在某个地方存储或发送任务处理后的状态，可以通过 backend 参数来指定。格式和 broker 一致。 完整的 tasks.py: 1234567891011121314#!/usr/bin/env python3# -*- coding: utf-8 -*-from celery import Celeryapp = Celery(&apos;tasks&apos;, broker=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos;, backend=&apos;amqp://myuser:hello@localhost:5672/hellohost&apos; )@app.taskdef add(x, y): return x + y 运行Celery用 worker 参数执行程序: 1$ celery -A tasks worker --loglevel=info 输出： 123456789101112131415161718192021222324252627282930313233343536root@b792ae940e3e:/app# celery -A tasks worker --loglevel=info/usr/local/lib/python3.5/dist-packages/celery/platforms.py:795: RuntimeWarning: You&apos;re running the worker with superuser privileges: this isabsolutely not recommended!Please specify a different user using the -u option.User information: uid=0 euid=0 gid=0 egid=0 uid=uid, euid=euid, gid=gid, egid=egid,/usr/local/lib/python3.5/dist-packages/celery/backends/amqp.py:68: CPendingDeprecationWarning: The AMQP result backend is scheduled for deprecation in version 4.0 and removal in version v5.0. Please use RPC backend or a persistent backend. alternative=&apos;Please use RPC backend or a persistent backend.&apos;) -------------- celery@b792ae940e3e v4.1.0 (latentcall)---- **** ----- --- * *** * -- Linux-4.4.0-42-generic-x86_64-with-Ubuntu-16.04-xenial 2017-12-09 13:50:06-- * - **** --- - ** ---------- [config]- ** ---------- .&gt; app: tasks:0x7f97a8360dd8- ** ---------- .&gt; transport: amqp://myuser:**@localhost:5672/hellohost- ** ---------- .&gt; results: amqp://- *** --- * --- .&gt; concurrency: 2 (prefork)-- ******* ---- .&gt; task events: OFF (enable -E to monitor tasks in this worker)--- ***** ----- -------------- [queues] .&gt; celery exchange=celery(direct) key=celery [tasks] . tasks.add[2017-12-09 13:50:06,121: INFO/MainProcess] Connected to amqp://myuser:**@127.0.0.1:5672/hellohost[2017-12-09 13:50:06,137: INFO/MainProcess] mingle: searching for neighbors[2017-12-09 13:50:07,178: INFO/MainProcess] mingle: all alone[2017-12-09 13:50:07,228: INFO/MainProcess] celery@b792ae940e3e ready. 可以看到 celery 的 worker 已经准备就绪了。 查看 worker 完整的命令行参数列表: 123$ celery worker --help## 或者：$ celery help 调用任务使用 delay() 方法来调用任务。 新打开一个控制台界面， 1$ docker exec -it celery1 /bin/bash 执行： 1234# python3&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; add.delay(4, 4) 示例： 12345678root@b792ae940e3e:/app# python3Python 3.5.2 (default, Nov 23 2017, 16:37:01) [GCC 5.4.0 20160609] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; from tasks import add&gt;&gt;&gt; add.delay(3,4)&lt;AsyncResult: e1ae8ea3-8a8f-47c5-befb-e6ba975f0580&gt;&gt;&gt;&gt; 执行结果： 同时，也可以在 RabbitMQ web 管理页面看到新增了一个任务并存储了处理结果： 为了得到调用任务后返回的 AsyncResult 实例，通过一个参数来接收： 1&gt;&gt;&gt; result=add.delay(3,4) ready() 方法查看任务是否完成处理: 12&gt;&gt;&gt; result.ready()True #结果返回 `True` 表示任务处理完成 这里是异步调用，如果我们需要返回的结果，那么要等 ready 状态为 True 才行。 执行结果： 12345[2017-12-09 13:50:07,228: INFO/MainProcess] celery@b792ae940e3e ready.[2017-12-09 14:00:33,132: INFO/MainProcess] Received task: tasks.add[e1ae8ea3-8a8f-47c5-befb-e6ba975f0580] [2017-12-09 14:00:33,163: INFO/ForkPoolWorker-1] Task tasks.add[e1ae8ea3-8a8f-47c5-befb-e6ba975f0580] succeeded in 0.02956800399988424s: 7[2017-12-09 14:17:21,033: INFO/MainProcess] Received task: tasks.add[c178619e-3af3-41ed-8d2c-6371de80a601] [2017-12-09 14:17:21,058: INFO/ForkPoolWorker-1] Task tasks.add[c178619e-3af3-41ed-8d2c-6371de80a601] succeeded in 0.024445844999718247s: 7 相关参考 Celery 初步]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
        <tag>Docker</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Celery分布式任务队列入门(一)-理论]]></title>
    <url>%2F2017%2F12%2F10%2Fcelery-distributed-task-queue-introduction-first%2F</url>
    <content type="text"><![CDATA[之前曾在公司的一个分布式爬虫项目中使用 Celery 和 RabbitMQ 实现过分布式爬虫的功能。最近在整理之前的开发笔记时，看到之前写的关于 Celery 的文章，决定趁着有时间再把关于Celery相关的内容好好的整理一番，没想到越写越想把相关的点都理清楚，也就有了这个Celery系列文章。 Celery 是一个简单、灵活且可靠的，处理大量消息的分布式系统，并且提供维护这样一个系统的必需工具。它是一个专注于实时处理的任务队列，同时也支持任务调度。 主要模块 任务模块 Task包含异步任务和定时任务。其中，异步任务通常在业务逻辑中被触发并发往任务队列，而定时任务由 Celery Beat 进程周期性地将任务发往任务队列。 消息中间件 Broker一个消息传输的中间件，可以理解为一个邮箱，作为消费者和生产者之间的桥梁。接收任务生产者发来的消息（即任务），将任务存入队列。Celery 本身不提供队列服务，官方推荐使用 RabbitMQ 和 Redis 等。 任务执行单元 WorkerWorker 是执行任务的处理单元，它实时监控消息队列，获取队列中调度的任务，并执行它。 任务结果存储 BackendBackend 用于存储任务的执行结果，以供查询。同消息中间件一样，存储也可使用 RabbitMQ, Redis 和 MongoDB 等。 系列文章目录 Celery分布式任务队列入门(一)-理论 Celery分布式任务队列入门(二)-环境配置 Celery分布式任务队列入门(三)-任务 未完待续。。。]]></content>
      <categories>
        <category>Celery分布式任务队列入门</category>
      </categories>
      <tags>
        <tag>Celery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客功能优化]]></title>
    <url>%2F2017%2F12%2F06%2Fhexo-blog-optimization%2F</url>
    <content type="text"><![CDATA[介绍Hexo博客功能优化项，如 文章置顶、显示版权、访问统计、字数统计、显示更新时间等 文章置顶在Hexo博客中，有时候我们想要将一些特别的文章一直置顶在首页。Hexo博客中，默认的情况是按照时间倒序来排列的，即新发布的文章排在前面。虽然有一种很简单的方法，就是更改文章的发布时间到一个“未来”的时间点，这样虽然能让文章一直置顶，但是给人的体验和感觉是非常不好的。 今天介绍一种非常简单而且体验上也非常好的方法。 安装node插件12$ npm uninstall hexo-generator-index --save$ npm install hexo-generator-index-pin-top --save 添加标记在需要置顶的文章的 Front-matter 中加上 top: true 即可。 比如： 12345678910---title: 从0到1学Golang之基础--Go 数组date: 2017-05-24 22:07:58tags: - Golangcategories: - 从0到1学Golangdescription: Golang下的数组操作top: true--- ok，现在发布文章，就能看到我们设置的文章已经置顶显示了，即使是之前发布的文章，同时日期也不会被更改。 相关参考 解决Hexo置顶问题 hexo-generator-index-pin-top 使用Hexo基于GitHub Pages搭建个人博客（三） 如何置顶post？ 显示版权信息一般在网络上发表文章时，都要时刻提防着网络爬虫的抓取。特别是有些网站在抓取到你的文章后进行一些词语、段落的修改，公然改为自己发表的文章。完全无视原作者的辛苦。 为了更好的标明文章的版权，一般我们都会在文章中添加上文章的链接、版权声明等信息，虽然不能完全彻底的抵制文章抄袭的情况，也算是“防君子不防小人”吧。 启用版权我使用的是 Hexo 的 Next 主题。找到主题目录下的 _config.yml 文件，更改以下部分： 12345# Declare license on postspost_copyright: enable: false license: CC BY-NC-SA 3.0 license_url: https://creativecommons.org/licenses/by-nc-sa/3.0/ 将其中的 enable: false 改为 enable: true 即可。 但是改完后，使用 hexo s -g 预览，发现 “本文链接” 部分有问题。 这就需要我们修改主站点的配置文件了。打开主站点的 _config.yml 文件，修改： 将 url 部分改成自己站点的域名地址即可。 相关参考 Hexo持续优化-在文章尾部添加版权声明信息 访问统计功能在博客中我们一般都比较在意自己博客的访问量，或者哪篇文章比较受欢迎之类的。 在Hexo的 Next 主题下带有多种统计和分析的功能。这里我选择 不蒜子统计来显示文章的访客数、浏览量等信息。 启用统计找到 Next 主题下的配置文件 _config.yml ，找到 busuanzi_count 部分： 1234567891011121314151617# Show PV/UV of the website/page with busuanzi.# Get more information on http://ibruce.info/2015/04/04/busuanzi/busuanzi_count: # count values only if the other configs are false enable: true # custom uv span for the whole site site_uv: true site_uv_header: 访客数 &lt;i class=&quot;fa fa-user&quot;&gt;&lt;/i&gt; site_uv_footer: 人次 # custom pv span for the whole site site_pv: true site_pv_header: 访问量 &lt;i class=&quot;fa fa-eye&quot;&gt;&lt;/i&gt; site_pv_footer: 次 # custom pv span for one page only page_pv: true page_pv_header: 阅读量 &lt;i class=&quot;fa fa-file-o&quot;&gt;&lt;/i&gt; page_pv_footer: 次 当 enable: true 时，代表开启全局开关。 当 site_uv: true 时，代表在页面底部显示站点的UV值。当 site_pv: true 时，代表在页面底部显示站点的PV值。当 page_pv: true 时，代表在文章页面的标题下显示该页面的PV值（阅读数）。 相关参考 不蒜子统计 显示文章更新时间在文章列表中我们一般都能看的文章的发布时间。对于一些文章来说，比如涉及到文章中的内容过期，或者软件的升级等等，我们都会进行一些修改。这种情况下，我们就像把文章的更新日期也显示处理，也能让读者看的我们写的之前的文章也是有更新的，不会过时的。 显示更新日期在 Next 主题下添加显示更新时间非常简单，找到主题下的配置文件 _config.yml 的 post_meta 部分： 123456# Post meta display settingspost_meta: item_text: true created_at: true updated_at: false categories: true 将 updated_at: false 修改为 updated_at: true 即可。 通过 hexo s -g 预览，可以看到已经自动添加上了更新日期。 自定义显示更新日期对于某些特殊的文章，我们也想能够自定义这个更新的日期。当然，更改起来也非常的简单，Hexo默认就支持更新日期的配置。 在每一篇文章的 Front-matter 部分，只要添加 updated 参数即可。 12345678910---title: 从0到1学Golang之基础--Go 数组date: 2017-05-24 22:07:58updated: 2017-12-01 10:35:18tags: - Golangcategories: - 从0到1学Golangdescription: Golang下的数组操作--- 这样我们就自定义了这篇文章的更新时间。 相关参考 Front-matter 添加文章字数统计一般为了让读者大概估计阅读文章的时间，有的文章在头部会显示总的字数统计。 启用字数统计首先安装一个依赖插件： 1npm i --save hexo-wordcount 然后修改主题配置文件 _config.yml 中的 post_wordcount 部分： 12345678# Post wordcount display settings# Dependencies: https://github.com/willin/hexo-wordcountpost_wordcount: item_text: true //底部是否显示“总字数”字样 wordcount: false //文章字数统计 min2read: false //文章预计阅读时长（分钟） totalcount: false //网站总字数，位于底部 separated_meta: true //是否将文章的字数统计信息换行显示 将 wordcount: false 改为 wordcount: true 即可显示单篇文章的总字数了。另外，totalcount 是用来统计整站总的字数的。 相关参考 hexo-wordcount 畅玩Hexo——2：骚起来吧，NexT]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[百度人工智能开放平台DuerOS初体验]]></title>
    <url>%2F2017%2F12%2F05%2Fthe-initial-experience-of-dueros-open-platform%2F</url>
    <content type="text"><![CDATA[今年11月初的时候在百度DuerOS开放平台上申请了DuerOS的“开发套件个人版”的开发板，前几天正式收到了该开发板，经过几天的摸索，发现DuerOS开放平台还是有很多可挖掘的功能的。在此将这几天的研究成果记录一下。 双十一的时候在天猫上买了一个阿里的天猫精灵，通过对比小米的小爱同学，阿里的天猫精灵，和百度的DuerOS开发板比起来，个人感觉DuerOS开发板要更贴近于开发者，可以让开发者自己动手去实现想要的智能化的功能。 DuerOS唤醒百度的DuerOS开发套件个人版需要用户自备一个树莓派3B来结合使用。开发板上带有2颗高灵敏度MEMS麦克风，搭载百度DuerOS SDK，可为用户提供百度海量的信息服务能力。 按照官方给的硬件安装文档和提供的镜像系统将设备组合成功，插入刷好系统的内存卡，通电等待系统开机。在初次连接时，可以使用百度提供的 “小度之家app” 将系统接入网络。 小度联网成功后，直接说 “小度小度+内容” 即可实现语音式的对话交互操作。 总体来说，唤醒小度的这一步非常的简单，附上一张设备的合影。 接入Python SDKDuerOS开发平台中也提供了相应的Python SDK，以便于个人开发者通过该SDK来实现想要的技能。 通过SSH登陆官方提供的DuerOS镜像系统是基于Raspbian系统的，所以我们可以按照在树莓派上安装Raspbian系统的方式来配置SSH服务。 为了找到树莓派的IP地址，我们可以使用 Fing 这个app来查看当前局域网上连接的所有设备。 然后通过SSH使用默认的用户名 pi 密码 raspberry 登陆DuerOS系统。我这里使用的是 Xshell，也可以选择 Putty 等其他软件。 在当前的用户目录下创建一个目录，用于后面的操作。比如我这里创建的目录名为 Leafney： 12$ mkdir Leafney$ cd Leafney 停止现有小度功能，因为会占用MIC资源12$ sudo systemctl disable duer$ sudo systemctl stop duer 安装需要的依赖更换地址源在操作之前，建议先更换地址源。因为DuerOS系统是基于 Raspbian jessie 版本的，操作如下： 1$ sudo vim /etc/apt/sources.list 把原来的第一行用#注释掉，在末尾添加下面一行： 1deb http://mirrors.aliyun.com/raspbian/raspbian/ jessie main contrib non-free rpi 还需要更改deb的源地址，这里可选择清华的源: 1deb https://mirrors.tuna.tsinghua.edu.cn/raspberrypi/ jessie main ui 或中科大的源： 1deb http://mirrors.ustc.edu.cn/archive.raspberrypi.org/debian/ jessie main ui 编辑以下文件添加:1$ sudo vim /etc/apt/sources.list.d/raspi.list update更新修改完成后，更新： 1$ sudo apt-get update 其他依赖包安装其他的依赖包： hyper库用来支持http2.0 client, pyaudio用来支持录音，tornado用来完成oauth认证。 12$ sudo apt-get install python-dateutil gir1.2-gstreamer-1.0 python-pyaudio libatlas-base-dev python-dev$ sudo pip install tornado hyper 下载编译好的openssl和Python安装包由于DuerOS运行所需要的依赖环境跟平台是相关的。比如DuerOS是基于Http2 ALPN的，但树莓派官方镜像的OpenSSL并不支持，而对应的Python库依赖于OpenSSL。为了在树莓派平台上支持Python的DuerOS SDK，专门交叉编译了OpenSSL和Python。 从如下地址下载openssl安装包(链接: https://pan.baidu.com/s/1skAP6WH 密码: wknz)从如下地址下载python2.7.14安装包(链接: https://pan.baidu.com/s/1o8MHkzK 密码: ngx4) 将下载的两个文件用 FileZilla 传输到树莓派的 /home/pi/Leafney 目录下： 然后分别解压： 1$ sudo tar -zxvf openssl1.1.tar.gz -C /usr 1$ sudo tar -zxvf python2.7.14.tar.gz -C /usr/local/ 替换已有的python： 12$ sudo rm -rf /usr/bin/python$ sudo ln -s /usr/local/python2.7.14/bin/python /usr/bin/python 下载Python SDK和示例代码123$ git clone https://github.com/MyDuerOS/DuerOS-Python-Client.git$ cd DuerOS-Python-Client$ git checkout raspberry-dev 初次授权如果直接按照官方给出的教程配置 Step by Step带你玩转DuerOS - Python DuerOS SDK[树莓派平台] (3)，下一步就是授权操作了。 1$ ./auth.sh 执行后在 Xshell 中有提示 A web page should is opened. If not, go to http://127.0.0.1:3000 to start 。 因为这里是要求访问 127.0.0.1 ，所以必须在树莓派系统中通过浏览器来访问。我在Windows系统下通过 树莓派IP+端口3000 的方式访问，会提示 “授权回调页地址错误” 的错误页面。 我并没有多余的HDMI数据线来直接连接树莓派和显示器，所以这里我用远程桌面的方式来配置。 安装远程桌面树莓派下的远程桌面我们选择 xrdp 或者 VNC 来实现。 xrdpxrdp 可以使用 windows下的远程桌面直接连接，不过这种方式只适合于Windows系统下连接。 在树莓派下执行安装： 1$ sudo apt-get install xrdp 打开windows系统的 “远程桌面连接” 程序，输入树莓派的IP地址进行连接。 在弹出的 Login to xrdp 窗口中，输入树莓派的用户名和密码，点击 OK 连接。 VNC如果你是MAC系统或者不喜欢Windows自带的远程桌面，可以使用适合于全平台的 VNC 。 VNC初始化在树莓派下执行安装： 1$ sudo apt-get install tightvncserver 增加一个桌面，执行： 1$ tightvncserver 会要求设置一个连接的密码并重复输入。 会询问是否设置一个只读方式的密码，一般选择否 n 。 连接从网站 vncViewer 下载vncViewer。打开程序后连接： 1234your Pi IP:1# 比如我的设置：192.168.5.130:1 关闭桌面关闭VNC桌面只需要在树莓派中将VNC的服务kill掉即可。在 Xshell 中操作： 1$ vncserver -kill :1 再次授权再次进入树莓派的 /home/pi/Leafney/DuerOS-Python-Client 目录，启动授权： 123$ cd /home/pi/Leafney/DuerOS-Python-Client$ ./auth.sh 通过远程桌面访问，在树莓派的桌面系统下打开浏览器，访问 127.0.0.1:3000 地址，会出现 “百度账号的登陆授权页面” 。 不过这个是官方的测试账号 GitHub项目测试账号。如果我们想要配置自己的设备，还是需要去申请自己的client_id和client_secret来调用。 这里我不在继续往下操作，先去申请自己的ClientID信息。 在 Xshell 中按 Ctrl+C 停止启动的web服务。 创建设备打开 DuerOS开放平台官网 DuerOS开放平台 ，选择右上角 “控制台” – “设备控制台” – 在打开的新页面选择 “配置新设备” 。 然后在 请选择终端场景 中选择 “音箱” 点击 “下一步” 。 在 请选择操作系统 界面选择第一项 “Linux” 或者也可以选择最下面的 “点击这里” ，没有太大区别。 输入 “产品名称”，比如这里我取名叫 贾维斯 （电影钢铁侠里的人工智能系统），点击 “申请ClientID” ，下面会显示出相应的 client_id 和 client_secret等信息。这里，我们先将这两项记下来以待后面使用。 接下来是配置 “端能力”的页面，可以自定义选择，或者直接保持默认下一步即可。 然后会弹出 BOT配置 页面。 ​可以看到上面是一些 音乐 有声点播 有声直播 等等选项；下面有 聊天定制 语音唤醒服务 自定义控制指令 这些，如果看不懂呢可以不用管，直接下一步。后面会询问是否下载SDK，也不用管，直接点击下面的 “完成” 会提示 “创建产品成功” 。 这样我们就创建好了自己的client_id和client_secret。 设置个人的ClientID信息使用 FileZilla 软件，在树莓派的目录 /home/pi/Leafney/DuerOS-Python-Client 下找到 app/auth.py 这个文件，因为在控制台界面下不太方便编辑文件，所以这里我选择将该文件下载到Windows本地来编辑。 将 auth.py 下载到本地后，推荐使用 SublimeText 或 NotePad++ 来进行编辑。 找到 开发者注册信息 部分，替换成刚刚申请的信息： 123# 开发者注册信息CLIENT_ID = &apos;XXXXX&apos;CLIENT_SECRET = &apos;XXXXXX&apos; 然后将下面的 使用开发者注册信息 一行下面代码段前面的井号 # 去掉，解注释这一行。 12# 使用开发者注册信息auth.auth_request(CLIENT_ID, CLIENT_SECRET) 再将下面的 使用默认的CLIENT_ID和CLIENT_SECRET 一行下面代码行前面加一个井号 # 注释掉这一行。 12# 使用默认的CLIENT_ID和CLIENT_SECRET# auth.auth_request() 然后使用 FileZilla 将我们刚刚改好的 auth.py 上传到树莓派中。 设置授权回调地址在浏览器中访问 控制台 – 设备控制台 页面 设备控制台 , 选择我们刚刚创建的产品点击 “编辑” 选项。 在 基础信息 页面，可以查看刚刚创建设备的 client_id 等信息。这里我们点击 OAUTH CONFIG URL 这个链接： 在新页面的左侧点击 安全设置 选项，在 授权回调页 的输入框中输入如下内容，然后点击 确定 保存修改。 1http://127.0.0.1:3000/authresponse 使用个人设备授权完成上面的配置后，回到 Xshell 中，在树莓派的 /home/pi/Leafney/DuerOS-Python-Client 目录下，再次执行授权命令： 12$ ./auth.shA web page should is opened. If not, go to http://127.0.0.1:3000 to start 然后在树莓派系统浏览器输入 127.0.0.1:3000 访问。 可以看到页面右侧的授权应用变成了我自己创建的设备名称。 如果你的授权页面中这里显示的是空的，那是因为你用的是中文名称。在“基础信息” 的 “名称”那里需要再次添加一下名称。如果是英文的话，这个名称会直接显示。我觉得这里可能是一个bug。 ​在授权页面输入我的百度账号和密码进行授权。 看到提示 Succeed to login DuerOS Voice Service 的信息就说明授权成功了。 同时在 Xshell 下我们会看到输出相应的授权信息。 语言唤醒执行如下命令： 1$ ./wakeup_trigger_start.sh 使用唤醒词 小度小度 就能唤醒了。 因为我在 Xshell 下操作时发现命令行下的中文会有乱码的情况，所以我改用远程桌面下树莓派上自带的 Terminal 程序来执行。 也可以使用enter按键唤醒，执行命令： 1$ ./enter_trigger_start.sh 使用enter键回车唤醒。 这里我尝试了上面的两种唤醒方式，发现不知道是哪里的问题，音箱都没有声音输出。查看输出的日志信息是能看到有音频文件下载成功并播放的。 解决没有声音的问题我使用 alsamixer 然后按 F6 切换使用的声卡，发现无论如何切换，似乎都没有效果。 后来我考虑将音箱线换到树莓派本身的音频接口上，发现居然有声音输出了。不过树莓派自带的音频输出杂音还是很吵的。 这里要注意的是不能在树莓派通电的情况下切换音频口，我发现如果直接将音频线从DuerOS板子的音频口换到树莓派的音频口上时，刚一接触的时候噪音是非常大的，所以最后我是将树莓派关机然后切换的。 感受 使用Python SDK 最后唤醒的时候需要将音频接口插到树莓派的音频接口上，这一点在论坛的文档中没有说明，可能会给一些人操作时带来困惑。 个人认为应该是有方法使用DuerOS开发版的音频接口的，毕竟没有杂音嘛。需要进一步研究一下。 发现在使用 Python SDK 唤醒小度时，语言识别的效果不如镜像系统中语音的识别准确度高。]]></content>
      <categories>
        <category>DuerOS开放平台</category>
      </categories>
      <tags>
        <tag>DuerOS</tag>
        <tag>智能家居</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Hexo博客搜索异常]]></title>
    <url>%2F2017%2F11%2F24%2Fresolve-hexo-blog-search-exception%2F</url>
    <content type="text"><![CDATA[最近在更新博客文章时发现之前新添加的搜索功能不太好用了。每次点击了搜索按钮之后，搜索弹框一直显示 “加载中” 的状态。 尝试因为我使用的是 hexo 的 Next 主题中的 Local Search 搜索功能，所以就去 Next 主题的github中查找了类似的 issues ，发现类似问题下作者是建议重新安装该搜索组件来解决的。 于是我就卸载了该组件，然后重新安装： 123$ npm uninstall hexo-generator-searchdb --save$ npm install hexo-generator-searchdb --save 结果问题依旧。 探究后来我发现 Local Search 的搜索功能是加载的项目目录下的 search.xml 文件：http://localhost:4000/search.xml。于是我在浏览器中打开，居然有报错提示。 按照错误信息的说明，我找到了出错的第 47 行第 35 列，发现和其他内容不同的是这里居然多了一个 “红点”，那么搜索弹窗出不来的问题应该就是这个 “红点” 搞的鬼了。 我通过 Sublime Text 打开了源博客文件，发现在段落的开头居然多了两个奇葩的字符：BS。 我觉得可能是什么时候复制文件时给加上的。删除后，再次生成。问题解决。 再次访问搜索的xml文件 http://localhost:4000/search.xml ，发现已经不会再报之前的错误了。 需要注意的一点：我在查看源博客文件时也使用了 VS Code 编辑器，但是 VS Code 却无法显示出来前面的特殊字符 BS，通过 Sublime Text 才查看到。 扩展在Hexo博客文件的项目目录下有一个 node_modules 目录。每次在windows系统下删除 (拷贝或者移动) 该目录时都会报 文件名或扩展名太长，目录层次超过限制 等错误而导致操作失败。 解决这个问题只需要使用 unix 或者 linux 下的 rm -rf（强制删除） 命令来删除即可，但要注意操作时一定要慎重，不要误删其他文件。 在 node_modules 文件夹所在目录下右键打开 Git Bash 窗口，执行： 1$ rm -rf ./node_modules/ 等待完成，即可。 相关参考 how to uninstall npm modules in node js? windows删除node_modules[文件名或扩展名太长，目录层次超过无法删除的问题]]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--下载神器aria2]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-docker-aria2%2F</url>
    <content type="text"><![CDATA[上一篇文章说了如何配置Docker加速器，现在下载Docker镜像文件已经非常的快了。但是对于其他的一些文件比如电影、程序文件等来说，如何在NAS中来快速的下载呢？ 虽然群晖中已经自带了下载套件，不过看到那个界面我就有种不想用的感觉。这里推荐一个开源的下载神器 – aria2，号称迅雷的替代者。 这里我还选择在Docker中来配置，选择的镜像为我之前创建的 leafney/debian-aria2-kode 镜像。该镜像自带了 aria2下载程序、ariaNg管理页面以及KodExplorer文件管理页面。 具体可以访问：Leafney/debian-aria2-kode 创建aria2容器打开群晖的docker套件，选择 “注册表” 项，搜索并下载镜像 leafney/debian-aria2-kode 。 下载完成后，选中该镜像，点击 “启动” 菜单，打开 “创建容器” 界面。 为该容器设置一个自定义的名称，我这里命名为 aria2-kode，然后打开 “高级设置” 窗口。 在 “高级设置” 选项卡，选中 “启用自动重新启动” 及 “创建桌面快捷方式” 。 自动重新启动是在容器不当关机的情况下回尝试自动重启的操作。 在 “卷” 菜单中，为创建的容器添加一个文件夹用来管理和查看我们通过aria2下载的文件。因为要存储新文件，所以这里不要勾选 “只读” 项。 在 “端口设置” 菜单中，已经列出了镜像中预设的端口信息，在 “本地端口” 项下，我们为其指定相应的端口，不选择默认的 “自动” 。 然后点击 “应用” 按钮。 回到 “创建容器” 界面，点击 “下一步” 。查看我们设置的容器信息，勾选左下角的 “向导完成后运行此容器” 项，然后点击 “应用” 等待容器启动。 查看容器信息选择左侧 “容器” 项，可以看到我们刚刚创建的容器已经启动了。 点击顶部的 “详情” 选项，可以查看容器 aria2-kode 的信息。 在 “日志” 项下，可以查看当前容器运行时输出的日志记录。 配置KodExplorer在浏览器中输入 群晖ip:6860 ，打开 KodExplorer 的登录界面。看到 “运行环境检测” 下输出 “Successful!” 说明我们的容器已经正常的跑起来了。 首先要设置 KodExplorer 资源管理器的管理员 admin 的密码。 然后使用管理员账号登录。登录后可以看到 KodExplorer 的文件管理页面和我们平时使用的资源管理器页面非常的相似，操作起来也没有什么难度。 配置aria2在浏览器中输入 群晖ip:6801 ,打开 AriaNg 的管理页面。进入后会弹出 “认证失败” 的错误弹窗，不用管它。 选择左侧 “系统设置” 下的 “AriaNg 设置” 项。在右侧选择 “RPC(192.168.x.xx…” 的菜单，然后配置之前创建容器时设置的 “Aria2 RPC 地址” 端口号和 “Aria2 RPC 密钥” 项。 RPC密钥默认是 123456 。设置完成后点击 “重新加载页面” 应用配置。 然后可以看到 Aria2 状态 已经显示为 “已连接” 的状态了。 至此，aria2就配置完成了。选择左侧的 “正在下载” 项新建下载任务即可。 管理下载文件这里我以下载 BaiduExporter 为例来示范如何管理下载的文件。 BaiduExporter 下载文件打开 BaiduExporter 的github页面，在master分支下，选择右侧的 Clone or download 项下的 Download Zip ，右击选择 “复制链接地址” 。 打开 “AriaNg” 页面，在 “正在下载” 页面 “新建” 下载任务。粘贴下载链接，点击 “立即下载” 开始。 下载完成后，会在 “已完成/已停止” 菜单中显示。 KodExplorer文件管理要查看我们刚刚下载的文件，在浏览器打开 KodExplorer 页面，选择上面的目录路径，点击根目录项，查看所有的文件及目录。 找到 app 目录，打开里面的 aria2down 目录即可查看到我们刚刚下载的文件了。 在群晖DSM中查看下载文件在创建容器时我们为容器指定了群晖本地的下载文件目录。打开群晖DSM界面 – “File Station” 文件管理器，找到我们设置的目录，可以看到容器为我们自动创建了三个目录，在 aria2down 下就能找到我们刚刚下载的文件了。 百度网盘文件下载知道了如何下载和如何管理文件，接下来我们看看具体的应用。因为之前网盘刚兴起的时候，我把大部分的文件都放在到了百度网盘里，但后来网盘逐渐衰落，百度网盘的客户端下载文件还会限速，除非你冲超级会员才行。 今天，我们就用aria2来解决这个问题。 安装插件想要下载百度网盘中的文件，首先需要安装一个插件，也就是上面我们已经下载的 BaiduExporter。 在 KodExplorer 管理界面或群晖的 DSM 界面，选中文件 BaiduExporter-master.zip 右击选择下载均可将该文件下载到当前电脑上，解压后看到一个名为 BaiduExporter.crx 的文件。 打开 Chrome 浏览器 – “更多工具” – “扩展程序” 界面。将 BaiduExporter.crx 拖放到该页面以安装。 打开百度网盘页面，在顶部菜单栏中可以看到多出了一项 “导出下载” 的按钮。 设置ARIA2 RPC仍在百度网盘页面，选择菜单 “导出下载” – “设置” 项，在 ARIA2 RPC 右侧输入RPC地址，格式为 ：http://192.168.5.120:6800/jsonrpc 。 因为我的aria2是添加了密钥的，所以最后的rpc地址格式应为：http://token:RPC密钥@192.168.5.120:6800/jsonrpc ，即 设置密码以后需要在导出下面的设置里在 JSONRPC 的地址的 http:// 后面 localhost 前面加上 token:你的密码@。 下载点击应用后，勾选百度网盘中要下载的文件或文件夹，选择 “导出下载” 菜单下的 “ARIA2 RPC”，会弹出 “下载成功，赶紧去看看吧！” 的提示信息。切换到 AriaNg 页面，我们可以看到在百度网盘上选择的文件已经在依次下载了。 另外在 KodExplorer 和群晖DSM的资源管理界面，都可以看到正在下载的文件。 注意这里发现一个问题：如果在 Mac10.13 系统上使用release下的 v0.8.5 的版本在百度网盘页面选中文件后，“导出下载” 的按钮就消失了。更新成当前的master版本 v0.9.10 后没有问题。所以上面直接推荐安装master版本。 具体可以看 github issues：mac os 10.13 无法使用了 相关参考 Aria2c那边设置rpc-secret后，chrome里的aria按钮点击后就不能无法下载了，报：是不是没有启动aria2]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--Docker加速]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-docker-accelerator%2F</url>
    <content type="text"><![CDATA[群晖的DSM系统上安装Docker套件非常的简单，只要点击一个按钮就行了。 但是由于某些 “你懂的” 原因，DockerHub的网站是在国外的，而在国内访问起来就会特别的慢。之前我也写过在其他Linux系统如Ubuntu下配置Docker加速器的方法，但经过一番研究发现群晖NAS下的Docker套件配置加速器的方法还是有一定区别的。 启用Docker套件进入群晖的 DSM 系统后，选择桌面的 “套件中心” 图标（或在 “主菜单” 界面中选择 “套件中心”），在左侧找到 “实用工具” 一项，右侧往下拉在 “第三方” 一栏下找到 “Docker” 的图标，点击 “安装套件” ，等待安装完成。 安装完成后，选择 “主菜单” 找到 “Docker” 图标并打开。 具体的操作可以查看 DSM 的帮助界面，这里主要说明重点的项： 总览 能看到当前群晖的 “CPU 使用率” 和 “内存使用率” 以及正在运行的 Docker 容器。 注册表 对应于 Docker 来说就是“Docker Hub”。我们可以在这里搜索以及下载镜像。 映像 对应于 Docker 来说就是“镜像”，用来管理镜像，创建容器等操作。 容器 是对创建的容器进行管理。 未启用加速器要在Docker套件中创建容器，我们可以在左侧菜单 “注册表” 项搜索相应的镜像名称，双击下载。但是我们发现下载中的镜像右侧的下载图标在一段时间之内一直显示 “0 B” 的情况，然后就自动消失了。 同时在 “映像” 中也会提示 “您未下载任何映像，请进入注册表选项卡以下载。”： 一连试过几次，都是下载中途镜像就自动消失了。 启用SSH要配置Docker的配置文件，还得需要在命令行下来操作。群晖NAS默认没有开启SSH功能，得需要我们先开启才行。 打开 “控制面板” 图标，选择 “应用程序” – “终端机和SNMP” – 勾选 “启用 SSH 功能” 。端口可以选择默认或自定义，然后点击应用。 启用用户主目录服务这时如果你以任何用户身份通过终端使用SSH方式访问NAS的ip地址，登陆后一般会看到一条警告提示： 1Could not chdir to home directory /var/services/homes/tiger: No such file or directory 发生此警告是因为主目录由DSM的“用户主目录服务”控制，默认情况下该主目录服务是禁用的。要防止错误，请通过选中 “控制面板” – “用户账户”菜单 – “高级设置”选项卡 – “家目录”组 – “启用家目录服务” 复选框来启用用户主目录服务。 这样再次尝试登陆，会看到警告信息没有了。 即使您不打算使用该家目录，但还是建议您选择启用用户主目录服务，以防影响其他某些程序的运行。 临时性Docker加速如果是临时性的想要 “加速” 下载镜像，可以选择通过命令的方式，执行 docker pull 时加入国内源地址，格式为： 1$ docker pull registry.docker-cn.com/myname/myrepo:mytag 例如: 1$ docker pull registry.docker-cn.com/library/ubuntu:16.04 虽然能实现加速效果，但是对于在群晖NAS中操作Docker来说，每次下载镜像都要先去登陆SSH，在命令行中下载好了镜像再回到 DSM 界面来操作，这样的流程未免有些太繁琐了。 配置Docker加速器我们可以通过配置 Docker 守护进程默认使用 Docker 官方镜像加速。 查看群晖下Docker版本这里我使用 admin 账号通过SSH登陆到群晖的命令模式下来操作。 使用命令 docker info 查看docker详细信息： 如果提示 Cannot connect to the Docker daemon. Is the docker daemon running on this host? 说明当前的账号没有 root 权限，可以使用 sudo 提权来操作，或者可以通过切换到 root 账户下来操作，这里我们选择后者。 通过 admin 账号登录后，执行 sudo su - 切换到 root 账户下(注意这一步输入的是admin账号的密码)： 示例命令如下： 12345678910111213141516171819202122232425262728293031323334admin@HomeNAS:/etc$ docker infoCannot connect to the Docker daemon. Is the docker daemon running on this host?admin@HomeNAS:~$ sudo su -Password: # 注意这一步输入的是admin账号的密码root@HomeNAS:~# docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 1.11.2Storage Driver: btrfsLogging Driver: dbCgroup Driver: cgroupfsPlugins: Volume: local Network: host bridge nullKernel Version: 4.4.15+Operating System: &lt;unknown&gt;OSType: linuxArchitecture: x86_64CPUs: 2Total Memory: 1.801 GiBName: HomeNASID: A3DQ:M62X:NLZP:RYMF:NINR:5QBY:7OIJ:L425:3WDR:4V2N:FEFL:OV42Docker Root Dir: /volume1/@dockerDebug mode (client): falseDebug mode (server): falseRegistry: https://index.docker.io/v1/WARNING: No kernel memory limit supportWARNING: No cpu cfs quota supportWARNING: No cpu cfs period supportWARNING: bridge-nf-call-iptables is disabledWARNING: bridge-nf-call-ip6tables is disabled 我们可以看到 Server Version 目前版本是 1.11.2 的。 要退出 root 账户模式，执行 exit 即可： 123root@HomeNAS:~# exitlogoutadmin@HomeNAS:~$ 配置加速器这里我选择使用阿里云的镜像加速器。打开阿里云的 开发者平台 , 选择 “管理中心” – “镜像加速器” ，可以看到 “您的专属加速器地址” 。 而且下面也给出了具体的操作方法。 通过上一步我们看到群晖下的 Docker 版本是大于 1.10.0 的，按照文档我们可以通过修改daemon配置文件 /etc/docker/daemon.json 来使用加速器。 但是，这里一定要说但是，文档中的方法是对应于在 Ubuntu 等Linux系统下通过 Docker 官方的安装方式安装的Docker而言的，对于群晖下的Docker来说，并不是这样的。 通过查找我发现群晖中Docker的配置文件地址在 /var/packages/Docker/etc/dockerd.json 下， 使用vim编辑： 1root@HomeNAS:~# vim /var/packages/Docker/etc/dockerd.json 可以看到内容如下： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: []&#125; 然后将从阿里云获得的加速器地址填入 registry-mirrors 部分即可： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: [&quot;https://xxxxxx.mirror.aliyuncs.com&quot;]&#125; 注意：网址要用英文的双引号引起来再添加到中括号中。 当然，也可以使用其他的加速器地址。比如使用Docker中国官方镜像的加速地址： 1234&#123; &quot;ipv6&quot;: true, &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;]&#125; 然后需要重启群晖下的Docker服务。 重启群晖下的Docker服务上面也说到，群晖的DSM系统并不像其他的linux系统如 Ubuntu 那样，管理服务可以使用 systemctl(Ubuntu16.04后版本) 或 service 来操作: 12345root@HomeNAS:~# systemctl-ash: systemctl: command not foundroot@HomeNAS:~# service-ash: service: command not foundroot@HomeNAS:~# 可以看到这两个命令在群晖下都是找不到的。 那是因为在群晖下的操作命令都要加上 syno 前缀来操作，执行命令 synoservice 或 synoservice --help： 123456789101112131415161718192021222324252627root@HomeNAS:~# synoserviceCopyright (c) 2003-2017 Synology Inc. All rights reserved.SynoService Tool Help (Version 15217)Usage: synoservice --help Show this help --help-dev More specialty functions for deveplopment --is-enabled [ServiceName] Check if the service is enabled --status [ServiceName] Get the status of specified services --enable [ServiceName] Set runkey to yes and start the service (alias to --start) --disable [ServiceName] Set runkey to no and stop the service (alias to --stop) --hard-enable [ServiceName] Set runkey to yes and start the service and its dependency (alias to --hard-start) --hard-disable [ServiceName] Set runkey to no and stop the service and its dependency (alias to --hard-stop) --restart [ServiceName] Restart the given service --reload [ServiceName] Reload the given service --pause [ServiceName] Pause the given service --resume [ServiceName] Resume the given service --pause-by-reason [ServiceName] [Reason] Pause the service by given reason --resume-by-reason [ServiceName] [Reason] Resume the service by given reason --pause-all (-p) [Reason] (Event) Pause all service by given reason with optional event(use -p to include packages) --pause-all-no-action (-p) [Reason] (Event) Set all service runkey to no but leave the current service status(use -p to include packages) --resume-all (-p) [Reason] Resume all service by given reason(use -p to include packages) --reload-by-type [type] (buffer) Reload services with specified type --restart-by-type [type] (buffer) Restart services with specified type Type may be &#123;file_protocol|application&#125; Sleep $buffer seconds before exec the command (default is 0)root@HomeNAS:~# 好的，现在已经知道了如何在群晖下管理服务，那么按照步骤，下一步只需要重启Docker服务使其应用上加速器地址即可。 按照上面的规律可想而知，在群晖下Docker的守护进程服务名称肯定会和在 Ubuntu 下的名称不一样，那我们如何来找到呢？ 可以通过 synoservicecfg --list 命令来查看当前群晖系统下所有运行的服务： 1234567891011121314151617root@HomeNAS:~# synoservicecfg --listDSMapparmoratalkavahibluetoothdbonjour......pkgctl-Dockerpkgctl-FileStationpkgctl-LogCenterpkgctl-PDFViewerpkgctl-PHP7.0pkgctl-PhotoStation...... 可以看到通过群晖的 “套件中心” 添加的套件程序的服务名称均以 pkgctl- 为前缀来命名。 然后重启群晖的docker服务： 12root@HomeNAS:~# synoservice --restart pkgctl-Dockerroot@HomeNAS:~# 如果没有错误提示，说明docker服务重启正常。 现在我们再次回到 DSM 操作界面中，重新下载我们需要的Docker镜像即可。 可以看到现在后面的容量大小一直在增加，很快我们就看到 “消息通知” 里提示我们镜像下载完成了。 后面就是通过镜像来创建容器了，后文继续。 相关参考 Synology DSM 6 (terminal) service control restart WebServer bash command Documentation for /var/packages/Docker/etc config files? Docker 中国官方镜像加速]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转群晖NAS--开篇]]></title>
    <url>%2F2017%2F11%2F17%2Fplaying-synology-nas-of-start%2F</url>
    <content type="text"><![CDATA[双十一的时候在天猫上入手了一台群晖的 DS218+ NAS主机，也算是很早就打算入手的一台设备。再加上去年双十一的时候在京东购置的两个4T的硬盘，就开始了我的玩转群晖NAS之旅。 对于开篇文章呢，也不想说太多吧，主要就是作为一个 “玩转群晖NAS” 系列的目录来展示，同时也算是时刻的提醒自己还是要多写写笔记的。 对于群晖的“+”系列NAS，最值得把玩的一个功能就是支持的Docker套件了。Docker简直就是一个 “神器”。至于有多么神，尽管看我后面的文章吧！ 目录 玩转群晖NAS–开篇 玩转群晖NAS–Docker加速 玩转群晖NAS–下载神器aria2]]></content>
      <categories>
        <category>玩转群晖NAS</category>
      </categories>
      <tags>
        <tag>SynologyNAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过路由器找回忘记的宽带密码]]></title>
    <url>%2F2017%2F11%2F13%2Fretrieve-forgotten-broadband-passwords-through-routers%2F</url>
    <content type="text"><![CDATA[可能是因为赶上了双十一的缘故,最近我的宽带网络总是时好时坏的,给宽带客服打了电话,说会找师傅过来给我看看.突然间想起来好像我的宽带自从安装上以后,我就没再改动过,怎么也想不起来宽带的密码了.账号的话可以在路由器中直接看到,而密码却是显示成星号,还不能复制出来. 所以特意上网找了找方法,记录于此. 备份路由器配置我的路由器是 TP-Link WR847N 型号的，其他路由器的方法类似。 第一步：在浏览器输入路由器网关地址（一般是192.168.1.1）进入路由器登录界面 第二步：输入路由器账号和密码登录（如果未更改过一般都是admin）到路由器管理界面 第三步：在左菜单栏点击 “系统工具” – “备份和载入配置” 第四步：在右侧对话框中点击 “备份配置文件” 按钮 第五步：保存配置文件，名称为 config.bin 。 通过配置文件找回第六步：从网站 RouterPassView 下载软件RouterPassView。 RouterPassView 是 NirSoft 出品的一款路由密码恢复软件，可以查看绝大多数家用路由的配置文件中保存的密码。 第七步：用 RouterPassView打开备份的配置文件 config.bin, 就能看到当前路由器上已配置的所有账号和密码了。 附件百度网盘链接: Download 密码: hwpx]]></content>
      <tags>
        <tag>Skill</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[红米Note4X高通版升级MIUI9]]></title>
    <url>%2F2017%2F11%2F12%2FRedmiNote4X-HP-version-upgrade-miui9%2F</url>
    <content type="text"><![CDATA[双十一当天在京东上买了一个红米Note4X高通版的手机,收到货后发现系统仍然是MIUI8的稳定版.之前看过MIUI9的介绍视频,官方给出的标语是”快如闪电”,所以就想体验一把.我的方法是采用 卡刷 的方式，不需要BL解锁。 当前系统版本在手机的”设置”–”我的设备” 下查看当前的MIUI版本: 1MIUI 8.5 稳定版 8.5.6.0(MCFCNED) 先从稳定版升级开发版不能直接刷最新版因为小米Note4x稳定版8.5的系统是基于Android6.0开发的，而最新的MIUI9是基于Android7.0开发的，Android版本不一致也就导致无法直接卡刷到最新版，会报错。 可行的方法是可以先卡刷MIUI8 7.4.6 的开发版（基于Android6.0），然后再刷MIUI9最新的开发版。 卡刷Android6.0开发版下载 7.4.6 开发版卡刷包,然后拷贝到手机的内置存储中。 在手机端选择 设置 – 我的设备 – MIUI版本 – 进入 “系统升级” 界面 点击 右上角三点 ，选择 手动选择安装包 选择刚刚下载的卡刷包，确定。等待其解密并自动升级。 升级完成后，在 设置 – 我的设备 – MIUI版本 – 进入 “系统升级” 界面 这时如果点击 “检查更新” 的话，收到的应该是MIUI8的最新开发版的更新包,所以这里不点击“立即更新”。(MIUI论坛中官方给出的说法是现在MIUI8开发版可以直接自动检查升级到MIUI9的最新开发版了,不知道我这里为什么不行?如果你的可以,那就直接升级即可,否则继续下面的操作) 卡刷MIUI9最新开发版从网址 http://www.miui.com/download-326.html 下载 红米Note4X(高通平台) 的最新开发版的完整卡刷包，然后拷贝到手机中，依照上一步的操作方法通过 手动更新 的方式来升级。 我这里下载到的是当前的最新版本 MIUI9开发版 7.11.9 的版本 : miui_HMNote4X_7.11.9_71db0b04ec_7.0.zip 。 等待其解密安装包并自动更新完成即可。 上面的整个升级过程要保证手机电量充足,按照步骤操作即可,非常适合小白升级. 附件百度网盘 Download 密码: d2v7 MIUI8(Android6.0)_7.4.6.zip MIUI9(Android7.0)_7.11.9.zip]]></content>
      <tags>
        <tag>XiaoMI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客添加搜索功能]]></title>
    <url>%2F2017%2F10%2F27%2Fadd-search-function-to-hexo-blog%2F</url>
    <content type="text"><![CDATA[渐渐的随着hexo博客中文章越来越多了之后,平时想要查找一篇文章时,一般都是记得部分标题内容或者某些关键词,而在”归档”下通过标题一页一页的找又非常的麻烦.所以考虑为博客增加搜索功能. 从Next主题网站上我们可以搜索多款搜索插件 第三方服务集成 – Next文档,个人感觉 “Local Search” 和 “Algolia” 这两款搜索插件比较和我的心意. 下面简要的介绍为hexo博客添加搜索插件的过程. 升级Next主题版本我的hexo主题安装的是 Next 主题,当前版本为 v5.0.1 .最新版本为 5.1.3. 因为我的hexo主题版本差距太大,而且我在 next 主题目录下的 .git 目录我已经删除了,所以我采用完全更新的方式. 先备份本地的 hexo 主题目录 your-hexo-site/themes/next ,其实只需要备份 _config.yml 一个文件即可,为了保险这里我将整个目录都备份一下. 另外还要注意如果你之前添加了自定义头像及打赏功能等所需图片,添加的图片是在 /themes/next/source/images/ 目录下的,也要记得做好备份. 如果你本地的主题 next 目录下的 .git 目录没有删除,你可以直接通过 git pull 命令来更新: 12$ cd themes/next$ git pull 完全更新先删除本地现在的 next 主题目录: 12$ cd &lt;your-hexo-site&gt;$ rm -rf ./themes/next 从github下载 hexo 主题文件最新版本: 12$ cd &lt;your-hexo-site&gt;$ git clone https://github.com/iissnan/hexo-theme-next themes/next 比照新的主题配置文件 _config.yml ,将旧的主题文件中的内容添加到新文件中. 我这里更改的地方有: menu scheme social sidebar highlight_theme tencent_analytics 打赏功能 reward_comment wechatpay alipay 站点建立时间 since 更改后,清除缓存,然后再查看: 12345$ hexo clean$ hexo s -gINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 打开浏览器,查看页面中是否有错误并修改. LocalSearch搜索安装 hexo-generator-searchdb，在站点的根目录下执行以下命令： 1$ npm install hexo-generator-searchdb --save 编辑 站点配置文件，新增以下内容到任意位置： 12345search: path: search.xml field: post format: html limit: 10000 编辑 主题配置文件，启用本地搜索功能： 123# Local searchlocal_search: enable: true 然后 重新生成 查看: 12345$ hexo clean$ hexo s -gINFO Start processingINFO Hexo is running at http://localhost:4000/. Press Ctrl+C to stop. 这样,搜索功能就添加上了. Algolia搜索详情可参考官方教程,这里不再详述. Algolia – Next文档 相关链接 搜索服务 – Next文档 hexo-generator-search hexo-algoliasearch Hexo集成Algolia搜索插件]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mac系统下配置Hexo博客运行环境遇到的问题]]></title>
    <url>%2F2017%2F10%2F27%2Fproblems-for-configuring-hexo-blog-in-mac%2F</url>
    <content type="text"><![CDATA[今天在Mac下更新hexo博客时,遇到了一些安装 Node.js 和安装 hexo 相关的小问题,特此记录下来. Mac下配置Node.js环境安装 node.js 有多种方法：使用 homebrew 安装或者直接下载 安装包。 官网下载安装包从node.js官网 Node.js 下载对应系统的安装包,打开会提示安装位置: 123This package will install: • Node.js v8.8.1 to /usr/local/bin/node • npm v5.4.2 to /usr/local/bin/npm 按照步骤安装即可. homebrew安装通过 homebrew 安装,直接执行如下命令: 1$ brew install node 检测安装是否成功终端输入 -v , 成功则显示版本号: 12345$ node -vv8.8.1$ npm -v5.4.2$ Mac系统下Finder显示隐藏文件涉及到一些以 . 开头的文件或目录(如.git目录)或者隐藏文件,默认在Finder下是看不到的. 我们可以通过命令 Command+Shift+. 来在Finder中快速的切换显示出隐藏的文件或文件夹,再按一次,恢复隐藏. 更换Node.js镜像源由于npm的官方镜像源在国外,而由于国内”众所周知的”的网络原因,访问默认的官方镜像源常常会出问题.我们可以更改为国内的镜像源来加速软件的安装. 淘宝npm镜像目前国内推荐的是淘宝的npm镜像: 搜索地址：http://npm.taobao.org/ registry地址：http://registry.npm.taobao.org/ 如何使用临时使用以下载 express 软件为例: 1npm --registry https://registry.npm.taobao.org install express 持久使用1npm config set registry https://registry.npm.taobao.org 配置后可通过下面方式来查看是否设置成功: 1npm config get registry 我的操作记录: 123456$ npm config get registryhttps://registry.npmjs.org/$ npm config set registry https://registry.npm.taobao.org$ npm config get registryhttps://registry.npm.taobao.org/$ 提醒 : 我在实际操作时发现淘宝的npm镜像源有时候也会请求失败,然后又切换回了官方源(npm config set registry https://registry.npmjs.org/)发现能够操作成功了.所以是否更换镜像源还要根据实际情况来定. 123456789101112131415161718192021222324252627282930313233343536373839$ npm config get registryhttps://registry.npm.taobao.org/$ npm installnpm ERR! code ENOTFOUNDnpm ERR! errno ENOTFOUNDnpm ERR! network request to https://registry.npm.taobao.org/hexo-generator-category failed, reason: getaddrinfo ENOTFOUND registry.npm.taobao.org registry.npm.taobao.org:443npm ERR! network This is a problem related to network connectivity.npm ERR! network In most cases you are behind a proxy or have bad network settings.npm ERR! networknpm ERR! network If you are behind a proxy, please make sure that thenpm ERR! network &apos;proxy&apos; config is set properly. See: &apos;npm help config&apos;npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-26T14_59_23_770Z-debug.log$ $ $ npm config set registry https://registry.npmjs.org/$ npm installnpm WARN deprecated swig@1.4.2: This package is no longer maintained&gt; dtrace-provider@0.8.5 install /Users/xxx/Project17/Leafney.github.io/node_modules/dtrace-provider&gt; node scripts/install.js&gt; fsevents@1.1.2 install /Users/xxx/Project17/Leafney.github.io/node_modules/fsevents&gt; node install[fsevents] Success: &quot;/Users/xxx/Project17/Leafney.github.io/node_modules/fsevents/lib/binding/Release/node-v57-darwin-x64/fse.node&quot; already installedPass --update-binary to reinstall or --build-from-source to recompile&gt; hexo-util@0.6.1 postinstall /Users/xxx/Project17/Leafney.github.io/node_modules/hexo-util&gt; npm run build:highlight&gt; hexo-util@0.6.1 build:highlight /Users/xxx/Project17/Leafney.github.io/node_modules/hexo-util&gt; node scripts/build_highlight_alias.js &gt; highlight_alias.jsonnpm notice created a lockfile as package-lock.json. You should commit this file.added 430 packages in 119.035s Mac install hexo use sudo but sitll permission denied安装报错参照hexo官网 Hexo 安装hexo时,使用命令 npm install hexo-cli -g 却报没有权限: 123456789101112131415161718$ npm install hexo-cli -gnpm WARN checkPermissions Missing write access to /usr/local/lib/node_modulesnpm ERR! path /usr/local/lib/node_modulesnpm ERR! code EACCESnpm ERR! errno -13npm ERR! syscall accessnpm ERR! Error: EACCES: permission denied, access &apos;/usr/local/lib/node_modules&apos;npm ERR! &#123; Error: EACCES: permission denied, access &apos;/usr/local/lib/node_modules&apos;npm ERR! stack: &apos;Error: EACCES: permission denied, access \&apos;/usr/local/lib/node_modules\&apos;&apos;,npm ERR! errno: -13,npm ERR! code: &apos;EACCES&apos;,npm ERR! syscall: &apos;access&apos;,npm ERR! path: &apos;/usr/local/lib/node_modules&apos; &#125;npm ERR!npm ERR! Please try running this command again as root/Administrator.npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-27T01_21_01_871Z-debug.log 然后我换用管理员权限,加上 sudo ,执行如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465$ sudo npm install hexo-cli -gPassword:/usr/local/bin/hexo -&gt; /usr/local/lib/node_modules/hexo-cli/bin/hexo&gt; dtrace-provider@0.8.5 install /usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider&gt; node scripts/install.jsfs.js:768 return binding.rename(pathModule._makeLong(oldPath), ^Error: EACCES: permission denied, rename &apos;/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/compile.py&apos; -&gt; &apos;/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/binding.gyp&apos; at Object.fs.renameSync (fs.js:768:18) at Object.&lt;anonymous&gt; (/usr/local/lib/node_modules/hexo-cli/node_modules/dtrace-provider/scripts/install.js:14:4) at Module._compile (module.js:612:30) at Object.Module._extensions..js (module.js:623:10) at Module.load (module.js:531:32) at tryModuleLoad (module.js:494:12) at Function.Module._load (module.js:486:3) at Function.Module.runMain (module.js:653:10) at startup (bootstrap_node.js:187:16) at bootstrap_node.js:608:3&gt; fsevents@1.1.2 install /usr/local/lib/node_modules/hexo-cli/node_modules/fsevents&gt; node install[fsevents] Success: &quot;/usr/local/lib/node_modules/hexo-cli/node_modules/fsevents/lib/binding/Release/node-v57-darwin-x64/fse.node&quot; already installedPass --update-binary to reinstall or --build-from-source to recompile&gt; hexo-util@0.6.1 postinstall /usr/local/lib/node_modules/hexo-cli/node_modules/hexo-util&gt; npm run build:highlight&gt; hexo-util@0.6.1 build:highlight /usr/local/lib/node_modules/hexo-cli/node_modules/hexo-util&gt; node scripts/build_highlight_alias.js &gt; highlight_alias.jsonsh: highlight_alias.json: Permission deniednpm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! hexo-util@0.6.1 build:highlight: `node scripts/build_highlight_alias.js &gt; highlight_alias.json`npm ERR! Exit status 1npm ERR!npm ERR! Failed at the hexo-util@0.6.1 build:highlight script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.┌────────────────────────────────────────────────────────┐│ npm update check failed ││ Try running with sudo or get access ││ to the local update config store via ││ sudo chown -R $USER:$(id -gn $USER) /Users/xxx/.config │└────────────────────────────────────────────────────────┘npm WARN optional SKIPPING OPTIONAL DEPENDENCY: dtrace-provider@0.8.5 (node_modules/hexo-cli/node_modules/dtrace-provider):npm WARN optional SKIPPING OPTIONAL DEPENDENCY: dtrace-provider@0.8.5 install: `node scripts/install.js`npm WARN optional SKIPPING OPTIONAL DEPENDENCY: Exit status 1npm ERR! code ELIFECYCLEnpm ERR! errno 1npm ERR! hexo-util@0.6.1 postinstall: `npm run build:highlight`npm ERR! Exit status 1npm ERR!npm ERR! Failed at the hexo-util@0.6.1 postinstall script.npm ERR! This is probably not a problem with npm. There is likely additional logging output above.npm ERR! A complete log of this run can be found in:npm ERR! /Users/xxx/.npm/_logs/2017-10-27T02_56_29_887Z-debug.log 解决方法第一步,赋予目录权限: 1$ sudo chown -R `whoami` /usr/local/lib/node_modules 第二步,安装hexo: 1$ npm install hexo-cli -g 需要注意的点: 在安装hexo时,不要用 sudo 命令. 相关参考 国内优秀npm镜像推荐及使用 Mac install hexo use sudo but sitll permission denied npm update -g fails and causes /usr/local/lib/node_modules to be deleted]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Node.js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs数据库及初始化配置]]></title>
    <url>%2F2017%2F09%2F07%2Fdocker-ubuntu-gogs-initialization%2F</url>
    <content type="text"><![CDATA[Ubuntu-Gogs 首次运行安装程序配置及多数据库配置方法整理。 app.ini中数据库配置说明 名称 描述 DB_TYPE 数据库类型，可以是 mysql、postgres、mssql 或 sqlite3 HOST 数据库主机地址与端口 NAME 数据库名称 USER 数据库用户名 PASSWD 数据库用户密码 SSL_MODE 仅限 PostgreSQL 使用 PATH 仅限 SQLite3 使用，数据库文件路径 初次启动时数据库设置Gogs 要求安装 MySQL、PostgreSQL、SQLite3、MSSQL 或 TiDB。 SQLite3数据库设置 数据库类型 ：SQLite3 数据库文件路径 ：可使用绝对路径：/app/gogs/data/gogs.db 或者 相对路径：data/gogs.db （推荐使用绝对路径） app.ini中配置结果12345678[database]DB_TYPE = sqlite3HOST = 127.0.0.1:3306NAME = gogsUSER = rootPASSWD = SSL_MODE = disablePATH = /app/gogs/data/gogs.db 示例容器1$ docker run --name gogs1 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs MySQL数据库设置 数据库类型 ：MySQL 数据库主机 ：127.0.0.1:3306 数据库用户 ：root 数据库用户密码 : ******* 数据库名称 ：gogs app.ini中配置结果12345678[database]DB_TYPE = mysqlHOST = 127.0.0.1:3306NAME = gogsUSER = rootPASSWD = `123456`SSL_MODE = disablePATH = data/gogs.db 示例容器第一种方法：创建mysql容器和gogs容器，让gogs容器通过 --link 直接链接mysql容器。 创建mysql容器，并设置root账户密码：123456；新用户：gogs123；密码：gogs123；新用户数据库：gogs ： 1$ docker run --name mysqlgogs -v /home/tiger/mysqldb/:/var/lib/mysql -v /home/tiger/mysqldbase/:/home/mysqldbase/ -d -e MYSQL_ROOT_PWD=&quot;123456&quot; -e MYSQL_USER=gogs123 -e MYSQL_USER_PWD=&quot;gogs123&quot; -e MYSQL_USER_DB=&quot;gogs&quot; leafney/docker-alpine-mysql 创建gogs容器并链接： 1$ docker run --name gogs2 -d -p 10080:3000 -p 10022:22 --link mysqlgogs:mydb -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 相对应的配置信息如下： 数据库类型 ：MySQL 数据库主机 ：mydb:3306 数据库用户 ：gogs123 数据库用户密码 : ******* 数据库名称 ：gogs 第二种方法：让gogs容器链接已有mysql地址。 在创建gogs容器之前，先创建mysql数据库： 在下载的 gogs 压缩包中，我们可以找到一个名为 mysql.sql 的文件，是用来初始化mysql数据库的，内容如下： 12DROP DATABASE IF EXISTS gogs;CREATE DATABASE IF NOT EXISTS gogs CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci; 使用 root 账户登录，然后执行 mysql -u root -p &lt; mysql.sql （需要输入密码）即可初始化好数据库。 还要注意：使用 MySQL 数据库时，必须要保证mysql的存储引擎为 INNODB 且 编码格式为 utf8_general_ci 。可以使用如下语句来设置： 12use gogs;set global storage_engine=INNODB; 或者使用如下命令创建数据库 gogs 及新用户 gogsUser, 并将数据库 gogs 的所有权限都赋予该用户,密码 123456: 123456mysql -u root -pmysql&gt; SET GLOBAL storage_engine = &apos;InnoDB&apos;;mysql&gt; CREATE DATABASE gogs CHARACTER SET utf8 COLLATE utf8_bin;mysql&gt; GRANT ALL PRIVILEGES ON gogs.* TO &apos;gogsUser&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;123456&apos;;mysql&gt; FLUSH PRIVILEGES;mysql&gt; QUIT； 使用 Gogs 搭建自己的 Git 服务器 - My Nook PostgreSQL数据库设置 数据库类型 ：PostgreSQL 数据库主机 ：127.0.0.1:5432 数据库用户 ：gogs 数据库用户密码 : ******* 数据库名称 ：gogs SSL 模式 : Disable (可选：Disable Require Verify Full) app.ini中配置结果12345678[database]DB_TYPE = postgresHOST = 127.0.0.1:5432NAME = gogsUSER = gogsPASSWD = gogsSSL_MODE = disablePATH = data/gogs.db 示例容器第一种方法：创建postgersql容器和gogs容器 创建postgresql容器，这里使用容器 docker pull ananthhh/postgress： 1docker run --name postgress -p 5432:5432 -e POSTGRES_PASSWORD=gogs -e POSTGRES_USER=gogs -d ananthhh/postgress 该postgresql容器创建的用户为：gogs；用户密码：gogs; 数据库：gogs 。 创建gogs容器并通过 --link 参数链接： 1$ docker run --name gogs3 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app --link postgress:psqldb leafney/ubuntu-gogs 相对应的配置信息如下： 数据库类型 ：PostgreSQL 数据库主机 ：psqldb:5432 数据库用户 ：gogs 数据库用户密码 : ******* 数据库名称 ：gogs SSL 模式 : Disable 第二种方法：让gogs容器链接已有PostgreSQL地址。 使用指定数据库账户登录PostgreSQL，先创建 gogs 数据库，链接成功后会自动创建所需表： 1&gt; CREATE DATABASE gogs MSSql数据库设置 数据库类型 ：MSSQL 数据库主机 ：127.0.0.1, 1433 数据库用户 ：sa 数据库用户密码 : ******* 数据库名称 ：gogs app.ini中配置结果12345678[database]DB_TYPE = mssqlHOST = 127.0.0.1, 1433NAME = gogsUSER = saPASSWD = 123456SSL_MODE = disablePATH = data/gogs.db 示例容器创建gogs容器链接已有MSSql地址： 1docker run --name gogs4 -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 使用指定数据库账户登录MSSql，先创建gogs数据库，链接成功后会自动创建所需表： 1&gt; CREATE DATABASE gogs 应用基本设置以如下命令创建容器为例： 1$ docker run --name mygogs -d -p 10080:3000 -p 10022:22 -v /home/tiger/gogsfile:/app leafney/ubuntu-gogs 仓库根目录： 更改为绝对路径 /app/gogs-repositories 运行系统用户： 使用默认用户 git 域名： 填写Docker宿主机的主机名或物理地址或要使用的域名(不带http/https) 如 192.168.137.140 SSH 端口号： 如果你映射Docker外部端口如 10022:22 那么这里就填写 10022 ；不要勾选“使用内置SSH服务器”（Don’t tick Use Builtin SSH Server） HTTP 端口号： 如果映射Docker外部端口如 10080:3000 这里要使用：3000 应用 URL： 使用域名和公开的HTTP端口值的组合(带http/https) 如 http://192.168.137.140:10080 日志路径： 可使用路径 /app/gogs/log(推荐) 或默认值 /home/git/gogs/log 可选设置app.ini中邮件(mailer)配置说明 名称 描述 ENABLED 启用该选项以激活邮件服务 DISABLE_HELO 禁用 HELO 操作 HELO_HOSTNAME HELO 操作的自定义主机名 HOST SMTP 主机地址与端口 FROM 邮箱的来自地址，遵循 RFC 5322规范，可以是一个单纯的邮箱地址或者 “名字” &#x65;&#x6d;&#97;&#105;&#x6c;&#x40;&#101;&#120;&#97;&#109;&#112;&#x6c;&#101;&#x2e;&#x63;&#x6f;&#x6d; 的形式 USER 邮箱用户名 PASSWD 邮箱密码 SKIP_VERIFY 不验证自签发证书的有效性 USE_PLAIN_TEXT 使用 text/plain 作为邮件内容格式 邮件服务设置 SMTP 主机： 以163为例 如 smtp.163.com:25 邮件来自： 格式为 &quot;Name&quot; &lt;email@example.com&gt; 如 GitAdmin &lt;xxxxx@163.com&gt; 发送邮箱： 邮箱地址 如 xxxxx@163.com 发送邮箱密码 : 邮箱密码 app.ini中配置结果 123456[mailer]ENABLED = trueHOST = smtp.163.com:25FROM = GitAdmin &lt;xxxxx@163.com&gt;USER = xxxxx@163.comPASSWD = 123456 服务器和其它服务设置 禁止用户自主注册 激活该选项来禁止用户注册功能，只能由管理员创建帐号 启用验证码服务 要求在用户注册时输入预验证码 启用登录访问限制 只有已登录的用户才能够访问页面，否则将只能看到登录或注册页面 管理员账号设置创建管理员帐号并不是必须的，因为 ID=1 的用户将自动获得管理员权限。 建议在此处直接创建管理员账户。 相关参考 How To Set Up Gogs on Ubuntu 14.04 | DigitalOcean 配置文件手册 - Gogs]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Gogs</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下安装Docker-CE社区版]]></title>
    <url>%2F2017%2F08%2F25%2Fubuntu-install-docker-ce-and-configure-mirror-accelerator%2F</url>
    <content type="text"><![CDATA[在2017年3月份，Docker公司宣布Docker企业版（Enterprise Edition, EE），并将开源版本重命名为Docker社区版（Community Edition, CE）；同时公布了产品迭代计划，这会为企业客户提供透明的生命周期支持计划、并对Docker技术的稳定性和可维护性提升带来了帮助。 注：文章写于 2017年8月 ,文中所讲方法可能会过时，请查看Docker官方最新安装文档 Get Docker CE for Ubuntu | Docker Documentation，本文仅供参考。 Docker CE 还是 Docker EEDocker CEDocker CE表示社区版，是免费的Docker产品的新名称，Docker CE包含了完整的Docker平台，非常适合开发人员和运维团队构建容器APP。 Docker EEDocker EE表示企业版，由公司支持，可在经过认证的操作系统和云提供商中使用，并可运行来自Docker Store的、经过认证的容器和插件。 Docker EE提供三个服务层次： 服务层级 功能 Basic 1. 包含用于认证基础设施的Docker平台 2. Docker公司的支持 3. 经过认证的、来自Docker Store的容器与插件 Standard 1. 添加高级镜像与容器管理 2. LDAP/AD用户集成 3. 基于角色的访问控制(Docker Datacenter) Advanced 1. 添加Docker安全扫描 2. 连续漏洞监控 版本迭代Docker从17.03开始，转向基于时间的 YY.MM 形式的版本控制方案，类似于Canonical为Ubuntu所使用的版本控制方案。 Docker CE有两种版本： edge版本每月发布一次，主要面向那些喜欢尝试新功能的用户。 stable版本每季度发布一次，适用于希望更加容易维护的用户（稳定版）。 edge版本只能在当前月份获得安全和错误修复。而stable版本在初始发布后四个月内接收关键错误修复和安全问题的修补程序。这样，Docker CE用户就有一个月的窗口期来切换版本到更新的版本。 Docker EE和stable版本的版本号保持一致，每个Docker EE版本都享受为期一年的支持与维护期，在此期间接受安全与关键修正。 官方安装方法系统要求安装Docker CE,需要64位的Ubuntu系统： Zesty 17.04 Xenial 16.04 (LTS) Trusty 14.04 (LTS) 我的系统是 Ubuntu 16.04.2 LTS 版本，通过命令 lsb_release -a 我们可以查看到: 1234567$ sudo lsb_release -a[sudo] password for tiger: LSB Version: core-9.20160110ubuntu0.2-amd64Distributor ID: UbuntuDescription: Ubuntu 16.04.2 LTSRelease: 16.04Codename: xenial 通过 uname -r 来查看内核信息： 12$ uname -r4.4.0-85-generic 卸载旧版本Docker旧版本的docker被称为 docker 或者 docker-engine，而现在最新的Docker CE包被称为 docker-ce。在安装之前，需要先卸载旧版本(如果之前有安装)： 1$ sudo apt-get remove docker docker-engine docker.io 另外原来 /var/lib/docker/ 目录下的镜像，容器，数据卷，网络等都会保留，新安装的docker任然可以使用这些内容。 14.04 Trusty 需要安装额外包在 14.04 系统版本下，需要安装 linux-image-extra-* 包以允许Docker使用 aufs 存储驱动程序： 12345$ sudo apt-get update$ sudo apt-get install \ linux-image-extra-$(uname -r) \ linux-image-extra-virtual 安装 Docker CE更新源1$ sudo apt-get update 允许通过HTTPS使用存储库12345$ sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ software-properties-common 导入官方 GPG 密钥1$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - 验证密钥指纹是否正确 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88 1$ sudo apt-key fingerprint 0EBFCD88 操作记录如下： 1234567$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -OK$ sudo apt-key fingerprint 0EBFCD88pub 4096R/0EBFCD88 2017-02-22 Key fingerprint = 9DC8 5822 9FC7 DD38 854A E2D8 8D81 803C 0EBF CD88uid Docker Release (CE deb) &lt;docker@docker.com&gt;sub 4096R/F273FCD8 2017-02-22 选择稳定版本使用如下命令安装稳定版本的docker-ce,64位系统： amd64 or x86_64: 1234$ sudo add-apt-repository \ &quot;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&quot; 更新源列表1$ sudo apt-get update 安装最新版本的Docker CE1$ sudo apt-get install docker-ce 安装特定版本的Docker CE使用命令 $ apt-cache madison docker-ce 查看可安装的版本列表： 123456$ apt-cache madison docker-ce docker-ce | 17.06.1~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.06.0~ce-0~ubuntu | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.2~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.1~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages docker-ce | 17.03.0~ce-0~ubuntu-xenial | https://download.docker.com/linux/ubuntu xenial/stable amd64 Packages 中间一项为版本名称，执行命令选择安装指定版本 $ sudo apt-get install docker-ce=&lt;VERSION&gt; ,比如： 1234567$ sudo apt-get install docker-ce=17.06.1~ce-0~ubuntu[sudo] password for tiger: Reading package lists... DoneBuilding dependency tree Reading state information... Donedocker-ce is already the newest version (17.06.1~ce-0~ubuntu).0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded. 安装完成后docker守护进程会自动启动。 验证执行命令 docker 查看安装是否成功： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576$ docker Usage: docker COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default &quot;/home/tiger/.docker&quot;) -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to -l, --log-level string Set the logging level (&quot;debug&quot;|&quot;info&quot;|&quot;warn&quot;|&quot;error&quot;|&quot;fatal&quot;) (default &quot;info&quot;) --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default &quot;/home/tiger/.docker/ca.pem&quot;) --tlscert string Path to TLS certificate file (default &quot;/home/tiger/.docker/cert.pem&quot;) --tlskey string Path to TLS key file (default &quot;/home/tiger/.docker/key.pem&quot;) --tlsverify Use TLS and verify the remote -v, --version Print version information and quitManagement Commands: config Manage Docker configs container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker volume Manage volumesCommands: attach Attach local standard input, output, and error streams to a running container build Build an image from a Dockerfile commit Create a new image from a container&apos;s changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes to files or directories on a container&apos;s filesystem events Get real time events from the server exec Run a command in a running container export Export a container&apos;s filesystem as a tar archive history Show the history of an image images List images import Import the contents from a tarball to create a filesystem image info Display system-wide information inspect Return low-level information on Docker objects kill Kill one or more running containers load Load an image from a tar archive or STDIN login Log in to a Docker registry logout Log out from a Docker registry logs Fetch the logs of a container pause Pause all processes within one or more containers port List port mappings or a specific mapping for the container ps List containers pull Pull an image or a repository from a registry push Push an image or a repository to a registry rename Rename a container restart Restart one or more containers rm Remove one or more containers rmi Remove one or more images run Run a command in a new container save Save one or more images to a tar archive (streamed to STDOUT by default) search Search the Docker Hub for images start Start one or more stopped containers stats Display a live stream of container(s) resource usage statistics stop Stop one or more running containers tag Create a tag TARGET_IMAGE that refers to SOURCE_IMAGE top Display the running processes of a container unpause Unpause all processes within one or more containers update Update configuration of one or more containers version Show the Docker version information wait Block until one or more containers stop, then print their exit codesRun &apos;docker COMMAND --help&apos; for more information on a command. 为当前用户添加管理员权限Docker进程启动后，执行docker命令都必须带上 sudo 才行，否则会报 permission denied 的错误： 12$ docker infoGot permission denied while trying to connect to the Docker daemon socket at unix:///var/run/docker.sock: Get http://%2Fvar%2Frun%2Fdocker.sock/v1.30/info: dial unix /var/run/docker.sock: connect: permission denied 解决方法是将当前用户加入到 docker 用户分组下。 将当前用户添加到 docker 分组下1$ sudo usermod -aG docker &lt;your-user&gt; 或者直接用 $USER 表示当前用户： 1$ sudo usermod -aG docker $USER 然后重启系统： 1$ sudo reboot 再执行时就不会报错了： 12345678910111213141516171819$ docker infoContainers: 0 Running: 0 Paused: 0 Stopped: 0Images: 0Server Version: 17.06.1-ceStorage Driver: aufs Root Dir: /var/lib/docker/aufs Backing Filesystem: extfs Dirs: 0 Dirperm1 Supported: trueLogging Driver: json-fileCgroup Driver: cgroupfsPlugins: Volume: local Network: bridge host macvlan null overlay Log: awslogs fluentd gcplogs gelf journald json-file logentries splunk syslogSwarm: inactive 使用阿里云Docker CE镜像源安装Ubuntu 14.04 16.04 (使用apt-get进行安装)12345678910111213141516171819# step 1: 安装必要的一些系统工具sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-common# step 2: 安装GPG证书curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -# Step 3: 写入软件源信息sudo add-apt-repository &quot;deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable&quot;# Step 4: 更新并安装 Docker-CEsudo apt-get -y updatesudo apt-get -y install docker-ce# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# apt-cache madison docker-ce# docker-ce | 17.03.1~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# docker-ce | 17.03.0~ce-0~ubuntu-xenial | http://mirrors.aliyun.com/docker-ce/linux/ubuntu xenial/stable amd64 Packages# Step 2: 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.1~ce-0~ubuntu-xenial)# sudo apt-get -y install docker-ce=[VERSION] CentOS 7 (使用yum进行安装)12345678910111213141516171819202122# step 1: 安装必要的一些系统工具sudo yum install -y yum-utils device-mapper-persistent-data lvm2# Step 2: 添加软件源信息sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# Step 3: 更新并安装 Docker-CEsudo yum makecache fastsudo yum -y install docker-ce# Step 4: 开启Docker服务sudo service docker start# 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r# Loading mirror speeds from cached hostfile# Loaded plugins: branch, fastestmirror, langpacks# docker-ce.x86_64 17.03.1.ce-1.el7.centos docker-ce-stable# docker-ce.x86_64 17.03.1.ce-1.el7.centos @docker-ce-stable# docker-ce.x86_64 17.03.0.ce-1.el7.centos docker-ce-stable# Available Packages# Step2 : 安装指定版本的Docker-CE: (VERSION 例如上面的 17.03.0.ce.1-1.el7.centos)# sudo yum -y install docker-ce-[VERSION] 配置阿里云Docker镜像加速器打开阿里云 开发者平台 - 管理中心 - Docker Hub 镜像站点。可以看到 您的专属加速器地址 https://xxxxx.mirror.aliyuncs.com 配置Docker加速器通过修改daemon配置文件 /etc/docker/daemon.json (没有时新建该文件) 来使用加速器： 12345678sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxx.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 注意：上文代码段中给出的镜像加速器地址中的 xxxxx 为阿里云在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关参考 Get Docker CE for Ubuntu | Docker Documentation Docker 17.03系列教程（一）Docker EE/Docker CE简介与版本规划 | 周立|Spring Cloud Docker CE 镜像源站-博客-云栖社区-阿里云]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB备份与恢复]]></title>
    <url>%2F2017%2F08%2F22%2Fmongodb-mongodump-and-mongorestore%2F</url>
    <content type="text"><![CDATA[mongodb中有工具mongodump和mongorestore提供了非常方便的对数据库备份与恢复功能。可以在命令后面加 --help 选项查看两个工具的帮助文档。 12345678910111213141516171819/ # mongodump --helpUsage: mongodump &lt;options&gt;Export the content of a running server into .bson files.Specify a database with -d and a collection with -c to only dump that database or collection.See http://docs.mongodb.org/manual/reference/program/mongodump/ for more information.general options: --help print usage --version print the tool version and exitverbosity options: -v, --verbose=&lt;level&gt; more detailed log output (include multiple times for more verbosity, e.g. -vvvvv, or specify a numeric value, e.g. --verbose=N) --quiet hide all log output ... ... MongoDB备份mongodump备份命令语法: 1&gt; mongodump -h dbhost -d dbname -o dbdirectory -h : MongDB所在服务器地址，例如：127.0.0.1，当然也可以指定端口号：127.0.0.1:27017 -d : 需要备份的数据库实例，例如：test -o ：备份的数据存放位置，例如：c:\data\dump，当然该目录需要提前建立 备份指定数据库： 1&gt; mongodump -h 127.0.0.1:27017 -d local -o D:\Test\aatt 备份所有数据库： 1&gt; mongodump --host 127.0.0.1 --port 27017 如果mongodb设置了密码，则命令格式为： 1&gt; mongodump --host localhost --port 27017 -u dbUser -p dbPassword -d mydb --out /home/dbbackup 或者如下的格式： 1&gt; mongodump -h 127.0.0.1:27017 -u admin -p 123456 -d test -o /data/backup MongoDB恢复mongorestore 恢复备份命令语法： 1&gt; mongorestore -h &lt;hostname&gt;&lt;:port&gt; -d dbname &lt;path&gt; --host &lt;:port&gt;, -h &lt;:port&gt; : MongoDB所在服务器地址，默认为： localhost:27017 --db , -d ：需要恢复的数据库实例，该名称与备份时的名称可以不一致 --drop : 恢复的时候，先删除当前数据，然后恢复备份的数据。 &lt;path&gt; ：mongorestore 最后的一个参数，设置备份数据所在位置，例如：c:\data\dump\test。你不能同时指定 和 –dir 选项，–dir也可以设置备份目录。 --dir : 指定备份的目录 恢复备份数据到指定的服务器数据库中： 1&gt; mongorestore -h 127.0.0.1:27017 -d test2 D:\Test\aatt\local Alpine系统下的MongoDB备份与恢复Alpine系统下使用MongoDB，需要安装MongoDB包: apk add mongodb 。如果要使用备份与恢复功能，需要安装 mongodb-tools 包：apk add mongodb-tools。 1234567alpine:edge$ echo http://dl-4.alpinelinux.org/alpine/edge/testing &gt;&gt; /etc/apk/repositories$ apk add --no-cache mongodb mongodb-tools$ ls /usr/bin/]]></content>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang下通过Gin体验WebSocket框架Melody]]></title>
    <url>%2F2017%2F08%2F14%2Fwebsocket-framework-for-go-melody%2F</url>
    <content type="text"><![CDATA[Melody 是一个 Go 语言的微型 WebSocket 框架，基于 github.com/gorilla/websocket 开发. Gin-Gonic获取包： 1&gt; go get github.com/gin-gonic/gin 添加引用： 1inport &quot;github.com/gin-gonic/gin&quot; 创建Gin测试站点： 12345678910111213141516package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;Hello Gin&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125; 运行： 1&gt; go run main.go Melody获取包： 1&gt; go get gopkg.in/olahol/melody.v1 添加引用： 1import &quot;gopkg.in/olahol/melody.v1&quot; Simple Chat Demomain.go： 123456789101112131415161718192021222324252627package mainimport ( &quot;github.com/gin-gonic/gin&quot; &quot;gopkg.in/olahol/melody.v1&quot; &quot;net/http&quot;)func main() &#123; r := gin.Default() m := melody.New() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; http.ServeFile(c.Writer, c.Request, &quot;templates/index.html&quot;) &#125;) //websocket r.GET(&quot;/ws&quot;, func(c *gin.Context) &#123; m.HandleRequest(c.Writer, c.Request) &#125;) m.HandleMessage(func(s *melody.Session, msg []byte) &#123; m.Broadcast(msg) &#125;) r.Run(&quot;:8080&quot;)&#125; index.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950&lt;html&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;WebSocket&lt;/title&gt; &lt;style&gt; #chat &#123; text-align: left; background: #f1f1f1; width: 500px; min-height: 300px; padding: 20px; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;center&gt; &lt;h3&gt;Chat&lt;/h3&gt; &lt;pre id=&quot;chat&quot;&gt;&lt;/pre&gt; &lt;input placeholder=&quot;say something&quot; id=&quot;text&quot; type=&quot;text&quot;&gt; &lt;/center&gt; &lt;script&gt; var url = &quot;ws://&quot; + window.location.host + &quot;/ws&quot;; var ws = new WebSocket(url); var name = &quot;Guest&quot; + Math.floor(Math.random() * 1000); var chat = document.getElementById(&quot;chat&quot;); var text = document.getElementById(&quot;text&quot;); var now = function () &#123; var iso = new Date().toISOString(); return iso.split(&quot;T&quot;)[1].split(&quot;.&quot;)[0]; &#125;; ws.onmessage = function (msg) &#123; var line = now() + &quot; &quot; + msg.data + &quot;\n&quot;; chat.innerText += line; &#125;; text.onkeydown = function (e) &#123; if (e.keyCode === 13 &amp;&amp; text.value !== &quot;&quot;) &#123; ws.send(&quot;&lt;&quot; + name + &quot;&gt; &quot; + text.value); text.value = &quot;&quot;; &#125; &#125;; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 运行： 1&gt; go run main.go GitHub - olahol/melody: Minimalist websocket framework for Go]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Travis CI自动部署Hexo博客]]></title>
    <url>%2F2017%2F08%2F09%2Fusing-travis-ci-automatic-deploy-hexo-blogs%2F</url>
    <content type="text"><![CDATA[自从使用GitHub Pages和Hexo来发布博客之后，不得不说方便了许多，只需要几个简单的命令博客就发布了。但在不断的使用中发现每次的发布操作也挺耗时的。 我一般的操作是将平时整理好的md文件放到私有的git仓库中（感兴趣可了解 Ubuntu-Gogs 用更简单的方式部署、升级或迁移Gogs服务），每次发布的时候都要先将文件 clone 到本地，然后配置一下hexo的运行环境，接着再执行 hexo s -g 来预览和调整，最后执行 hexo d 命令将博客发布上去，在这之前如果你没有配置过GitHub的 SSH Key,还要花一些时间来弄权限的问题。久而久之就发现这样操作起来实在是太繁琐了。 后来看到一篇文章介绍可以使用Travis CI来自动部署hexo的博客，只需要将md文件 pull 到仓库中博客就自动发布好了。趁着这几天工作任务不太着急，研究了一下，特纪录在此，希望能帮到有需要的朋友。 Travis CI 是目前新兴的开源持续集成构建项目，用来构建托管在GitHub上的代码。它提供了多种编程语言的支持，包括Ruby，JavaScript，Java，Scala，PHP，Haskell和Erlang在内的多种语言。 配置GitHub Pages如果你是新手或者还没有自己的 GitHub Pages 博客站点，可以先看我之前的文章 使用GitHub搭建Hexo静态博客 | IT范儿 了解如何配置，具体过程这里不再详述。 创建 hexo 分支因为我之前的博客源文件是存放在私有的git管理工具下，如果我们要使用Travis CI自动部署，必须将这些博客的源码文件放到GitHub上才能被Travis访问到。因为 GitHub Pages 默认要求必须使用 master 分支存放静态文件，我们可以在该仓库下使用其他分支来存放博客源码文件，或者新创建一个仓库来单独保存。这里我们把hexo博客的源码放在 hexo 分支下，博客的静态文件部署在 master 分支下。 对于如何在GitHub上创建分支，相关操作命令如下，仅供参考： 12345# 克隆项目到本地&gt; git clone https://github.com/Leafney/Leafney.github.io.git# 创建并切换到 hexo 分支&gt; git checkout -b hexo 当切换到 hexo 分支后，因为我们是需要用 hexo 分支来存放博客源码文件的，所以，将 hexo 分支下的文件除 .git 目录外全部删除，然后将博客源码文件拷贝到该目录下，并 commit 到 hexo 分支. 然后我们需要将本地的 hexo 分支提交到远程仓库中 12# 提交本地hexo分支到远程仓库的hexo分支&gt; git push origin hexo:hexo 这样我们在GitHub的仓库下就能看到 hexo 分支为博客源文件，master 分支为静态文件。 这里需要注意一点，当我们新增博客md文件时，获取远程分支时要指定分支的名称，否则会默认获取 master 分支： 1&gt; git pull origin hexo 设置 Travis CI使用 GitHub账户登录 Travis CI官网 ，进去后能看到已经自动关联了 GitHub 上的仓库。这里我们选择需要启用的项目，即 yourname/yourname.github.io 。 然后点击后面的齿轮图标进入设置界面。 如果你之前已经勾选过项目，可以进到项目主页中，在右上角找到 More options 选项下的 Settings 进入设置界面。 通用设置在 General 区域开启：Build only if .travis.yml is present 表示“只有当 .travis.yml 存在时才构建” ；开启：Build branch updates 表示 “当分支更新时构建” 两个选项，如下： Travis CI在自动构建完成后需要push静态文件到仓库的 master 分支下，而访问GitHub的仓库是需要权限的，下面来看看如何配置权限。 配置 Access Token如下图，Environment Variables 区域就是用来添加权限信息的。我们需要填写一个Token的名称和值，该名称可以在配置文件中以 ${变量名} 来引用，该Token我们需要从Github中获取。 从GitHub获取Access Token之前我们在使用命令 hexo d 部署hexo博客到GitHub上时，是因为本地有 SSH key，当交给 Travis 去自动部署时我们也需要设置可操作权限，这里我们使用GitHub提供的token变量来实现。 登陆 GitHub –Settings 选项，找到 Personal access tokens 页面。 点击右上角的 Generate new token 按钮会生成新的token，点击后提示输入密码后继续，然后来到如下界面，取个名字（我这里取 Travis_Token 下面的配置文件中会用到)，勾选相应权限，这里只需要 repo 下全部和 user 下的 user:email 即可。 生成完成后，将该token拷贝下来。这里需要注意的是该token只有这个时候才能看到，当再次进入这个页面时就只会显示之前设置的名称了。如果忘记了只能重新生成一个。 在Travis CI中配置将上面获取到的token添加到 Environment Variables 部分，值为该 token ,而名称即为上面设置的 Travis_Token (请更改为个人所设置名称)。不勾选后面的 Display value in build log . 否则会在日志文件中暴露你的 token 信息，而日志文件是公开可见的。 至此我们已经配置好了要构建的仓库和访问的token，接下来就是如何构建的问题了。 创建 .travis.yml 文件之前的步骤中我们勾选了一项 Build only if .travis.yml is present,所以我们要在博客源码文件的 hexo 分支下新增一个 .travis.yml 配置文件，其内容如下： 123456789101112131415161718192021222324252627language: node_js # 设置语言node_js: stable # 设置相应版本install: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - cd ./public - git init - git config user.name &quot;yourname&quot; # 修改name - git config user.email &quot;your email&quot; # 修改email - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master # GH_TOKEN是在Travis中配置token的名称branches: only: - hexo #只监测hexo分支，hexo是我的分支的名称，可根据自己情况设置env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改yourname 注意：需要将配置文件中的 GH_TOKEN 换成我们自己设定的名称，这里我的配置应该是 Travis_Token 即 - git push --force --quiet &quot;https://${Travis_Token}@${GH_REF}&quot; master:master # GH_TOKEN是在Travis中配置token的名称。 还要更改 GH_REF 中我们的博客仓库的地址。 配置文件中的操作也很简单，这也是网上找到的比较常见的一种配置格式了。然而，这份配置文件中却隐藏着一个大坑。至于如何跳过去，后面再详说。 实现自动部署当 .travis.yml 配置文件修改完成后，将其提交到远程仓库的 hexo 分支下，此时如果之前的配置一切ok，我们应该能在 Travis CI 的博客项目主页页面中看到自动构建已经在开始执行了。上面会显示出构建过程中的日志信息及状态等。 遇到的问题问题一：提示 .travis.yml 文件格式错误在 Travis CI 的日志文件中，如果遇到下面的错误提示，那可能就是 .travis.yml 文件的格式有问题。 1234ERROR: An error occured while trying to parse your .travis.yml file.Please make sure that the file is valid YAML.http://lint.travis-ci.org can check your .travis.yml.The log message was: Build config file had a parse error: found character that cannot start any token while scanning for the next token at line 6 column 1. 通过在github上查询，我发现这个问题是我在配置文件中的缩进使用了 tab 键导致的。因为在不同的编辑器下，tab 键表示的宽度可能不同。 这里建议是：不要用 tab 键，而是用适当的空格实现缩进 found character &#39;\t&#39; that cannot start any token while scanning for the next token at line · Issue #136 · ruby/psych · GitHub 问题二：Travis CI的自动构建成功，但是构建完成后的项目没有推送到github中123456......git commit -m &quot;Travis CI Auto Builder&quot;git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:masterremote: Anonymous access to Leafney/Leafney.github.io.git denied.fatal: Authentication failed for &apos;https://@github.com/Leafney/Leafney.github.io.git/&apos; 查看日志提示是权限问题。 这里的问题是我在 .travis.yml 配置文件中没有把 ${GH_TOKEN} 部分换成自己在 Travis CI 中填写的token名称而导致的。执行时找不到token，也就没法设置权限了。 问题三：master commit 树被清空 ☆如果你按照上面的 travis.yml 配置文件的设置去自动构建你的博客，你会发现 master 分支的提交记录只有当前提交的这一条，而且无论操作多少次，也仅仅只有一条。这还真的是一个大坑呀！ 比如下面这位网友的站点： GitHub - hhstore/hhstore.github.io: 个人技术博客 在 master 分支下就只有一条提交记录。 .travis.yml 部分配置内容： 12345678after_script: - cd ./public - git init - git config user.name &quot;yourname&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;update&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master 仔细查看上面的配置文件，我们发现每次都是将 public 目录下的文件重新生成了一个git项目，然后强制覆盖提交到了 master 分支下，这就是问题的所在。 为了解决这个问题，我将配置文件改为了如下的内容： 123456789101112after_script: - git clone https://$&#123;GH_REF&#125; .deploy_git - cd .deploy_git - git checkout master - cd ../ - mv .deploy_git/.git/ ./public/ - cd ./public - git config user.name &quot;yourname&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:master 在 after_script 部分，我先将博客项目 clone 到本地的 .deploy_git 目录下（目录名可自定义）,然后切换到 master 分支，将 master 分支下的 .git 目录拷贝到了 public 目录下，接着继续后面的 commit 操作。 这里算是采用了一种 换位 的方式。之前我们通过git管理文件时并不会改动 .git 目录，而只是更改文件。但在这种情况下，我们需要提交的是 public 目录下的新文件。这样，就会保留之前的提交记录了。 附上我在使用的配置文件内容： 123456789101112131415161718192021222324252627282930313233343536373839language: node_js # 设置语言node_js: stable # 设置相应版本cache: apt: true directories: - node_modules # 缓存不经常更改的内容before_install: - npm install hexo-cli -ginstall: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - git clone https://$&#123;GH_REF&#125; .deploy_git - cd .deploy_git - git checkout master - cd ../ - mv .deploy_git/.git/ ./public/ - cd ./public - git config user.name &quot;your name&quot; - git config user.email &quot;your email&quot; - git add . - git commit -m &quot;Travis CI Auto Builder&quot; - git push --force --quiet &quot;https://$&#123;GH_TOKEN&#125;@$&#123;GH_REF&#125;&quot; master:masterbranches: only: - hexo # 只监测hexo分支env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改成自己的仓库地址 注意上面配置文件中的某些参数改为自己的。 问题四：添加 commit 时间戳 2017-8-23 11:25:34 Update: 按照上面的方法配置 travis.yml 的内容，我在一段时间后发现在 master 分支下的提交记录是这样的： 1234567Travis CI Auto BuilderTravis CI Auto BuilderTravis CI Auto Builder.... 而之前在使用 hexo d 直接部署的时候的提交记录是这样的： 1234567Site updated: 2017-06-22 22:29:10Site updated: 2017-04-19 08:13:36Site updated: 2017-03-27 20:54:40... 看到每次的提交记录中没有提交的时间戳，感觉似乎缺少了些什么，所以考虑着要把 commit 的时间戳给加上。 通过查看 travis.yml 的文档，并没有找到如何直接获取当前时间或者和 date 有关的方法，但是 script 命令下是可以执行 shell 命令的，所以对 travis.yml 文件进行了修改。 在 shell 中获取当前的时间戳，可以这样： 1234#/bin/bash&gt; date +&quot;%Y-%m-%d %H:%M&quot;2017-08-23 11:07 需要注意的是：命令中要为 publish-to-gh-pages.sh 文件赋予可执行权限，否则会报无权限错误： 1234# travis-ci log$ ./publish-to-gh-pages.sh/home/travis/.travis/job_stages: line 57: ./publish-to-gh-pages.sh: Permission denied 另外，通过在测试中发现，Travis CI 中使用的linux系统在编译生成时使用的是UTC时间，这样我们在github中的提交列表中看到的提交时间就会晚8小时。我们需要在执行时将时区改为东八区。 这里通过在 .travis.yml 文件中添加如下代码解决： 12before_install: - export TZ=&apos;Asia/Shanghai&apos; 修改后的 .travis.yml 内容： 12345678910111213141516171819202122232425262728293031language: node_js # 设置语言node_js: stable # 设置相应版本cache: apt: true directories: - node_modules # 缓存不经常更改的内容before_install: - export TZ=&apos;Asia/Shanghai&apos; # 更改时区 - npm install hexo-cli -g - chmod +x ./publish-to-gh-pages.sh # 为shell文件添加可执行权限install: - npm install # 安装hexo及插件script: - hexo clean # 清除 - hexo g # 生成after_script: - ./publish-to-gh-pages.shbranches: only: - hexo # 只监测hexo分支env: global: - GH_REF: github.com/yourname/yourname.github.io.git #设置GH_REF，注意更改成自己的仓库地址 将 after_script 段中的命令移到了单独的shell文件中： 文件 publish-to-gh-pages.sh 内容： 1234567891011121314151617181920#!/bin/bashset -evgit clone https://$&#123;GH_REF&#125; .deploy_gitcd .deploy_gitgit checkout mastercd ../mv .deploy_git/.git/ ./public/cd ./publicgit config user.name &quot;your name&quot;git config user.email &quot;your email&quot;# add commit timestampgit add .git commit -m &quot;Travis CI Auto Builder at `date +&quot;%Y-%m-%d %H:%M&quot;`&quot;git push --force --quiet &quot;https://$&#123;TravisCIToken&#125;@$&#123;GH_REF&#125;&quot; master:master 注意上面配置文件中的某些参数改为自己的。 Customizing the Build - Travis CI travis ci - Permission denied for build.sh file - Stack Overflow Shell中date命令用法 | Hom 问题五：使用 x-oauth-basic在网上看到一位网友解决 “master commit 树被清空” 的问题时采用了另外一种方法，即在 after_script 部分调用执行 hexo d 命令来发布。这样的方式遇到的问题是需要设置 SSH Key 或者必须获得权限才能进行 push 操作。 有一种授权的方式是通过https使用OAuth验证的方式将token添加到url中来提交。即需要更改 _config.yml 中的如下部分： 12345## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:Leafney/Leafney.github.io.git branch: master 为： 12345## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: https://&lt;token&gt;:x-oauth-basic@github.com/owner/repo.git branch: master 而这样一来 token 就暴露在配置文件中了。所以还需要在操作命令中使用替换的方式只在自动部署时更改该token。 这里仅做介绍，更详细可访问： 使用Travis Ci使hexo自动生成并部署 | xingo&#39;s private plot Easier builds and deployments using Git over HTTPS and OAuth · GitHub 问题六：git branch 分支操作相关命令1234567891011121314151617181920212223242526# 查看本地所有分支(分之名称前面带*表示当前分支)&gt; git branch# 查看远程所有分支&gt; git branch -r# 创建分支 blog&gt; git branch blog# 切换到 blog 分支&gt; git checkout blog# 创建并切换到新分支&gt; git checkout -b blog# 删除分支&gt; git branch -d blog# 提交本地test分支作为远程的test分支&gt; git push origin test:test# 合并分支(将名称为[blog]的分支与当前分支合并)&gt; git merge blog# 获取远程指定分支&gt; git pull origin blog 问题七：博客仓库源码如果没有耐心按照上面的步骤一步步操作的话，可以直接查看我的博客仓库源码： GitHub - Leafney/Leafney.github.io: blog 相关参考 手把手教你使用Travis CI自动部署你的Hexo博客到Github上 - 简书 使用 Travis CI 自动部署 Hexo - 简书 使用 Travis-CI 来自动化部署 Hexo · ZHOU 用TravisCI来做持续集成 | 进击的马斯特 Customizing the Build - Travis CI 该文章同步发表在： 使用Travis CI自动部署Hexo博客 - 酷小孩 - 博客园 使用Travis CI自动部署Hexo博客 | IT范儿]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Travis-CI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[reload-changed-without-restart-for-golang-web-gin]]></title>
    <url>%2F2017%2F08%2F01%2Freload-changed-without-restart-for-golang-web-gin%2F</url>
    <content type="text"><![CDATA[Gin is a HTTP web framework written in Go (Golang)。但是在调试Gin项目时，每次更改了文件内容后都需要重新运行 go run main.go 命令才能看到更改。项目 codegangsta/gin 和 pilu/fresh 是通过采用热更新的方式来调试Gin项目推荐度较高的两个，且看哪个在操作上更加的方便。 gingithub 地址GitHub - codegangsta/gin: Live reload utility for Go web servers 下载并安装1go get github.com/codegangsta/gin 将 GOPATH/bin 目录添加到系统的 PATH 中。 项目测试123456789101112131415package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world\n&quot;) &#125;) r.Run(&quot;:3001&quot;)&#125;# 运行&gt; gin run main.go# 浏览器访问http://localhost:3000 扩展 因为项目 codegangsta/gin 和 gin-gonic/gin 重名，所以这里我用 Reload gin 代指 codegangsta/gin;用 Web gin 代指 gin-gonic/gin。 默认情况下，Reload gin的默认监听端口为 3000,内部导向的go web项目端口为 3001。如果采用 Reload gin 的默认端口，则需要将 Web gin 的监听端口改为 3001,即：r.Run(&quot;:3001&quot;) 。 如果需要自定义端口，通过 gin -h 可以看到 Reload gin 的常用配置项。其中: 12--port value, -p value port for the proxy server (default: 3000)--appPort value, -a value port for the Go web server (default: 3001) 可以分别指定监听端口和映射端口。 不过，经过测试，自定义端口时报如下错误： 12345678λ gin run -p 8082 -a 8080 main.goIncorrect Usage: flag provided but not defined: -pNAME: gin run - Run the gin proxy in the current working directoryUSAGE: gin run [arguments...] 好像目前只能使用默认的 3000 和 3001 端口。 freshgithub地址GitHub - pilu/fresh: Build and (re)start go web apps after saving/creating/deleting source files. 下载及安装1go get github.com/pilu/fresh 将 GOPATH/bin 目录添加到系统的 PATH 中。 项目测试123456789101112131415161718package mainimport &quot;github.com/gin-gonic/gin&quot;func main() &#123; r := gin.Default() r.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world\n&quot;) &#125;) r.Run(&quot;:8080&quot;)&#125;# 进入项目所在目录&gt; cd /path/to/myapp# 运行&gt; fresh# 浏览器访问http://localhost:8080 扩展原项目不需要做任何改动，只需要在原项目的目录下执行命令 fresh 即可。 经以上测试，推荐使用 fresh 来运行 Gin 项目。 相关链接 GitHub - codegangsta/gin: Live reload utility for Go web servers GitHub - pilu/fresh: Build and (re)start go web apps after saving/creating/deleting source files. GitHub - gin-gonic/gin: Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance – up to 40 times faster. If you need smashing performance, get yourself some Gin.]]></content>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang网站微框架Gin]]></title>
    <url>%2F2017%2F07%2F30%2Fgolang-web-framework-gin%2F</url>
    <content type="text"><![CDATA[Gin is a web framework written in Golang. 安装 Gin获取包： 1&gt; go get github.com/gin-gonic/gin 添加引用： 1import &quot;github.com/gin-gonic/gin&quot; Gin web 入门一个简单的示例12345678910111213141516171819202122232425package mainimport ( &quot;github.com/gin-gonic/gin&quot;)func main() &#123; router := gin.Default() router.GET(&quot;/&quot;, func(c *gin.Context) &#123; c.String(200, &quot;hello world!&quot;) &#125;) //http://localhost:8081 postdata: name=tom router.POST(&quot;/&quot;, postHome) router.Run(&quot;:8081&quot;)&#125;func postHome(c *gin.Context) &#123; uName := c.PostForm(&quot;name&quot;) c.JSON(200, gin.H&#123; &quot;say&quot;: &quot;Hello &quot; + uName, &#125;)&#125; 请求方法名必须全部是大写字母1234567router.GET(&quot;/someGet&quot;, getting)router.POST(&quot;/somePost&quot;, posting)router.PUT(&quot;/somePut&quot;, putting)router.DELETE(&quot;/someDelete&quot;, deleting)router.PATCH(&quot;/somePatch&quot;, patching)router.HEAD(&quot;/someHead&quot;, head)router.OPTIONS(&quot;/someOptions&quot;, options) 获取路由参数通过 Context 的 Param 方法来获取： 12345678910111213141516171819...// http://localhost:8081/user/article/tommyrouter.GET(&quot;/user/:type/:name&quot;, getRouteStr)...func getRouteStr(c *gin.Context) &#123; ctype := c.Param(&quot;type&quot;) cname := c.Param(&quot;name&quot;) c.JSON(200, gin.H&#123; &quot;typeName&quot;: ctype, &quot;username&quot;: cname, &#125;)&#125;//result:&#123; &quot;typeName&quot;: &quot;article&quot;, &quot;username&quot;: &quot;tommy&quot;&#125; 获取url参数通过 DefaultQuery 或 Query 方法获取： Query(&#39;xxx&#39;) 如果没有相应值，默认为空字符串 DefaultQuery(&quot;xxx&quot;,&quot;defaultValue&quot;) 可设置默认值,string类型 1234567891011121314151617181920212223242526... router.GET(&quot;/user&quot;, getQueryStrs)...func getQueryStrs(c *gin.Context) &#123; name := c.Query(&quot;name&quot;) //如果没有相应值，默认为空字符串 age := c.DefaultQuery(&quot;age&quot;, &quot;0&quot;) //可设置默认值,string类型 c.JSON(200, gin.H&#123; &quot;name&quot;: name, &quot;age&quot;: age, &#125;)&#125;//result://http://localhost:8081/user?name=tom&amp;age=23&#123; &quot;age&quot;: &quot;23&quot;, &quot;name&quot;: &quot;tom&quot;&#125;//result2://http://localhost:8081/user?name=tom&#123; &quot;age&quot;: &quot;0&quot;, &quot;name&quot;: &quot;tom&quot;&#125; c.Request.URL.Query() 可获取所有url请求参数 map[] 集合： 1234567 //获取所有url请求参数 reqData := c.Request.URL.Query() fmt.Printf(&quot;[info] req url data is %s\n&quot;, reqData)//result://http://localhost:8080?id=3&amp;name=zhangsan&amp;address=beijing[info] req url data is map[name:[zhangsan] address:[beijing] id:[3]] 获取表单参数表单参数通过 PostForm 或 DefaultPostForm 方法获取： PostForm() DefaultPostForm(&quot;xxx&quot;,&quot;defaultValue&quot;) 12345678910111213141516171819 ... router.POST(&quot;/&quot;, getFormStr) ...func getFormStr(c *gin.Context) &#123; title := c.PostForm(&quot;title&quot;) cont := c.DefaultPostForm(&quot;cont&quot;, &quot;没有内容&quot;) c.JSON(200, gin.H&#123; &quot;title&quot;: title, &quot;cont&quot;: cont, &#125;)&#125;//result://http://localhost:8081 postData: title:这是一个标题&#123; &quot;cont&quot;: &quot;没有内容&quot;, &quot;title&quot;: &quot;这是一个标题&quot;&#125; c.Request.Body 获取所有 post body 数据： 1234567891011 //获取post body x, _ := ioutil.ReadAll(c.Request.Body) fmt.Printf(&quot;[info] %s&quot;, string(x))//result:// post body type :x-www-form-urlencoded (user=tom pwd=123)[info] user=tom&amp;pwd=123//result:// post body type: raw application/json[info] &#123;&quot;name&quot;:&quot;zhangfei&quot;,&quot;id&quot;:32&#125; go - gin/golang - Empty Req Body - Stack Overflow Print Request Body empty · Issue #401 · gin-gonic/gin · GitHub 获取所有 post data 数据 （map[] 类型） 1234567 c.Request.ParseForm() reqBodyData := c.Request.PostForm fmt.Printf(&quot;[info] req body data is %s \n&quot;, reqBodyData)//result:// post body type :x-www-form-urlencoded (user=tom pwd=123)[info] req body data is map[user:[tom] pwd:[123]] go - Gin Gonic array of values from PostForm - Stack Overflow 路由群组支持 一级 或 多级 分组的路由规则： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657 ... //路由分组 articleGroup := router.Group(&quot;/article&quot;) &#123; articleGroup.GET(&quot;/one/:id&quot;, getArticleByid) articleGroup.GET(&quot;/list&quot;, getArticleList) &#125; //多级路由分组 apiGroup := router.Group(&quot;/api&quot;) apiv1Group := apiGroup.Group(&quot;/v1&quot;) &#123; apiv1Group.GET(&quot;/user&quot;, getApiV1User) &#125; apiv2Group := apiGroup.Group(&quot;/v2&quot;) &#123; apiv2Group.GET(&quot;/order&quot;, getApiV2Order) &#125; ...func getArticleByid(c *gin.Context) &#123; a_id := c.Param(&quot;id&quot;) c.String(200, a_id)&#125;//result://http://localhost:8081/article/one/33func getArticleList(c *gin.Context) &#123; c.JSON(200, gin.H&#123; &quot;a&quot;: &quot;1&quot;, &quot;b&quot;: &quot;2&quot;, &#125;)&#125;//result://http://localhost:8081/article/list&#123; &quot;a&quot;: &quot;1&quot;, &quot;b&quot;: &quot;2&quot;&#125;func getApiV1User(c *gin.Context) &#123; c.String(200, &quot;api/v1/user&quot;)&#125;//result://http://localhost:8081/api/v1/userapi/v1/userfunc getApiV2Order(c *gin.Context) &#123; c.String(200, &quot;api/v2/order&quot;)&#125;//result://http://localhost:8081/api/v2/orderapi/v2/order 数据绑定 Bind() BindJSON() 123456789101112131415161718192021222324252627282930 ... //绑定普通表单 (user=tom&amp;&amp;pwd=123) router.POST(&quot;/loginform&quot;, func(c *gin.Context) &#123; var form Login if c.Bind(&amp;form) == nil &#123; if form.User == &quot;tom&quot; &amp;&amp; form.Password == &quot;123&quot; &#123; c.JSON(200, gin.H&#123;&quot;status&quot;: &quot;form logined in&quot;&#125;) &#125; else &#123; c.JSON(201, gin.H&#123;&quot;status&quot;: &quot;form no login&quot;&#125;) &#125; &#125; &#125;) //绑定JSON (&#123;&quot;user&quot;:&quot;tom&quot;,&quot;pwd&quot;:&quot;123&quot;&#125;) Content-Type:application/json router.POST(&quot;/loginjson&quot;, func(c *gin.Context) &#123; var json Login if c.BindJSON(&amp;json) == nil &#123; if json.User == &quot;tom&quot; &amp;&amp; json.Password == &quot;123&quot; &#123; c.JSON(200, gin.H&#123;&quot;status&quot;: &quot;json logined in&quot;&#125;) &#125; else &#123; c.JSON(201, gin.H&#123;&quot;status&quot;: &quot;json no login&quot;&#125;) &#125; &#125; &#125;) ...type Login struct &#123; User string `form:&quot;user&quot; json:&quot;user&quot;` Password string `form:&quot;pwd&quot; json:&quot;pwd&quot;`&#125; POST上传文件12345678910111213141516...//表单上传文件 http://localhost:8081/upload // key:upload value: file....//result://&#123; //&quot;filename&quot;: &quot;1009e3ee4bc0919e11d32e00ccf55cdf.jpg&quot;//&#125;router.POST(&quot;/upload&quot;, func(c *gin.Context) &#123; _, header, _ := c.Request.FormFile(&quot;upload&quot;) filename := header.Filename c.JSON(200, gin.H&#123; &quot;filename&quot;: filename, &#125;)&#125;)... 根据客户端的请求类型，返回对应的响应格式1234567891011121314...router.GET(&quot;/getdata&quot;, func(c *gin.Context) &#123; contentType := c.Request.Header.Get(&quot;Content-Type&quot;) switch contentType &#123; case &quot;application/json&quot;: c.JSON(200, gin.H&#123;&quot;user&quot;: &quot;张飞&quot;, &quot;address&quot;: &quot;长坂坡&quot;&#125;) case &quot;application/xml&quot;: c.XML(200, gin.H&#123;&quot;user&quot;: &quot;张飞&quot;, &quot;address&quot;: &quot;长坂坡&quot;&#125;) case &quot;application/x-www-form-urlencoded&quot;: c.String(200, &quot;张飞 长坂坡&quot;) &#125;&#125;)... 字符串响应1234import &quot;net/http&quot;c.String(200, &quot;some string&quot;)c.String(http.StatusOK, &quot;some string&quot;) JSON/XML/YAML等格式响应12345...c.JSON(http.StatusOK, msg)c.XML(http.StatusOK, msg)c.YAML(http.StatusOK, msg)... 视图响应12345678910111213141516171819202122232425262728293031323334 ... //加载模板 router.LoadHTMLGlob(&quot;templates/*&quot;) // router.LoadHTMLFiles(&quot;templates/index.html&quot;,&quot;templates/article.html&quot;) router.GET(&quot;/&quot;, func(c *gin.Context) &#123; //根据完整文件名渲染模板，并传递参数 c.HTML(200, &quot;index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;Hello World!&quot;, &#125;) &#125;) ...//index.html:&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;//result:&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt;Hello World!&lt;/h3&gt; &lt;/body&gt;&lt;/html&gt; 加载多层模板路径经测试：如果是多层级的模板文件，要在模板文件中使用1&#123;&#123;define xxx&#125;&#125; &#123;&#123;end&#125;&#125; 将该模板作为嵌套模板： 12345678910111213141516//加载模板router.LoadHTMLGlob(&quot;templates/**/*&quot;)// router.LoadHTMLFiles(&quot;templates/index.html&quot;,&quot;templates/article.html&quot;)router.GET(&quot;/articles/index&quot;, func(c *gin.Context) &#123; //根据完整文件名渲染模板，并传递参数 c.HTML(200, &quot;articles/index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;Article index!&quot;, &#125;)&#125;)router.GET(&quot;/users/index&quot;, func(c *gin.Context) &#123; c.HTML(200, &quot;/users/index.html&quot;, gin.H&#123; &quot;say&quot;: &quot;User index!&quot;, &#125;)&#125;) templates/articles/index.html: 1234567891011&#123;&#123;define &quot;articles/index.html&quot;&#125;&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;&#123;&#123;end&#125;&#125; templates/users/index.html: 1234567891011&#123;&#123;define &quot;users/index.html&quot;&#125;&#125;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h3&gt;&#123;&#123; .say &#125;&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt;&#123;&#123;end&#125;&#125; 提供静态文件 Static() StaticFS() StatucFile() 示例: 123456789func main() &#123; router := gin.Default() router.Static(&quot;/assets&quot;, &quot;./assets&quot;) router.StaticFS(&quot;/more_static&quot;, http.Dir(&quot;my_file_system&quot;)) router.StaticFile(&quot;/favicon.ico&quot;, &quot;./resources/favicon.ico&quot;) // Listen and serve on 0.0.0.0:8080 router.Run(&quot;:8080&quot;)&#125; 待详细研究。 重定向支持 内部 和 外部 地址的重定向 123456789101112131415...//跳转到外部地址router.GET(&quot;/abc&quot;, func(c *gin.Context) &#123; c.Redirect(302, &quot;http://www.baidu.com&quot;)&#125;)//跳转到内部地址router.GET(&quot;def&quot;, func(c *gin.Context) &#123; c.Redirect(302, &quot;/home&quot;)&#125;)router.GET(&quot;/home&quot;, func(c *gin.Context) &#123; c.String(200, &quot;home page&quot;)&#125;)... 自定义中间件及中间件的使用方式12345678910111213141516171819202122232425262728293031323334353637383940414243 ...func main() &#123; // router := gin.Default() router := gin.New() //全局中间件 router.Use(MyLogger()) router.GET(&quot;/test&quot;, func(c *gin.Context) &#123; example := c.MustGet(&quot;example&quot;).(string) c.String(200, example) &#125;) //单路由中间件 router.GET(&quot;/abc&quot;,MyMiddelware(),getAbc) //群组路由中间件 aGroup:=router.Group(&quot;/&quot;,MyMiddelware()) //中间件可以同时添加多个 aGroup:=router.Group(&quot;/&quot;,MyMiddelware(),My2Middelware(),My3Middelware()) //或者：群组路由中间件 bGroup:=router.Group(&quot;/&quot;) bGroup.Use(MyMiddelware()) &#123; bGroup.GET(&quot;/v1&quot;,getV1) &#125; router.Run(&quot;:8081&quot;)&#125;func MyLogger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; c.Set(&quot;example&quot;, &quot;123465&quot;) c.Next() &#125;&#125; 异步处理goroutine 中只能使用只读的上下文 c.Copy() 1234567891011121314151617181920...//异步router.GET(&quot;/async&quot;, func(c *gin.Context) &#123; // goroutine 中只能使用只读的上下文 c.Copy() cCp := c.Copy() go func() &#123; time.Sleep(5 * time.Second) //需要使用只读上下文 log.Println(&quot;Done! in path &quot; + cCp.Request.URL.Path) &#125;()&#125;)//同步router.GET(&quot;/sync&quot;, func(c *gin.Context) &#123; time.Sleep(5 * time.Second) //可以使用原始上下文 log.Println(&quot;Done! in path &quot; + c.Request.URL.Path)&#125;)... 初始化不带中间件和带有默认中间件的路由 r := gin.New() 创建不带中间件的路由 r := gin.Default() 创建带有默认中间件的路由:日志与恢复中间件 Cookie http://www.grdtechs.com/2016/03/29/gin-setcookie/ 其他示例获取所有请求参数 获取所有URL请求参数 12reqData := c.Request.URL.Query()fmt.Printf(&quot;[info] req url data is %s\n&quot;, reqData) 获取所有Body请求参数 123c.Request.ParseForm()reqBodyData := c.Request.PostFormfmt.Printf(&quot;[info] req body data is %s \n&quot;, reqBodyData) 获取请求头信息123456789// 获取请求头Header中的 key sign timestamptoken := c.Request.Header.Get(&quot;X-Auth-Token&quot;)key := c.Request.Header.Get(&quot;X-Auth-Key&quot;)timestamp := c.Request.Header.Get(&quot;X-Auth-TimeStamp&quot;)fmt.Printf(&quot;[info] key is %s ,timestamp is %s\n&quot;, key, timestamp)//获取Post put请求模式下的Content-lengthconlength := c.Request.Header.Get(&quot;Content-Length&quot;)fmt.Printf(&quot;[info] Content-Length is %s\n&quot;, conlength) 获取请求 Method Host URL ContentLength1234567//判断请求Method// GET POST PUT DELETE OPTIONSfmt.Println(&quot;[info]&quot;, c.Request.Method)fmt.Println(&quot;[info]&quot;, c.Request.Host) // localhost:8080fmt.Println(&quot;[info]&quot;, c.Request.URL) ///?id=3&amp;name=zhangsan&amp;address=beijing//获取请求头中数据长度 ContentLengthfmt.Println(&quot;[info]&quot;, c.Request.ContentLength) // POST for 16 or GET for 0 CORS 跨域请求 (未测试)123456789101112131415 // CORS middleware g.Use(CORSMiddleware())func CORSMiddleware() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; c.Writer.Header().Set(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;) c.Writer.Header().Set(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type, Content-Length, Accept-Encoding, X-CSRF-Token, Authorization&quot;) if c.Request.Method == &quot;OPTIONS&quot; &#123; c.Abort(200) return &#125; c.Next() &#125;&#125; Json not work · Issue #149 · gin-gonic/gin · GitHub 定义 struct 时，参数的首字母要大写才能被访问到12345type ReturnMsg struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125; Go json.Marshal(struct) returns &quot;{}&quot; - Stack Overflow 输出一个struct对象123456789 ... c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) ...type ReturnMsg struct &#123; Code int `json:&quot;code&quot;` Msg string `json:&quot;msg&quot;` Data interface&#123;&#125; `json:&quot;data&quot;`&#125; gin中间件阻止请求继续访问c.Abort() 1234567891011121314151617token := c.Request.Header.Get(&quot;X-Auth-Token&quot;)key := c.Request.Header.Get(&quot;X-Auth-Key&quot;)timestamp := c.Request.Header.Get(&quot;X-Auth-TimeStamp&quot;)//判断请求头中是否含有必须的三个参数if token == &quot;&quot; || key == &quot;&quot; || timestamp == &quot;&quot; &#123; //经测试，c.Abort() 在前在后均可 // c.Abort() // c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) c.JSON(403, ReturnMsg&#123;Code: 1, Msg: &quot;req error&quot;&#125;) c.Abort() return //一定要加return&#125;c.Next() go - Failed to Abort() context - gin - Stack Overflow gin安装报错安装 gin 包时可能会报 x/net 相关错误，可以先下载该必须包： 1234567$ mkdir -p $GOPATH/src/golang.org/x/$ cd $GOPATH/src/golang.org/x/$ git clone https://github.com/golang/net.git net$ go install net Gin 安装报错 - 简书 golang中相关易错点时间戳转换12345678910111213141516package mainimport ( &quot;fmt&quot; &quot;time&quot; &quot;strconv&quot;)func main() &#123; i, err := strconv.ParseInt(&quot;1405544146&quot;, 10, 64) if err != nil &#123; panic(err) &#125; tm := time.Unix(i, 0) fmt.Println(tm)&#125; date - How to parse unix timestamp in golang - Stack Overflow 什么类型可以声明为常量及在func外部声明变量时不能使用:=数字类型，字符串或布尔类型可以声明为 const 常量；array ,slice 或 map 不能声明为常量。 map类型不能声明为常量: 12345678const myString = &quot;hello&quot;const pi = 3.14 // untyped constantconst life int = 42 // typed constant (can use only with ints)const ( First = 1 Second = 2 Third = 4) 在函数func外部声明变量，要用完整模式： 1234var romanNumeralDict = map[int]string&#123; 1:&quot;a&quot;, 2:&quot;b&quot;,&#125; 在函数func内部声明变量，可以使用缩写模式： 123romanNumeralDict := map[int]string&#123;...&#125; go - How to declare constant map in golang - Stack Overflow 判断map中是否存在某值，可以写在一行123456// 查找键值是否存在if v, ok := m1[&quot;a&quot;]; ok &#123; fmt.Println(v)&#125; else &#123; fmt.Println(&quot;Key Not Found&quot;)&#125; map排序map 是无序的: 1234567891011121314151617181920212223242526272829import ( &quot;fmt&quot; &quot;sort&quot;)func main() &#123; // fmt.Printf(&quot;Hello,是按揭&quot;) // fmt.Printf(&quot;ni好呀&quot;) m := map[string]string&#123; &quot;sign&quot;: &quot;1399dke&quot;, &quot;user&quot;: &quot;zhangsan&quot;, &quot;timestamp&quot;: &quot;36644747373&quot;, &quot;id&quot;: &quot;3&quot;, &#125; fmt.Println(m) var keys []string for k := range m &#123; // fmt.Println(k) keys = append(keys, k) &#125; sort.Strings(keys) // fmt.Println(keys) for _, k := range keys &#123; fmt.Println(&quot;key:&quot;, k, &quot;Value :&quot;, m[k]) &#125;&#125; go - sort golang map values by keys - Stack Overflow for rangefor range 可以遍历 slice 或 map。并通过两个参数(index和value)，分别获取到slice或者map中某个元素所在的index以及其值。 在Go的 for…range 循环中，Go始终使用值拷贝的方式代替被遍历的元素本身。 1234for index, value := range mySlice &#123; fmt.Println(&quot;index: &quot; + index) fmt.Println(&quot;value: &quot; + value)&#125; go语言string、int、int64互相转换12345678#string到intint,err:=strconv.Atoi(string)#string到int64int64, err := strconv.ParseInt(string, 10, 64)#int到stringstring:=strconv.Itoa(int)#int64到stringstring:=strconv.FormatInt(int64,10) http.Request123func getURL(w http.ResponseWriter, r *http.Request) &#123; url := r.URL.String()&#125; How to convert *url.URL to string in GO, Google App Engine - Stack Overflow 中文 url 编码问题12345678910import &quot;net/url&quot; //url编码 str := &quot;中文-_.&quot; unstr := &quot;%2f&quot; fmt.Printf(&quot;url.QueryEscape:%s&quot;, url.QueryEscape(str)) fmt.Println() s, _ := url.QueryUnescape(unstr) fmt.Printf(&quot;url.QueryUnescape:%s&quot;, s) fmt.Println() go 中url编码和字符转码(类似php中的urlencode 和htmlspecialchars): 1234567891011121314151617181920212223242526package mainimport ( &quot;fmt&quot; &quot;html&quot; &quot;net/url&quot; &quot;testing&quot;)func Test_Escape(t *testing.T) &#123;//url编码 str := &quot;中文-_.&quot; unstr := &quot;%2f&quot; fmt.Printf(&quot;url.QueryEscape:%s&quot;, url.QueryEscape(str)) fmt.Println() s, _ := url.QueryUnescape(unstr) fmt.Printf(&quot;url.QueryUnescape:%s&quot;, s) fmt.Println()//字符转码 hstr := &quot;&lt;&quot; hunstr := &quot;&amp;lt&quot; fmt.Printf(&quot;html.EscapeString:%s&quot;, html.EscapeString(hstr)) fmt.Println() fmt.Printf(&quot;html.UnescapeString:%s&quot;, html.UnescapeString(hunstr)) fmt.Println()&#125; go 中url编码和字符转码(类似php中的urlencode 和htmlspecialchars) - coolaf golang中字符串拼接一种说法： 如果是少量小文本拼接，用 “+” 就好如果是大量小文本拼接，用 strings.Join如果是大量大文本拼接，用 bytes.Buffer 字符串连接哪一种方式最高效 - Go 技术社区 - golang golang 高效字符串拼接 - Go语言中文网 - Golang中文社区 go语言中高效字符串拼接 strings 包 Go语言开发-字符串-strings包 | Plum Wine Blog - 青梅酒博客 获取字符串的MD5值12345678910import ( &quot;crypto/md5&quot; &quot;encoding/hex&quot;)func GetMD5Hash(text string) string &#123; hasher := md5.New() hasher.Write([]byte(text)) return hex.EncodeToString(hasher.Sum(nil))&#125; md5 example 相关链接 GitHub - gin-gonic/gin: Gin is a HTTP web framework written in Go (Golang). It features a Martini-like API with much better performance – up to 40 times faster. If you need smashing performance, get yourself some Gin. Gin Web Framework gin-doc-cn/README.md at master · ningskyer/gin-doc-cn · GitHub Go语言web框架 gin | shanshanpt Gin 安装报错 - 简书 Building Go Web Applications and Microservices Using Gin - Semaphore Build a RESTful API Server with Golang and MySQL - Jinchuriki Golang 微框架 Gin 简介 - 简书 How to create a basic Restful API in Go – Etienne Rouzeaud – Medium Gin middleware examples - Dan Sosedoff REST Microservices in Go with Gin Go: Templating with the Gin Web Framework 相关问题 关于数据绑定 how to bind query string? · Issue #742 · gin-gonic/gin · GitHub 关于模板文件 go - How to make templates work with gin framework? - Stack Overflow]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>Gin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs关于使用SSH]]></title>
    <url>%2F2017%2F07%2F21%2Fdocker-ubuntu-gogs-ssh%2F</url>
    <content type="text"><![CDATA[记录在Docker容器中运行Gogs时，使用SSH操作遇到的git密码问题。 SSH key passphrases在本地电脑上(我这里是Windows系统)创建 SSH key 时，会要求你为key设置一个密码： 123456789λ ssh-keygen -t rsa -C &quot;xxxxx@qq.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/You/.ssh/id_rsa):Enter passphrase (empty for no passphrase):Enter same passphrase again:Your identification has been saved in /c/Users/You/.ssh/id_rsa.Your public key has been saved in /c/Users/You/.ssh/id_rsa.pub.The key fingerprint is:... 即其中的： 12Enter passphrase (empty for no passphrase):Enter same passphrase again: 一般情况下我们可以选择直接回车即不设置密码。 如果没有设置key的密码，我们在通过SSH提交代码时，可以直接操作。如果设置了key的密码，那我们在每次 pull 或 push 时都会要求你输入key的密码： 12$ git pullEnter passphrase for key &apos;/c/Users/You/.ssh/id_rsa&apos;: Docker-Ubuntu-Gogs容器使用SSH提交时要求输入git密码在使用SSH获取或提交代码时，偶尔会遇到要求输入 git 密码的情况： 123456789101112$ git clone ssh://git@gogit.itfanr.cc/haha/wohaha.gitCloning into &apos;wohaha&apos;...git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied (publickey,password).fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 或者： 12345678910$ git pullgit@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 但是我们通过Docker创建的gogs容器中，并没有为git账户设置密码，所以这里无论输入什么都是错误的。 通过查看 Issues · gogits/gogs · GitHub 中相关的 issues 可以了解到，但凡是要求输入git密码的问题，十有八九是 关于 .ssh/authorize_keys 文件的权限 问题。 gogs的文档中要求： .ssh/ 目录权限为 0700 .ssh/authorize_keys 文件的权限为 0600 相关的操作命令为： 12$ chmod 0700 /home/git/.ssh$ chmod 0600 /home/git/.ssh/* 方法一登陆gogs站点的管理员账户，选择 管理面板 访问 /admin 页面。在 管理员操作 区域选择 重新生成 &#39;.ssh/authorized_keys&#39; 文件（警告：不是 Gogs 的密钥也会被删除） 点击 执行 按钮。 然后再次尝试看是否能够成功操作。 方法二如果 方法一 的操作无效，那么我们需要登陆该gogs容器所在的服务器来进入如下操作： 进入该gogs容器，然后删除 .ssh/authorized_keys 文件 。 重复方法一的操作：登陆管理员账户，选择 管理面板 – 管理员操作 – 点击 重新生成 &#39;.ssh/authorized_keys&#39; 文件（警告：不是 Gogs 的密钥也会被删除） 后的 执行 按钮。 然后再次尝试看是否能够成功操作。 我的操作记录： 12345678910111213141516$ docker exec -it gogs /bin/bashroot@564c5628c7e9:/home/git/gogs# cd ..root@564c5628c7e9:/home/git# cd .ssh/root@564c5628c7e9:/home/git/.ssh# lsauthorized_keysroot@564c5628c7e9:/home/git/.ssh# rm authorized_keys root@564c5628c7e9:/home/git/.ssh# ls# 此时在管理后台重新生成 authorized_keysroot@564c5628c7e9:/home/git/.ssh# lsauthorized_keysroot@564c5628c7e9:/home/git/.ssh# ls -altotal 12drwx------ 2 git git 4096 Jul 21 14:20 .drwxr-xr-x 6 git git 4096 Jul 21 11:32 ..-rw------- 1 git git 549 Jul 21 14:20 authorized_keys 我在 git push 时遇到要求输入git密码的问题时，先将 authorized_keys 文件删除，然后重新生成，这样操作后就能正常获取和提交了。 相关参考 ssh 的链接地址不可以使用 · Issue #545 · gogits/gogs · GitHub]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Gogs</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang连接MongoDB数据库]]></title>
    <url>%2F2017%2F06%2F28%2Fgolang-connect-to-mongodb%2F</url>
    <content type="text"><![CDATA[目前go支持MongoDB最好的驱动就是mgo。 下载与引用123go get gopkg.in/mgo.v2import &quot;gopkg.in/mgo.v2&quot; 123go get labix.org/v2/mgoimport &quot;labix.org/v2/mgo&quot; 安装时发现，地址 labix.org/v2/mgo 中的mgo版本中有些方法不全，而地址 gopkg.in/mgo.v2中的方法是全的，但是该地址下载超时而失败，必须翻墙才可以访问。如 labix.org/v2/mgo 中就没有 mongo, err := mgo.ParseURL(MongoDBUrl) 的 ParseURL() 方法。 如果无法翻墙，还可以从 github 下载： 因为我们要使用 mgo 的 v2 版本，所以需要迁出 branch:v2 分支，不能直接使用 master 分支。 在 go get 命令后添加 -d 参数可以只下载而不会执行安装命令。 操作步骤为： 执行命令 go get -d github.com/go-mgo/mgo 找到上面 clone 的目录，迁出分支 v2 再次运行 go get 命令，这时会在迁出的分支上执行命令 12345go get -d github.com/go-mgo/mgogit checkout v2go get github.com/go-mgo/mgo mgo - Rich MongoDB driver for Go mgo.v2 - gopkg.in/mgo.v2 git - How to do &quot;go get&quot; on a specific tag of a github repository - Stack Overflow 安装bzr工具Bazaar是一款开源的分布式版本控制工具。 安装mgo之前，需要先安装 bzr 工具，否则直接执行或报错： 123&gt; go get labix.org/v2/mgogo: missing Bazaar command. See https://golang.org/s/gogetcmdpackage labix.org/v2/mgo: exec: &quot;bzr&quot;: executable file not found in %PATH% Win从网址 http://bazaar.canonical.com/en/ 下载安装包，选择 Standalone版本或其他版本。 Ubuntu sudo apt-get install bzr 多平台系统下如何安装Bazzar工具 连接字符串1234MONGODB_URL=&quot;mongodb://user:pass@server.compose.io/db_name&quot;mongodb://localhost:27017/articles_demo_devmongodb://myuser:mypass@localhost:40001,otherhost:40001/mydb 或者： 12345session, err := mgo.Dial(&quot;&quot;) session, err := mgo.Dial(&quot;localhost&quot;) session, err := mgo.Dial(&quot;127.0.0.1&quot;) session, err := mgo.Dial(&quot;localhost:27017&quot;)session, err := mgo.Dial(&quot;127.0.0.1:27017&quot;) 创建连接通过Session.DB()来切换相应的数据库 1db := session.DB(&quot;xtest&quot;) //数据库名称 通过Database.C()方法切换集合（Collection）： 1collection := db.C(&quot;xtest&quot;) // 集合名称 或直接一步： 1c := session.DB(&quot;xtest&quot;).C(&quot;xtest&quot;) 查询通过func (c Collection) Find(query interface{}) Query来进行查询通过Query.All()可以获得所有结果通过Query.One()可以获得一个结果条件用 bson.M{key: value} ，注意key必须用MongoDB中的字段名，而不是struct的字段名。 示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081package mainimport ( &quot;fmt&quot; &quot;labix.org/v2/mgo&quot; &quot;labix.org/v2/mgo/bson&quot;)const ( MONGODB_URL = &quot;127.0.0.1:27017&quot;)func main() &#123; //创建连接 session, err := mgo.Dial(MONGODB_URL) if err != nil &#123; panic(err) &#125; defer session.Close() session.SetMode(mgo.Monotonic, true) // db := session.DB(&quot;xtest&quot;) //数据库名称 // collection := db.C(&quot;xtest&quot;) // 集合名称 c := session.DB(&quot;xtest&quot;).C(&quot;xtest&quot;) // //插入数据 // err = c.Insert(&amp;Person&#123;&quot;Tommy&quot;, &quot;123456&quot;&#125;, &amp;Person&#123;&quot;Hanleilei&quot;, &quot;98765&quot;&#125;, // &amp;Person&#123;&quot;喜洋洋&quot;, &quot;98765&quot;&#125;, &amp;Person&#123;&quot;灰太狼&quot;, &quot;46577&quot;&#125;, // ) // if err != nil &#123; // panic(err) // &#125; // //查询并赋值 Find().One() // result := Person&#123;&#125; // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;result) // if err != nil &#123; // panic(err) // &#125; // //输出 // fmt.Println(&quot;Phone &quot;, result.Phone) // //集合中元素数量 Count() // countNum, err := c.Count() // fmt.Println(&quot;obj numbers &quot;, countNum) // //查询多条数据 Find().Iter() // var onep = Person&#123;&#125; // iter := c.Find(nil).Iter() // for iter.Next(&amp;onep) &#123; // fmt.Println(&quot;姓名 &quot;, onep.Name) // &#125; // //查询多条数据 Find().All() // var personAll []Person // err = c.Find(nil).All(&amp;personAll) // for i := 0; i &lt; len(personAll); i++ &#123; // fmt.Println(&quot;Person &quot;, personAll[i].Name, personAll[i].Phone) // &#125; // //更新数据 Update() // abc := Person&#123;&#125; // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;abc) // fmt.Println(&quot;Tommy phone is &quot;, abc.Phone) // err = c.Update(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;, bson.M&#123;&quot;$set&quot;: bson.M&#123;&quot;phone&quot;: &quot;10086&quot;&#125;&#125;) // err = c.Find(bson.M&#123;&quot;name&quot;: &quot;Tommy&quot;&#125;).One(&amp;abc) // fmt.Println(&quot;Tommy phone is &quot;, abc.Phone) // //删除数据 Remove() // fmt.Println(c.Count()) // err = c.Remove(bson.M&#123;&quot;phone&quot;: &quot;46577&quot;&#125;) // fmt.Println(c.Count()) fmt.Println(&quot;end&quot;)&#125;type Person struct &#123; Name string `bson:&quot;name&quot;` Phone string `bson:&quot;phone&quot;`&#125; 相关 GitHub - go-mgo/mgo: The MongoDB driver for Go. See http://labix.org/mgo for details. golang使用mgo连接MongoDB]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进京证办理]]></title>
    <url>%2F2017%2F06%2F22%2Fforeign-car-to-beijing%2F</url>
    <content type="text"><![CDATA[北京市公安局相关规定 适用范围：进入北京市六环路（不含）以内行驶的外埠车辆，以及前往昌平、怀柔、延庆城关镇行驶的外埠车辆，需办理进京通行证。 办理地点：本市任意进京检查站或办证处 北京市公安局公安交通管理局 办理时间：7*24小时 周末及法定节假日不休 携带资料： 驾驶人身份证 驾驶人驾驶证 车辆行驶证 交通事故责任强制保险凭证 安全技术检验合格标志 经北京市环保部门确认的车辆符合环保要求的凭证 有效期：进京通行证有效期为7天，可延期一次。 我是如何办理实体进京证的 驾驶人身份证 驾驶人驾驶证 车辆行驶证 我第一次办理实体进京证是在京港澳高速的兴礼检查站办理的 (2017-6-11)： 携带以上三个证件先用车辆行驶证去办理环保证明，然后拿着环保证明和三个证件去另一个窗口办理进京证。那里有指示牌可参考。 注意要仔细核对环保证明或进京证上的信息是否正确。 不需要保险单或其他材料。 实体进京证免费办理。 电子进京证–北京交警app优势 可提前1-4天在线申请办理进京通行证 电子进京证的效力与实体进京证相同，其有效期为2至7天 电子进京证所需证件、材料 车辆型号（见行驶证） 车辆发动机号（见行驶证） 进京车辆行驶证正面照片 车辆正面照片（需露出车辆号牌） 车主驾驶证正面照片 车主手持身份证的照片（必须是车主本人） 号牌类型 机动车类型 机动车号牌 车主姓名 车主驾驶证号（同身份证号） 进京日期（只能从后一天开始的7天内） 进京时长(可选2-7天) 进京路口（例如京津高速） 驾驶员信息 电子进京证注意事项 目前只允许外地小客车网上办理电子进京证，其它车辆仍需到检查站办证窗口办理。 电子进京证与实体进京证在同一时段内无法重复办理。 电子进京证无法在城区安监窗口续办。 目前，电子进京证一旦申请成功，无法更改日期。 注意事项 再次办理进京证的流程和所需的材料与初次办理相同。 在办理进京证之前，您需要将外地号牌车辆之前在北京产生的所有交通违法都处理完毕。 相关参考 外地车进京注意事项]]></content>
      <tags>
        <tag>人在帝都</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang实现http请求及代理设置]]></title>
    <url>%2F2017%2F06%2F15%2FGolang-implements-HTTP-request-and-proxy-settings%2F</url>
    <content type="text"><![CDATA[主要探究 1. 使用代理请求 2. 跳过https不安全验证 3. 自定义请求头User-Agent的实现 主要研究的技术点 使用代理请求 跳过https不安全验证 自定义请求头 User-Agent 静态数据请求并设置代理实例代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108package mainimport ( &quot;crypto/tls&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;net/http&quot; &quot;net/url&quot; &quot;time&quot;)func First() &#123; /* 1. 普通请求 */ webUrl := &quot;http://ip.gs/&quot; resp, err := http.Get(webUrl) if err != nil &#123; fmt.Println(err) return &#125; // if resp.StatusCode == http.StatusOK &#123; // fmt.Println(resp.StatusCode) // &#125; time.Sleep(time.Second * 3) defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func Second(webUrl, proxyUrl string) &#123; /* 1. 代理请求 2. 跳过https不安全验证 */ // webUrl := &quot;http://ip.gs/&quot; // proxyUrl := &quot;http://115.215.71.12:808&quot; proxy, _ := url.Parse(proxyUrl) tr := &amp;http.Transport&#123; Proxy: http.ProxyURL(proxy), TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: true&#125;, &#125; client := &amp;http.Client&#123; Transport: tr, Timeout: time.Second * 5, //超时时间 &#125; resp, err := client.Get(webUrl) if err != nil &#123; fmt.Println(&quot;出错了&quot;, err) return &#125; defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func Third(webUrl, proxyUrl string) &#123; /* 1. 代理请求 2. 跳过https不安全验证 3. 自定义请求头 User-Agent */ // webUrl := &quot;http://ip.gs/&quot; // proxyUrl := &quot;http://171.215.227.125:9000&quot; request, _ := http.NewRequest(&quot;GET&quot;, webUrl, nil) request.Header.Set(&quot;Connection&quot;, &quot;keep-alive&quot;) request.Header.Set(&quot;User-Agent&quot;, &quot;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36&quot;) proxy, _ := url.Parse(proxyUrl) tr := &amp;http.Transport&#123; Proxy: http.ProxyURL(proxy), TLSClientConfig: &amp;tls.Config&#123;InsecureSkipVerify: true&#125;, &#125; client := &amp;http.Client&#123; Transport: tr, Timeout: time.Second * 5, //超时时间 &#125; resp, err := client.Do(request) if err != nil &#123; fmt.Println(&quot;出错了&quot;, err) return &#125; defer resp.Body.Close() body, _ := ioutil.ReadAll(resp.Body) fmt.Println(string(body))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/user-agent&quot; //&quot;http://ip.gs/&quot; proxyUrl := &quot;http://119.5.0.75:808&quot; Second(webUrl, proxyUrl) // Third(webUrl, proxyUrl)&#125; 相关参考 Mocking a HTTP access with http.Transport in Golang - oinume journal Go http访问使用代理 GO HTTP client客户端使用 - 海运的博客 Making Tor HTTP Requests with Go | DevDungeon go - golang: How to do a https request with proxy - Stack Overflow go - Set UserAgent in http request - Stack Overflow 动态数据请求并设置代理动态数据请求使用golang调用phantomjs来请求网页数据内容实现。 通过命令参数方式： 1phantomjs [options] somescript.js [arg1 [arg2 [...]]] 代理相关的配置参数： --load-images=[true|false] (default is true) --proxy=address:port (eg --proxy=192.168.1.42:8080) --proxy-type=[http|socks5|none] (default is http) --proxy-auth (eg --proxy-auth=username:password) 其他常用配置参数： --load-images=[yes|no] Load all inlined images (default is ‘yes’). --load-plugins=[yes|no] Load all plugins (i.e. ‘Flash’, ‘Silverlight’, …) (default is ‘no’). --proxy=address:port Set the network proxy. --disk-cache=[yes|no] Enable disk cache (at desktop services cache storage location, default is ‘no’). --ignore-ssl-errors=[yes|no] Ignore SSL errors (i.e. expired or self-signed certificate errors). 也可以通过配置文件方式来设置： 1phantomjs --config=/path/to/config.json somescript.js [arg1 [...]] 常用配置相关参考 Command Line Interface | PhantomJS Proxy Auth In Phantomjs &middot; David Blooman 实例代码 经过测试，发现： phantomjs --proxy=address:port somescript.js [args] 这种方式无法执行成功。 经过测试，发现：在 somescript.js 中设置 page.setProxy(&quot;http://119.5.0.75:808/&quot;); 这种方式也无效。 经过测试，发现：在 somescript.js 中设置 phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &#39;manual&#39;, &#39;&#39;, &#39;&#39;); 这种方式可行。 不使用代理的动态数据请求dynamicproxy.go: 123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)func First(webUrl, jsFileName string) &#123; cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) out, err := cmd.Output() if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(out))&#125;func Second(webUrl, jsFileName string) &#123; // cmd := exec.Command(&quot;phantomjs.exe&quot;, &quot;test.js&quot;, &quot;https://www.cnblogs.com/&quot;) cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) stdout, err := cmd.StdoutPipe() if err != nil &#123; fmt.Println(err) &#125; cmd.Start() content, err := ioutil.ReadAll(stdout) if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(content))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/ip&quot; //&quot;http://httpbin.org/ip&quot; // &quot;http://ip.gs/&quot; // &quot;http://httpbin.org/user-agent&quot; jsfileName := &quot;somescript.js&quot; First(webUrl, jsfileName) // Second(webUrl, jsfileName)&#125; somescript.js: 123456789101112131415161718var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);url=system.args[1];page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; console.log(&apos;Loading &apos;+system.args[1]); if (status==&quot;success&quot;) &#123; // page.render(&apos;a.png&apos;); //网页截屏 system.stdout.writeLine(page.content); // 获取网页内容 // system.stdout.writeLine(page.title); // console.log(page.plainText); // 文本内容 // console.log(page.title); // 网页标题 &#125;else&#123; system.stdout.writeLine(&quot;request error&quot;); &#125;; phantom.exit();&#125;); 使用http代理的动态数据请求dynamicproxy.go: 1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot;)func Third(webUrl, jsFileName,proxyHost,proxyPort string) &#123; // cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName, webUrl) cmd := exec.Command(&quot;phantomjs.exe&quot;, jsFileName,proxyHost,proxyPort, webUrl) out, err := cmd.Output() if err != nil &#123; fmt.Println(err) &#125; fmt.Println(string(out))&#125;func main() &#123; webUrl := &quot;http://httpbin.org/ip&quot; //&quot;http://httpbin.org/ip&quot; // &quot;http://ip.gs/&quot; // &quot;http://httpbin.org/user-agent&quot; jsfileName := &quot;somescript.js&quot; Third(webUrl, jsfileName,&quot;139.224.237.33&quot;, &quot;8888&quot;)&#125; somescript.js: 123456789101112131415161718192021222324252627var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);if (system.args.length&lt;4) &#123; system.stdout.writeLine(&quot;somescript.js &lt;proxyHost&gt; &lt;proxyPort&gt; &lt;URL&gt;&quot;); phantom.exit(1);&#125;else&#123; host=system.args[1]; port=system.args[2]; url = system.args[3];// page.setProxy(&quot;http://119.5.0.75:808/&quot;);//这样设置请求失败// phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &apos;manual&apos;, &apos;&apos;, &apos;&apos;);//这样设置可以phantom.setProxy(host, port, &apos;manual&apos;, &apos;&apos;, &apos;&apos;);page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; if (status==&quot;success&quot;) &#123; system.stdout.writeLine(page.content); // 获取网页内容 &#125;else&#123; console.log(status); system.stdout.writeLine(&quot;error&quot;); &#125;; phantom.exit();&#125;);&#125; 说明：phantom.setProxy(&quot;139.224.237.33&quot;, &quot;8888&quot;, &#39;manual&#39;, &#39;&#39;, &#39;&#39;); 参数1为代理host;参数2为代理port;参数3可以保持默认定值manual,参数4为代理类型http socket5等可为空;参数5不知道为空。 忽略https安全验证的动态数据请求 暂时只找到一种方法，直接请求https网址不使用代理能够请求成功。 即忽略https安全验证，又使用代理经测试请求失败。 直接在命令窗口中执行可以，通过golang调用请求失败。 使用参数：--ignore-ssl-errors=true --ssl-protocol=any 设置。 如下方式执行成功，示例代码： 1phantomjs.exe --ignore-ssl-errors=true --ssl-protocol=any test.js https://kyfw.12306.cn/otn/ test.js: 1234567891011121314var page =require(&apos;webpage&apos;).create();system=require(&apos;system&apos;);url=system.args[1];page.settings.userAgent = &apos;Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/37.0.2062.120 Safari/537.36&apos;;page.open(url,function(status)&#123; console.log(&apos;Loading &apos;+system.args[1]); if (status==&quot;success&quot;) &#123; system.stdout.writeLine(page.content); // 获取网页内容 &#125;else&#123; console.log(&quot;request error&quot;); &#125;; phantom.exit();&#125;); 相关参考 –ignore-ssl-errors not working · Issue #12181 · ariya/phantomjs · GitHub phantomjs · GitHub phantomjs/examples at master · ariya/phantomjs · GitHub]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从0到1学Golang之基础--Go 数组]]></title>
    <url>%2F2017%2F05%2F24%2Flearn-golang-from-0-to-1-of-go-array%2F</url>
    <content type="text"><![CDATA[《Go In Action》 中文版 《Go语言实战》 读书笔记 内部实现数组是切片和映射的基础数据结构。 在Go语言中，数组是长度固定的数据类型，用于存储一段具有相同类型的元素的连续块。 数组存储的类型可以是内置类型，如整型或字符串，也可以是某种结构类型。 数组占用的内存是连续分配的。由于内存连续，CPU能把正在使用的数据缓存更久的时间。而且内存连续很容易计算索引，可以快速迭代数组里的所有元素。 特点： 长度固定 类型相同 内存连续 声明和初始化声明数组声明的原则： 指明存储数据的类型 指明存储元素数量（指明数组长度） 12#声明一个包含5个元素的整型数组var array [5]int 数组一旦声明后，数组里存储的数据类型和数组长度就不能改变了。 当数组初始化时，数组内每个元素都初始化为对应类型的零值。 声明并初始化使用数组字面量声明并初始化数组。数组字面量允许声明数组里元素的数量同时指定每个元素的值。 Go为我们提供了 := 操作符，可以让我们在创建数组的时候直接初始化。 12# 声明并初始化array:=[5]int&#123;1,2,3,4,5&#125; 自动推导数组长度使用 ... 替代数组的长度，Go语言会根据初始化时数组元素的数量来确定该数组的长度。 12# 容量由初始化值的数量决定array:=[...]int&#123;1,2,3,4,5&#125; 用具体值初始化特定索引使用指定索引的方式初始化特定索引值。 12# 用具体值初始化索引为1和3的元素，其余元素保持零值array:=[5]int&#123;1:10,3:30&#125; 使用数组要访问数组里某个单独元素，使用索引操作符 [] 即可。因为内存是连续的，所以索引访问的效率非常高。 1234# 声明一个包含5个元素的整形数组array:=[5]int&#123;1,2,3,4,5&#125;# 修改索引为2的元素值array[2]=80 遍历访问数组使用 for 遍历访问数组 123456func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; for i := 0; i &lt; 5; i++ &#123; fmt.Printf(&quot;索引：%d,值：%d\n&quot;, i, array[i]) &#125;&#125; 使用 for range 遍历访问数组每个元素 123456func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; for k, v := range array &#123; fmt.Printf(&quot;索引：%d,值：%d\n&quot;, k, v) &#125;&#125; 数组相互赋值同样类型的数组是可以相互赋值的，不同类型的不行，会编译错误。 数组变量的类型包括数组长度和每个元素的类型。只有这两部分都相同的数组，才是类型相同的数组，才能相互赋值。 12345678910func main() &#123; array := [5]int&#123;1, 2, 3, 4, 5&#125; //# 相同数组类型，能够互相赋值 // var array1 [5]int = array // fmt.Println(array1) //[1 2 3 4 5] //不同数组类型，不能互相赋值 var array2 [4]int = array //cannot use array (type [5]int) as type [4]int in assignment fmt.Println(array2)&#125; 指针数组在数组的类型前面加 * 声明为指针数组组。 使用 * 运算符可以访问指针数组元素指针所指向的值。 1234567891011func main() &#123; // # 声明指向整数的数组，用整形指针初始化索引为0和3的数组元素 array := [5]*int&#123;0: new(int), 3: new(int)&#125; // # 为索引为0和3的元素赋值 *array[0] = 10 *array[3] = 40 fmt.Println(array) // [0xc420070188 &lt;nil&gt; &lt;nil&gt; 0xc4200701b0 &lt;nil&gt;]&#125; 上面的示例要注意，我们只可以给索引0 和 3 赋值，因为只有它们分配了内存，才可以赋值。如果给其他索引赋值，运行时会提示无效内存或nil指针引用。要解决这个问题，需要先给这些索引分配内存，然后再进行赋值修改操作。 123456789101112......// # 为未分配内存的索引赋值，报错 *array[2] = 30// panic: runtime error: invalid memory address or nil pointer dereference// [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x2199]// # 先分配内存再赋值array[2] = new(int)*array[2] = 35fmt.Println(array)// [0xc420074188 &lt;nil&gt; 0xc4200741d0 0xc4200741b0 &lt;nil&gt;] 指针数组相互赋值复制数组指针，只会复制指针的值，而不会复制指针所指向的值。 1234567891011121314151617181920212223func main() &#123; // # 声明第一个包含3个元素的指向字符串的指针数组 var array1 [3]*string // # 声明第一个包含3个元素的指向字符串的指针数组 var array2 [3]*string // # 使用字符串指针初始化这个数组 array2 = [3]*string&#123;new(string), new(string), new(string)&#125; // # 使用颜色为每个元素赋值 *array2[0] = &quot;red&quot; *array2[1] = &quot;blue&quot; *array2[2] = &quot;green&quot; // # 将array2 复制给 array1 array1 = array2 // # 复制之后，两个数组指向同一组字符串 fmt.Println(array1) fmt.Println(array2) // [0xc420074030 0xc420074040 0xc420074050] // [0xc420074030 0xc420074040 0xc420074050]&#125; 多维数组数组本身只有一个维度，可以组合多个数组创建多维数组。 声明多维数组1234567891011121314151617func main() &#123; // # 声明一个二维数组 var array1 [4][2]int fmt.Println(array1) // [[0 0] [0 0] [0 0] [0 0]] // # 使用数组字面量来声明并初始化一个二维数组 array2 := [4][2]int&#123;&#123;10, 11&#125;, &#123;20, 21&#125;, &#123;30, 31&#125;, &#123;40, 41&#125;&#125; fmt.Println(array2) // [[10 11] [20 21] [30 31] [40 41]] // # 声明并初始化外层数组中索引为1 和 3 的元素 array3 := [4][2]int&#123;1: &#123;20, 21&#125;, 3: &#123;40, 41&#125;&#125; fmt.Println(array3) // [[0 0] [20 21] [0 0] [40 41]] // # 声明并初始化外层数组和内层数组的当个元素 array4 := [4][2]int&#123;1: &#123;0: 20&#125;, 3: &#123;1: 41&#125;&#125; fmt.Println(array4) // [[0 0] [20 0] [0 0] [0 41]]&#125; 声明多维数组时，第一维度的数组长度也可以使用 ... 来根据数组值的个数来确定，但后面维度不能使用 ...来自动推测。 12345func main() &#123; b := [...][2]int&#123;&#123;1, 1&#125;, &#123;2, 2&#125;, &#123;3, 3&#125;&#125; fmt.Println(b) // [[1 1] [2 2] [3 3]] fmt.Println(len(b)) // 3&#125; 访问二维数组元素为了访问单个元素，需要反复组合使用 [] 运算符。 123456789101112func main() &#123; // # 声明一个二维数组 var array1 [4][2]int fmt.Println(array1) // [[0 0] [0 0] [0 0] [0 0]] // # 设置指定元素的值 array1[1][0] = 5 fmt.Println(array1) // [[0 0] [5 0] [0 0] [0 0]] // # 获取指定位置的元素 fmt.Println(array1[1][0]) //5&#125; 多维数组相互赋值多维数组的类型包括每一维度的藏毒以及最终存储在元素中的数据的类型。只要类型一致，就可以将多维数组互相赋值。 1234567func main() &#123; array1 := [2][2]int&#123;&#123;1, 2&#125;, &#123;3, 4&#125;&#125; var array2 [2][2]int array2 = array1 fmt.Println(array2) // [[1 2] [3 4]]&#125; 在函数间传递数组在函数间传递变量时，总是以值的形式传递。如果变量是个数组，那么就会整个复制，并传递给函数，如果数组非常大，对于内存是一个很大的开销。 12345678910func main() &#123; array := [5]int&#123;1: 2, 3: 4&#125; modify(array) fmt.Println(array) //[0 2 0 4 0]&#125;func modify(a [5]int) &#123; a[1] = 3 fmt.Println(a) // [0 3 0 4 0]&#125; 如示例，数组是复制的，原来的数组没有修改。如果复制的数组非常大，对内存是一个非常大的浪费。 可以通过传递数组的指针的方式来在函数间传递大数组。 使用指针在函数间传递大数组传递数组的指针，复制的大小只是一个数组类型的指针大小。 12345678910func main() &#123; array := [5]int&#123;1: 2, 3: 4&#125; modify(&amp;array) fmt.Println(array) //[0 3 0 4 0]&#125;func modify(a *[5]int) &#123; a[1] = 3 fmt.Println(*a) // [0 3 0 4 0]&#125; 如示例，通过传递数组的指针，会发现原来的数组也被修改了。要意识到的是，因为传递的是指针，所以如果改变指针指向的值，会改变共享的内存。 使用切片能更好的处理内存共享问题。 这里注意，数组的指针和指针数组是两个概念，数组的指针是 *[5]int,指针数组是 [5]*int，注意 * 的位置。 总结概括数组知识点 数组是值类型，赋值和传参会复制整个数组，而不是指针。 数组长度必须是常量，且是类型的组成部分。[2]int 和 [3]int 是不同类型。 支持 &quot;==&quot;、&quot;!=&quot; 操作符，因为内存总是被初始化过的。 指针数组 [n]*T，数组指针 *[n]T。 值拷贝行为会造成性能问题，通常会建议使用 slice，或数组指针。 声明并初始化12345func main() &#123; // a := [3]int&#123;1, 2&#125; //未初始化元素值未数组类型零值 // b := [...]int&#123;1, 2, 3, 4&#125; //通过初始化值确定数组长度 // c := [5]int&#123;2: 10, 4: 20&#125; // 使用索引号初始化元素&#125; 多维数组1234func main() &#123; d := [2][3]int&#123;&#123;1, 2, 3&#125;, &#123;4, 5, 6&#125;&#125; //多维数组 e := [...][2]int&#123;&#123;1, 1&#125;, &#123;2, 2&#125;, &#123;3, 3&#125;, &#123;4, 4&#125;&#125; //第 2 维度不能用 &quot;...&quot;&#125; 内置函数 len 和 cap 都返回数组长度 (元素数量)1234func main() &#123; f := [2]int&#123;&#125; fmt.Println(len(f), cap(f)) // 2 2 &#125;]]></content>
      <categories>
        <category>从0到1学Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从0到1学Golang之基础--Go 包]]></title>
    <url>%2F2017%2F05%2F12%2Flearn-golang-from-0-to-1-of-go-package%2F</url>
    <content type="text"><![CDATA[《Go In Action》 中文版 《Go语言实战》 读书笔记 什么是包go语言的包其实就是我们计算机里的目录 包的命名所有的 .go 文件，除了空行和注释，都应该在第一行声明自己所属的包。 使用 package 关键字声明包。如： package main 。 每个包都在一个单独的目录里。也就是说，同一个目录下的所有 .go 文件必须声明同一个包名。 以 net/http 包为例，在 http 目录下的所有文件都属于 http 包。 go语言中给包及其目录命名，遵循 简洁 、清晰 、全小写 及 和所在目录同名 的原则。 1234567package mainimport &quot;net/http&quot;func main() &#123; http.ListenAndServe(&quot;127.0.0.1:80&quot;,handler);&#125; 如上 net/http，在导入包时采用 全路径 的方式，所以可以区分同名的不同包，只要保证全路径不同就可以。使用全路径的导入，也增加了包名命名的灵活性。 main 包在go语言中，命名为 main 的包会被尝试编译为一个二进制可执行文件。 所有用go语言编译的可执行程序都必须有一个名为 main 的包。 一个 main 的包，一定会包含一个 main() 函数。 在Go语言里同时要满足 main 包和包含 main() 函数，才会被编译成一个可执行文件。 Go程序编译时，会使用声明 main 包的代码所在的目录的目录名作为二进制可执行文件的文件名。 包的导入使用 import 关键字来导入包。导入的包必须是一个全路径的包，也就是包所在的位置。 导入单个包： 1import &quot;fmt&quot; 导入多个包时，使用一对括号包含的导入块，每个包独占一行。 12345import ( &quot;fmt&quot; &quot;net/http&quot; &quot;strings&quot;) 对于多于一个路径的包名，在代码中引用的时候，使用全路径最后一个包名作为引用的包名，比如 net/http ,我们在代码使用的是 http ，而不是 net 。 Go有两个很重要的环境变量 GOROOT 和 GOPATH ,这是两个定义路径的环境变量，GOROOT是安装Go的路径，比如/usr/local/go；GOPATH是我们自己定义的开发者个人的工作空间，比如 /home/myproject/go 。 标准库中的包会在 GOROOT 去查找，Go开发者创建的包会在 GOPATH 指定的目录中查找。 对于包的查找，是有优先级的，编译器会优先在 GOROOT 里搜索，其次是 GOPATH ,一旦找到，就会马上停止搜索。如果最终都没找到，就报编译异常了。 远程导入Go语言的工具链支持从Github、Bitbucket等类似网站获取源代码。 1import &quot;github.com/spf13/viper&quot; 用导入路径编译程序时，gobuild 命令会先在 GOPATH 下搜索这个包，如果没有找到，就会使用 go get 工具通过URL从网络获取，并把包的源代码保存在 GOPATH 目录下对应URL的目录里。 go get 工具可以递归获取依赖包。 命名导入如果要导入的多个包具有相同的名字，可以通过 命名导入 的方式来导入。 命名导入是指在 import 语句给出的包路径的左侧定义一个名字，将导入的包命名为新名字。 1234import ( &quot;fmt&quot; myfmt &quot;mylib/fmt&quot;) Go语言规定，导入的包必须要使用，否则会报编译错误。Go语言的这个特性可以防止导入了未被使用的包，避免代码变得臃肿。 但是有时候我们需要导入一个包，但是不需要引用这个包的标识符。这种情况下，可以使用空白标识符 _ 来重命名导入的包即可。 123456package mainimport ( &quot;fmt&quot; _ &quot;mylib/fmt&quot;) 空白标识符(_) 用来抛弃不想继续使用的值，如给导入的包赋予一个空名字，或忽略函数返回的不感兴趣的值。 init函数每个包都可以有任意多个init函数，这些init函数都会在main函数之前执行。init函数通常用来做初始化变量、设置包或者其他需要在程序执行前的引导工作。init函数用在设置包、初始化变量或者其他要在程序运行前优先完成的引导工作。 以数据库驱动为例， database 下的驱动在启动时执行 init 函数会将自身注册到 sql 包里，因为 sql 包在编译时并不知道这些驱动的存在，等启动之后 sql 才能调用这些驱动。 123456789package postgresimport ( &quot;database/sql&quot;)func init() &#123; sql.Register(&quot;postgres&quot;, new(PostgresDriver))&#125; 因为我们只是想执行这个 postgres 包的 init 方法，并不想使用这个包，所以我们在导入的时候，需要使用空白标识符 _ 来重命名包名，避免编译错误。 12345678910package mainimport ( &quot;database/sql&quot; _ &quot;github.com/goinaction/code/chapter3/dbdriver/postgres&quot;)func main() &#123; sql.Open(&quot;postgres&quot;, &quot;mydb&quot;)&#125; 如上非常简洁，剩下很对数据库的操作，都是使用 database/sql 标准接口。如果我们想换其他数据库驱动，只需要换个导入即可，灵活方便。]]></content>
      <categories>
        <category>从0到1学Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Golang运行环境配置]]></title>
    <url>%2F2017%2F04%2F02%2Fgolang-running-environment-configuration%2F</url>
    <content type="text"><![CDATA[Win系统下配置Go语言环境 从网站 Downloads - The Go Programming Language 下载 go1.6.3.windows-amd64.msi 安装包。 运行并安装到默认目录 C:\Go 目录下。 配置 GOROOT 和 GOPATH : 在 系统的环境变量中的 PATH 变量中添加Go的目录 C:\Go\bin; (通过安装包安装后已默认设置该项) 在 系统的环境变量中添加 GOROOT 变量，设置值为 C:\Go\ (通过安装包安装后已默认设置该项) 要验证 GOROOT 是否设置成功，我们可以在命令行窗口中输入 go version，如果输出了Go的版本信息则说明配置正确。 GOPATH 就需要我们手动配置一下，GOPATH 就是你的工作目录，用于存放项目和go依赖包等。假设目录 E:\GOProject 为我的Go项目工作目录，该工作目录下默认包含三个子目录：bin/ pkg/ src 。然后我们在 系统的环境变量中 新建 GOPATH 变量，设置值为 E:\GOProject;。默认情况下 GOPATH 目录可以设置多个，之间用分号 ; 分隔。 然后在命令行窗口中输入 echo %GOPATH% 如果打印出了上面设置的 GOPATH 的目录，则说明配置成功。 为了验证Go开发环境是否设置成功，我们可以在命令行下输入如下命令：(保证已经安装Git) 1go get github.com/golang/example/hello 然后执行命令： 1%GOPATH%/bin/hello 如果输出了 Hello,Go examples! 则说明Go语言的开发环境搭建成功。 参考自：Easy Go Programming Setup for Windows Wade Wegner Win下配置Golang开发环境添加多个工作目录我一般会设置两个目录用作我的工作项目。一般我会命名为 xgo 和 xgo_workspace ，一个用来存储网络上其他的Golang依赖项目，一个作为我自己的开发项目存放位置。 在Windows系统下安装上Go的msi安装包后，默认的 GOPATH 目录为当前管理员账户目录下的go文件夹：C:\Users\xxxx\go 中，在 Cmder 控制台中通过 go env 查看： 12345678910111213141516171819202122λ go env set GOARCH=amd64 set GOBIN= set GOEXE=.exe set GOHOSTARCH=amd64 set GOHOSTOS=windows set GOOS=windows set GOPATH=C:\Users\xxxx\go set GORACE= set GOROOT=C:\Go set GOTOOLDIR=C:\Go\pkg\tool\windows_amd64 set GCCGO=gccgo set CC=gcc set GOGCCFLAGS=-m64 -mthreads -fmessage-length=0 set CXX=g++ set CGO_ENABLED=1 set CGO_CFLAGS=-g -O2 set CGO_CPPFLAGS= set CGO_CXXFLAGS=-g -O2 set CGO_FFLAGS=-g -O2 set CGO_LDFLAGS=-g -O2 set PKG_CONFIG=pkg-config 在 环境变量 下新增 GOPATH 项，添加值为 E:\GOProject\xgo;E:\GOProject\xgo_workspace ，注意多个目录在windows下使用分号 ; 分隔，重启 Cmder 再次通过 go env 查看： 12345678910111213141516171819202122λ go envset GOARCH=amd64set GOBIN=set GOEXE=.exeset GOHOSTARCH=amd64set GOHOSTOS=windowsset GOOS=windowsset GOPATH=E:\GOProject\xgo;E:\GOProject\xgo_workspaceset GORACE=set GOROOT=C:\Goset GOTOOLDIR=C:\Go\pkg\tool\windows_amd64set GCCGO=gccgoset CC=gccset GOGCCFLAGS=-m64 -mthreads -fmessage-length=0set CXX=g++set CGO_ENABLED=1set CGO_CFLAGS=-g -O2set CGO_CPPFLAGS=set CGO_CXXFLAGS=-g -O2set CGO_FFLAGS=-g -O2set CGO_LDFLAGS=-g -O2set PKG_CONFIG=pkg-config Mac下配置Golang开发环境通过brew安装1$ brew install go 通过pkg包安装从 golang官网 下载Mac下的pkg安装包直接安装. 环境变量配置GOPATH允许多个目录，当有多个目录时，请注意分隔符，多个目录的时候Windows是分号 ;，Linux系统及Mac下是冒号 :，当有多个GOPATH时，默认会将 go get 的内容放在第一个目录下。 123456789101112131415$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOEXE=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;CC=&quot;clang&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/mk/7c0w24ts0ps1g06q78gzd7dc0000gn/T/go-build098119519=/tmp/go-build -gno-record-gcc-switches -fno-common&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot; 假如我的go项目开发主目录为:/Users/xxx/Learn/Go在该目录下,第一个目录为 xgo 第二个目录为 xgo_workspace 12345# GOPATHexport GOPATH=$HOME/Learn/Go/xgo:$HOME/Learn/Go/xgo_workspace# GOPATH binexport PATH=$PATH:$GOPATH/bin 添加完成后,重启终端即可生效.如果想立即生效,则可执行如下命令: 1$ source ~/.bash_profile 再次查看go环境变量: 123456789101112131415$ go envGOARCH=&quot;amd64&quot;GOBIN=&quot;&quot;GOEXE=&quot;&quot;GOHOSTARCH=&quot;amd64&quot;GOHOSTOS=&quot;darwin&quot;GOOS=&quot;darwin&quot;GOPATH=&quot;/Users/xxx/Learn/Go/xgo:/Users/xxx/Learn/Go/xgo_workspace&quot;GORACE=&quot;&quot;GOROOT=&quot;/usr/local/go&quot;GOTOOLDIR=&quot;/usr/local/go/pkg/tool/darwin_amd64&quot;CC=&quot;clang&quot;GOGCCFLAGS=&quot;-fPIC -m64 -pthread -fno-caret-diagnostics -Qunused-arguments -fmessage-length=0 -fdebug-prefix-map=/var/folders/mk/7c0w24ts0ps1g06q78gzd7dc0000gn/T/go-build346222074=/tmp/go-build -gno-record-gcc-switches -fno-common&quot;CXX=&quot;clang++&quot;CGO_ENABLED=&quot;1&quot; http://blog.helloarron.com/2015/08/29/go/mac-install-go/ https://github.com/astaxie/build-web-application-with-golang/blob/master/zh/01.2.md http://blog.studygolang.com/2013/01/%E5%86%8D%E7%9C%8Bgopath/ (设置多个目录时只会将最后一个目录添加上bin 这里要说明) Update 2017-11-28 更新windows下设置多个工作目录的说明]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言学习资料整理]]></title>
    <url>%2F2017%2F03%2F31%2Flearning-golang%2F</url>
    <content type="text"><![CDATA[整理网上找到的Golang语言学习资料 基础基础教程 书籍在线版 Go 指南-A Tour of Go Go语言圣经（中文版） Effective Go中文版 Go Web编程 build-web-application-with-golang Go入门指南 The Way to Go 《The Way to Go》中文译本，中文正式名《Go入门指南》 Golang学习室 Go轻松学 TechDoc 《Go实战开发》 go-best-practice 基础教程 书籍离线版 GitHub - qyuhen/book: 学习笔记 基础教程 视频 Go编程基础 Go编程基础_免费高速下载|百度网盘-分享无限制 Web Go Web 基础 - 网易云课堂 beego开发文档 进阶 深入解析Go go-internals Go名库讲解 - 网易云课堂 Go语言标准库 GO 命令教程 : Golang command tutorial in Chinese. 理解Go语言的nil - 简书 工具 Go Walker - Go 语言在线 API 文档 Go 语言包管理 Rego - A Go regular expression tester 项目 Projects · golang/go Wiki · GitHub Golang大牛 Unknwon (无闻) · GitHub qyuhen (Q.yuhen) · GitHub Go 开发工具 gosublimetext 插件 GitHub - DisposaBoy/GoSublime: A Golang plugin collection for SublimeText 3, providing code completion and other IDE-like features. Wise Turtles - Go学习笔记3之打造Sublime Text&nbsp;3作为Go的集成开发环境 Go语言编辑器IDE之JetBrains篇(PyCharm+go插件plugin) Sublime Text3 &#43; Golang搭建开发环境_随笔 - Vckai的个人技术博客. - Vckai.com Sublime Text 2搭建Go开发环境（Windows） - Bill Yuan - 博客园 Ubuntu 配置 Go 语言开发环境（Sublime Text+GoSublime） - 抛弃世俗之浮躁，留我钻研之刻苦 - 开源中国社区 相关参考 Golang学习历程 - 简书 GitHub - Unknwon/go-study-index: Go 语言学习资料索引 Go 标准库介绍 ironxu GO语言学习资源整理 - 知乎专栏 GO-Start/Go语言中的闭包.md at master · carryxyh/GO-Start · GitHub Go的文件操作 - 谢权SELF Go语言并发机制初探-博客-云栖社区-阿里云 Go语言实战笔记 Go学习【二】学习资料 - 一起学习 go - SegmentFault GO语言零基础入门资料整理 - 简书 Go简明教程 电子书教程Go 语言基础 go语言入门 · GitBook go语言教程 《学习GO语言》中文版 《学习GO语言》GitHub - mikespook/Learning-Go-zh-cn: 一本学习 Go 语言的免费电子书。 GitHub - Unknwon/go-fundamental-programming: 《Go编程基础》是一套针对 Google 出品的 Go 语言的视频语音教程，主要面向新手级别的学习者。 GitHub - Unknwon/go-rock-libraries-showcases: 《Go名库讲解》是一套针对 Google 出品的 Go 语言的第三方库进行评测讲解的集博客、示例与语音视频为一体的综合教程，适合完成学习完成《Go编程基础》教程的学习者。 GitHub - Unknwon/the-way-to-go_ZH_CN: 《The Way to Go》中文译本，中文正式名《Go入门指南》 前言 | Go语言圣经 Go Web 开发 GitHub - Unknwon/go-web-foundation: 《Go Web基础》是一套针对 Google 出品的 Go 语言的视频语音教程，主要面向完成《Go编程基础》教程后希望进一步了解有关 Go Web 开发的学习者。 《GO WEB编程》 视频教程 跟无闻学Go语言：Go编程基础视频教程（共15课时）_在线自学视频教程_51CTO学院 跟无闻学Go语言：Go Web基础视频教程（共12课时）_在线自学视频教程_51CTO学院 Go语言第一课_Go语言视频教程-慕课网 Go编程基础 Golang编程基础 Go全套]]></content>
      <categories>
        <category>Golang</category>
      </categories>
      <tags>
        <tag>Golang</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs个性化设置]]></title>
    <url>%2F2017%2F03%2F27%2Fdocker-ubuntu-gogs-custom%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 个性化的配置 Docker Gogs 首页样式。 Gogs MIT开源协议 Gogs 项目代码 100% 开源并可无条件免费使用。所有的源代码均通过 MIT 授权协议 托管在 GitHub 上。 准备工作在Docker宿主机和容器之间拷贝文件的命令以下命令均在 宿主机 上执行。 12345# 拷贝文件从宿主机至容器：$ docker cp localfile &lt;ConName&gt;:/app/confile# 拷贝文件从容器至宿主机：$ docker cp &lt;ConName&gt;:/app/confile localfile 将待处理文件进行备份操作使用 docker exec 命令进入运行中的容器： 1$ docker exec -it &lt;ConName&gt; /bin/bash 备份Gogs目录下的以下文件： templates/home.tmpl templates/base/head.tmpl templates/base/footer.tmpl 1docker@ConName/templates# cp ./home.tmpl ./home.tmpl.tmp 更改首页介绍 只保留Logo区域首页中部内容 – home.tmpl – 去除首页中下部分介绍，只保留Logo区域 将容器内的 home.tmpl 文件拷贝至宿主机本地： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl ./home.tmpl 修改首页站点介绍网站标题和介绍部分在页面中的 div.hero 部分： 123456&lt;div class="hero"&gt; &lt;h1 class="ui icon header title"&gt; ... &lt;/h1&gt; &lt;h2&gt;...&lt;/h2&gt;&lt;/div&gt; 这里我将站点介绍修改为了 ： 1&lt;h2&gt;用了雪哥Git库 从此编程不再吐&lt;/h2&gt; 隐藏首页站点说明部分说明部分我仅以 简体中文 和 English 两种语言的修改来说明： 中文说明部分：内容在页面中的1&#123;&#123;else if eq .Lang &quot;zh-CN&quot;&#125;&#125; 和1&#123;&#123;else if eq .Lang &quot;fr-FR&quot;&#125;&#125; 之间： 1234&#123;&#123;else if eq .Lang "zh-CN"&#125;&#125; ... ...&#123;&#123;else if eq .Lang "fr-FR"&#125;&#125; 英文说明部分：内容在页面中的1&#123;&#123;else&#125;&#125; 和1&#123;&#123;end&#125;&#125; 之间： 1234&#123;&#123;else&#125;&#125; ... ...&#123;&#123;end&#125;&#125; 将这两部分的内容删除或用 &lt;!-- --&gt; 隐藏。 更改完成后，保存，并更新回容器中： 1$ docker cp ./home.tmpl &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl 去除未登录用户左上角显示的“帮助”按钮及更换背景图案头部导航 – head.tmpl – 去除未登录用户左上角显示的“帮助”按钮 先从容器中获取该文件： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl ./head.tmpl 去除未登录用户左上角显示的“帮助”按钮将如下部分代码中的 &lt;a&gt;...&lt;/a&gt; 注释掉或删除，修改后如下： 1234&#123;&#123;else&#125;&#125; &lt;!--&lt;a class="item" target="_blank" href="https://gogs.io/docs" rel="noreferrer"&gt;&#123;&#123;.i18n.Tr "help"&#125;&#125;&lt;/a&gt;--&gt; &lt;div class="right menu"&gt; 更改首页背景图案仿照 https://gogs.io/ 首页在 head.tmpl 页面中找到如下部分: 123&lt;!-- Stylesheet --&gt;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/semantic-2.2.7.min.css"&gt;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/gogs.css?v=&#123;&#123;MD5 AppVer&#125;&#125;"&gt; 在这段下面添加如下代码: 123&#123;&#123;if .PageIsHome&#125;&#125;&lt;link rel="stylesheet" href="&#123;&#123;AppSubUrl&#125;&#125;/css/gghome.min.css"&gt;&#123;&#123;end&#125;&#125; 然后在本地新建名为 gghome.min.css 的样式文件，注意文件的格式为 UTF-8 且行结束标识为 Unix(LF) ，添加如下样式： 1.full.height&#123;background-color:#0F8DEC;background-image:url("data:image/svg+xml,%3Csvg width='304' height='304' viewBox='0 0 304 304' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='M44.1 224c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H0v-2h44.1zm160 48c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H82v-2h122.1zm57.8-46c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H304v2h-42.1zm0 16c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H304v2h-42.1zm6.2-114c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4h-86.2c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h86.2zm-256-48c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H0v-2h12.1zm185.8 34c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h86.2c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4h-86.2zM258 12.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V0h2v12.1zm-64 208c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-54.2c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9v54.2zm48-198.2c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V82h64v-2h-62V21.9zm16 16c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V66h48v-2h-46V37.9zm-128 96c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V210h16v10.1c-2.282.463-4 2.48-4 4.9 0 2.76 2.24 5 5 5s5-2.24 5-5c0-2.42-1.718-4.437-4-4.9V208h-16v-74.1zm-5.9-21.9c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H114v48H85.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H112v-48h12.1zm-6.2 130c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H176v-74.1c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V242h-60.1zm-16-64c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H114v48h10.1c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H112v-48h-10.1zM66 284.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V274H50v30h-2v-32h18v12.1zM236.1 176c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H226v94h48v32h-2v-30h-48v-98h12.1zm25.8-30c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H274v44.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V146h-10.1zm-64 96c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H208v-80h16v-14h-42.1c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H226v18h-16v80h-12.1zm86.2-210c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H272V0h2v32h10.1zM98 101.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V144H53.9c-.463-2.282-2.48-4-4.9-4-2.76 0-5 2.24-5 5s2.24 5 5 5c2.42 0 4.437-1.718 4.9-4H98v-44.1zM53.9 34c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H80V0h2v34H53.9zm60.1 3.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V64H80v64H69.9c-.463-2.282-2.48-4-4.9-4-2.76 0-5 2.24-5 5s2.24 5 5 5c2.42 0 4.437-1.718 4.9-4H82V66h32V37.9zM101.9 82c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H128V37.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V82h-28.1zm16-64c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H146v44.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9V18h-26.1zm102.2 270c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H98v14h-2v-16h124.1zM242 149.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9V162h16v30h-16v66h48v46h2v-48h-48v-62h16v-34h-16v-10.1zM53.9 18c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H64V2H48V0h18v18H53.9zm112 32c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H192V0h50v2h-48v48h-28.1zm-48-48c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5 0-.342.034-.677.1-1h2.07c-.11.313-.17.65-.17 1 0 1.657 1.343 3 3 3s3-1.343 3-3c0-.35-.06-.687-.17-1H178v34h-18V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V32h14V2h-58.1zm0 96c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H137l32-32h39V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V66h-40.172l-32 32H117.9zm28.1 90.1c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-76.513L175.586 80H224V21.9c-2.282-.463-4-2.48-4-4.9 0-2.76 2.24-5 5-5s5 2.24 5 5c0 2.42-1.718 4.437-4 4.9V82h-49.586L146 112.414V188.1zm16 32c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-99.513L184.586 96H300.1c.398-1.96 1.94-3.502 3.9-3.9v2.07c-1.165.413-2 1.524-2 2.83s.835 2.417 2 2.83v2.07c-1.96-.398-3.502-1.94-3.9-3.9H185.414L162 121.414V220.1zm-144-64c2.282.463 4 2.48 4 4.9 0 2.76-2.24 5-5 5s-5-2.24-5-5c0-2.42 1.718-4.437 4-4.9v-3.513l48-48V48h32V0h2v50H66v55.413l-48 48v2.687zM50 53.9c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9v42.686l-48 48V210h28.1c.463 2.282 2.48 4 4.9 4 2.76 0 5-2.24 5-5s-2.24-5-5-5c-2.42 0-4.437 1.718-4.9 4H2v-62.586l48-48V53.9zm-16 16c2.282-.463 4-2.48 4-4.9 0-2.76-2.24-5-5-5s-5 2.24-5 5c0 2.42 1.718 4.437 4 4.9v18.686l-32 32v2.828l34-34V69.9zM12.1 32c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H9.414L0 43.414v-2.828L8.586 32H12.1zm265.8 18c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h18.686L304 40.586v2.828L297.414 50H277.9zm-16 160c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H288V136.587l16-16v2.827l-14 14V210h-28.1zm-208 32c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H64v-22.586L40.586 194H21.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h19.513L66 216.586V242H53.9zm150.2 14c.463-2.282 2.48-4 4.9-4 2.76 0 5 2.24 5 5s-2.24 5-5 5c-2.42 0-4.437-1.718-4.9-4H96v-56.598L56.598 162H37.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h19.502L98 200.598V256h106.1zm-150.2 2c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4H80v-46.586L48.586 178H21.9c-.463 2.282-2.48 4-4.9 4-2.76 0-5-2.24-5-5s2.24-5 5-5c2.42 0 4.437 1.718 4.9 4h27.513L82 208.586V258H53.9zM97 100c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-48 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 96c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-144c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-96 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm96 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-32 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM49 36c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-32 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM33 68c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 240c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm80-176c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 48c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm112 176c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm-16 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM17 180c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0 16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm0-32c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16 0c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM17 84c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm32 64c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zm16-16c1.657 0 3-1.343 3-3s-1.343-3-3-3-3 1.343-3 3 1.343 3 3 3zM34 39.793V0h-2v40.586L8.586 64H0v2h9.413L34 41.414v-1.62zM2 300.1V258h14v46h2v-48H0V302.17c.313-.11.65-.17 1-.17 1.306 0 2.417.835 2.83 2H5.9c-.398-1.96-1.94-3.502-3.9-3.9zM34 241v63h-2v-62H0v-2h34v1zM17 18h1V0h-2v16H0v2h17zm273-2V0h-2v18h16v-2h-14zm-32 273v15h-2v-14h-14v14h-2v-16h18v1zM0 92.1c.323-.066.658-.1 1-.1 2.76 0 5 2.24 5 5s-2.24 5-5 5c-.342 0-.677-.034-1-.1v-2.07c.313.11.65.17 1 .17 1.657 0 3-1.343 3-3s-1.343-3-3-3c-.35 0-.687.06-1 .17V92.1zM80 272h2v32h-2v-32zm37.9 32c-.463-2.282-2.48-4-4.9-4-2.42 0-4.437 1.718-4.9 4h2.07c.413-1.165 1.524-2 2.83-2s2.417.835 2.83 2h2.07zM5.9 0c.066.323.1.658.1 1 0 2.76-2.24 5-5 5-.342 0-.677-.034-1-.1V3.83C.313 3.94.65 4 1 4c1.657 0 3-1.343 3-3 0-.35-.06-.687-.17-1H5.9zm294.2 0c-.066.323-.1.658-.1 1 0 2.42 1.718 4.437 4 4.9V3.83c-1.165-.413-2-1.524-2-2.83 0-.35.06-.687.17-1h-2.07zm3.9 300.1c-1.96.398-3.502 1.94-3.9 3.9h2.07c.302-.852.978-1.528 1.83-1.83v-2.07z' fill='%23afcfe1' fill-opacity='0.23' fill-rule='evenodd'/%3E%3C/svg%3E")&#125;.hero&#123;color:#fff&#125;.hero .ui.header&#123;color:#fff&#125; 然后将该文件 gghome.min.css 添加到容器中： 1$ docker cp ./gghome.min.css &lt;ConName&gt;:/home/git/gogs/public/css/gghome.min.css 待以上步骤操作完成后，更新回容器中： 1$ docker cp ./head.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl 更改底栏“官方网站”字样为“Gogs官方网站”底部 – footer.tmpl – 更改底栏“官方网站”字样为“Gogs官方网站” 从容器中获取该文件： 1$ docker cp &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl ./footer.tmpl 更改底栏“官方网站”字样为“Gogs官方网站”将以下部分： 1&lt;a target="_blank" href="https://gogs.io"&gt;&#123;&#123;.i18n.Tr "website"&#125;&#125;&lt;/a&gt; 更改为： 1&lt;a target="_blank" href="https://gogs.io"&gt;Gogs&#123;&#123;.i18n.Tr "website"&#125;&#125;&lt;/a&gt; Markdown文档中的链接跳转加上target标签底部 – footer.tmpl – Markdown文档中的链接跳转加上target标签 默认情况下，Gogs项目中的Markdown文档中的链接是在当前页面跳转的，但个人习惯还是喜欢在新页面打开链接。 找到 footer.tmpl 页面中如下代码： 123&lt;script src="&#123;&#123;AppSubUrl&#125;&#125;/js/libs/clipboard-1.5.9.min.js"&gt;&lt;/script&gt;&#123;&#123;template "inject/footer" .&#125;&#125; 在中间位置添加一行： 1&lt;script src="&#123;&#123;AppSubUrl&#125;&#125;/js/mdlinktarget.min.js"&gt;&lt;/script&gt; 在本地创建一个js文件，注意文件的格式为 UTF-8 且行结束标识为 Unix(LF) 并命名为 mdlinktarget.min.js ，内容如下： 1$(document).ready(function()&#123;$('#file-content a[href^="http"]').each(function()&#123;$(this).attr("target","_blank")&#125;)&#125;); 将该js文件拷贝添加到容器中的项目目录下，执行如下命令： 1$ docker cp ./mdlinktarget.min.js &lt;ConName&gt;:/home/git/gogs/public/js/mdlinktarget.min.js 然后将更改后的 footer.tmpl 更新回容器中： 1$ docker cp ./footer.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl 修改完成 重启容器待以上各步骤操作完成后，重启容器。 1$ docker restart gogs 命令整理示例命令123456$ docker cp ./home.tmpl &lt;ConName&gt;:/home/git/gogs/templates/home.tmpl$ docker cp ./footer.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/footer.tmpl$ docker cp ./head.tmpl &lt;ConName&gt;:/home/git/gogs/templates/base/head.tmpl$ docker cp ./mdlinktarget.min.js &lt;ConName&gt;:/home/git/gogs/public/js/mdlinktarget.min.js$ docker cp ./gghome.min.css &lt;ConName&gt;:/home/git/gogs/public/css/gghome.min.css$ docker restart &lt;ConName&gt; 操作命令123456$ docker cp ./home.tmpl gogs:/home/git/gogs/templates/home.tmpl$ docker cp ./footer.tmpl gogs:/home/git/gogs/templates/base/footer.tmpl$ docker cp ./head.tmpl gogs:/home/git/gogs/templates/base/head.tmpl$ docker cp ./mdlinktarget.min.js gogs:/home/git/gogs/public/js/mdlinktarget.min.js$ docker cp ./gghome.min.css gogs:/home/git/gogs/public/css/gghome.min.css$ docker restart gogs 获取文件以上操作的所有文件可以从 Docker Gogs custom files 或 GitHub - Leafney/ubuntu-gogs: Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 中获取。]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Gogs</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs部署及配置时遇到的问题]]></title>
    <url>%2F2017%2F03%2F24%2Fdocker-ubuntu-gogs-problems%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 这里主要记录在Docker下部署Gogs项目过程中遇到的问题及解决方法。 目录 Install页面中的注意问题 Connection timed out 问题 hooks/update: No such file or directory 添加 SSH key 时显示报错页面 500 要求输入git账户密码 SSH Connection refused 问题 Git SSH 使用非默认22端口时，如何隐藏端口号 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! echo 输出 Docker Gogs 使用 HTTPS Install页面中的注意问题 domain: ensure that is the IP address of your docker host SSH port: that is the forwarded ssh port. So if you forward 22 to 10022, it’s 10022. HTTP port: my error, here, you must enter the HTTP in the container. So it’s 3000. Even if you forward it to 10080 ;) Application URL: this is a combination of domain + forwarded HTTP port (I got this one wrong too). So, if you’re forwarding 3000 to 10080, then it’s http://domain:10080. ssh端口使用外部端口，而http端口使用的是容器内部端口. 着重需要说明的是： Domain 填写Docker宿主机的物理IP地址，或者域名地址,注意这里是不带 http的 如： 192.168.137.140 或 git.mydomain.com SSH port 假如Docker映射的端口是 10022:22 那么这里就填写宿主机开放的端口 10022 HTTP port 假如Docker映射的端口是 10080:3000 这里要填容器内的监听端口 3000 Application URL 这里要填写的格式为 http(s):// + Domain + HTTP port ，比如：http://git.mydomain.com/10080 。还需要注意的一点是，如果你用了nginx来映射宿主机的 10080 端口，这里要去掉后面的端口，即 http://git.mydomain.com/，说白了就是你在外部浏览器上访问的地址。 Docker gogs web/ssh does not restart after reboot · Issue #3039 · gogits/gogs · GitHub Connection timed out 问题使用HTTP方式 Push 代码时报错？使用HTTP方式获取： 1234567$ git clone http://gogit.itfanr.cc/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...remote: Counting objects: 8, done.remote: Compressing objects: 100% (6/6), done.remote: Total 8 (delta 1), reused 0 (delta 0)Unpacking objects: 100% (8/8), done.Checking connectivity... done. 使用HTTP方式提交： 12345678$ git pushCounting objects: 3, done.Writing objects: 100% (3/3), 379 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)error: RPC failed; HTTP 504 curl 22 The requested URL returned error: 504 Gateway Time-outfatal: The remote end hung up unexpectedlyfatal: The remote end hung up unexpectedlyEverything up-to-date 使用SSH方式获取代码时报错？使用SSH方式获取： 1234567$ git clone ssh://git@gogit.itfanr.cc:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...ssh: connect to host gogit.itfanr.cc port 10022: Connection timed outfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 对于 Connection timed out 的问题，可能是使用的端口已经被其他程序占用导致，也可能是缓存文件导致。 最后的解决方法是将 data/sessions 中的 session 文件删除，然后更换了其他端口后再次运行则能够提交数据了。 报错 hooks/update: No such file or directory将旧的配置和数据库拷贝到新的Gogs项目下（我这里是从v0.8.25.0129版本迁移到v0.10.18.0313版本），提交代码时会报如下错误： 123456789$ git push origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 432 bytes | 0 bytes/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: hooks/update: line 2: /home/git/gogs/goapp/gogs/gogs: No such file or directoryremote: error: hook declined to update refs/heads/masterTo http://gogit.itfanr.cc/xueer/HelloWorld.git ! [remote rejected] master -&gt; master (hook declined)error: failed to push some refs to &apos;http://gogit.itfanr.cc/xueer/HelloWorld.git&apos; 解决方法： 根据Gogs官网中的故障排查的说明： 123456Update 钩子指向错误的二进制路径可能原因：您升级 `Gogs` 后将其移动到了和之前安装位置不同的目录解决方案：到管理员控制面板（`/admin`）执行以下操作：重新生成 &apos;.ssh/authorized_keys&apos; 文件重新同步所有仓库的 `pre-receive`、`update` 和 `post-receive` 钩子 所以直接使用管理员账户在管理后台中操作即可解决。 详见：故障排查 之前的解决方法： 在新的Gogs位置执行 gogs fix location &lt;old Gogs path&gt; 经测试，该方法似乎已过时，执行时会报如下错误： 12/home/git/gogs# ./gogs fix location /home/git/gogs/goapp/gogsNo help topic for &apos;fix&apos; remote: hooks/update: line 2: /path/to/dir: No such file or directory · Issue #659 · gogits/gogs · GitHub Question: How do I move servers? · Issue #654 · gogits/gogs · GitHub 添加 SSH key 时显示报错页面 error 500查看日志，找到如下错误信息： 1AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 按照如下说法操作成功： So I changed the .ssh/ folder to 0700 and .ssh/authorize_keys to 0600. It works. 详细来源见：ssh 的链接地址不可以使用 修改 /home/git/.ssh 的权限为 700修改 /home/git/.ssh/authorized_keys 的权限为 600 我的操作： 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run 报错：open /home/git/.ssh/authorized_keys.tmp: permission denied 。 查看日志 gogs.log 文件，发现错误信息：AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 。 进入容器内部：docker exec -it gogs /bin/bash ,切换至git用户：su git,然后进入 /home/git/ 目录，更改 .ssh 目录权限：chmod 0700 .ssh 。（此时，该 .ssh 目录内为空） 然后再次访问 /admin 页面，再次执行 Run 操作，提示“所有公钥重新生成成功！”信息。查看容器内的 .ssh/ 目录下生成了一个 authorized_keys 文件。然后更改该文件权限：chmod 0600 authorized_keys 。 然后重启该容器。 重启容器后该问题解决。 要求输入git账户密码添加成功SSH密钥后，git clone 项目会报如下错误： 12345678910111213$ git clone ssh://git@gogit.itfanr.cc:10022/xueer/HelloWorld.gitCloning into &apos;Hello&apos;...The authenticity of host &apos;[gogit.itfanr.cc]:10022 ([gogit.itfanr.cc]:10022)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:+LHU3V00S0g9kNnpByc9ysAM5n6DWutT51YOldIcf88.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;[gogit.itfanr.cc]:10022&apos; (ECDSA) to the list of known hosts.git@gogit.itfanr.cc&apos;s password:Permission denied, please try again.git@gogit.itfanr.cc&apos;s password:fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 一种可能的解决方式是 Check if /home/git/.ssh/.authorized_keys&#39;s permission is 600. 这个问题还是关于 .ssh/authorize_keys 的权限问题。 我的解决方法： 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run ，会提示更新成功。 重启该容器即可。 2017-7-21 add: 如果以上方法无效，可以进入容器后将 authorize_keys 文件删除，然后在管理员操作页面中重新生成。这样应该能解决。 ssh 的链接地址不可以使用 · Issue #545 · gogits/gogs · GitHub SSH prompts for password in Docker · Issue #2409 · gogits/gogs · GitHub How troubleshoot SSHd on Docker ? SSH Connection refused 问题添加成功SSH密钥后，git clone 项目会报如下错误： 1234567$ git clone ssh://git@192.168.137.140:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...ssh: connect to host 192.168.137.140 port 10022: Connection refusedfatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 我的探索： 进入容器内部：docker exec -it gogs /bin/bash 查看ssh连接： 12root@b48dfa9583f9:/home/git/gogs# ssh localhostssh: connect to host localhost port 22: Connection refused 那现在这个问题就是在ubuntu下配置ssh链接的问题了。 发现问题的原因是安装 openssh 后，并没有启动 SSH 服务。执行如下命令启动： 1234/etc/init.d/ssh start# 或service ssh startservice ssh status 通过如下命令查看ssh服务是否启动：ps -e |grep ssh 12root@b48dfa9583f9:/home/git/gogs# ps -e |grep ssh 81 ? 00:00:00 sshd 然后使用 ssh localhost 命令查看是否能够连接本地： 12345root@b48dfa9583f9:/home/git/gogs# ssh localhostThe authenticity of host &apos;localhost (::1)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:eKk78mnEXpwvFhbzC6BgM70jZx3be4Fz8okyagHA6QA.Are you sure you want to continue connecting (yes/no)? noHost key verification failed. 可以看到SSH服务已经正常运行了。 然后在回到宿主机下，再次执行 git clone 命令，测试是否能够连通。 这里我整理了两种连接方法： 连接方法一： git clone ssh://git@192.168.137.140:10022/qqq/Xweixin.git Pull and Push Test Ok. 连接方法二： 如果嫌上面带有端口号的链接太不极客范儿，可以在客户端电脑上当前用户主目录的 .ssh 目录下创建一个没有扩展名的 config 文件（注意文件格式为 UTF-8 且行结束标识为 Unix(LF)），填写如下内容： ~/.ssh/config: 1234Host 192.168.137.140HostName 192.168.137.140Port 10022User git 这里， Host 是远程git仓库所在宿主机的IP地址或域名； HostName 不太重要，仅起到标识的作用； Port 表示远程git仓库使用的端口号； User 表示远程git仓库的默认用户，这里填写默认的 git 即可。 然后就可以直接请求不带端口号的ssh仓库地址了： git clone ssh://git@192.168.137.140/qqq/Xweixin.git Pull and Push Test Ok. 相关参考 ssh: connect to host localhost port 22: Connection refused 问题 ubuntu下如何安装使用SSH？ How to Enable SSH in Ubuntu 16.04 LTS | UbuntuHandbook SSH doesn’t work on ports other than 22 in dockerized gogs Git SSH 使用非默认22端口时，如何隐藏端口号Note that you can also add an entry to your ~/.ssh/config file: 123Host git.example.comPort 2222User git and then use the normal git clone git@git.example.com:myuser/myproject.git command. 相关参考 git - Using a remote repository with non-standard port - Stack Overflow Change port git is using for ssh Specify SSH Port for Git - Server Fault 报错 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!使用 SSH 获取时报错： 12345678910111213141516171819$ git clone ssh://git@192.168.137.140:10022/xueer/HelloWorld.gitCloning into &apos;HelloWorld&apos;...@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:+LHU3V00S0g9kNnpByc9ysAM5n6DWutT51YOldIcf88.Please contact your system administrator.Add correct host key in /c/Users/Yx/.ssh/known_hosts to get rid of this message.Offending ECDSA key in /c/Users/Yx/.ssh/known_hosts:5ECDSA host key for [192.168.137.140]:10022 has changed and you have requested strict checking.Host key verification failed.fatal: Could not read from remote repository.Please make sure you have the correct access rightsand the repository exists. 该问题是由于客户端电脑上的 .ssh/known_hosts 文件中记录了重复或冲突的ssh信息，删除该文件重新设置ssh连接即解决。 echo 输出下面两行命令的输出结果是不一样的： 123ab=$(service ssh status);echo $ab;ab=$(service ssh status);echo &quot;$ab&quot;; 123456you can get output of third solution in good way:echo &quot;$var&quot;and also in nasty way:echo $var 当 echo 后面的内容带有引号时，只会输出变量值的内容。当没有引号时，如果当前所在目录下有其他文件，这些文件的文件名也会被输出： 12ab=$(service ssh status);echo $ab;LICENSE README.md README_ZH.md custom data gogs log public scripts templates sshd is running linux - How to set a variable to the output from a command in Bash? - Stack Overflow Gogs 使用 HTTPS待完善。 使用 HTTPS 部署 Gogs · Issue #12 · Unknwon/wuwen.org · GitHub gogsi/gogs-nginx-ssl.conf at master · richardskumat/gogsi · GitHub One More Thing…根据以上遇到的问题，这里主要提一点： 但凡是SSH相关的问题，就是要保证目录 /home/git/.ssh 具有 0700 的权限，目录 /home/git/.ssh/ 下的文件具有 0600 的权限。 或者直接尝试如下操作: 登陆Gogs站点管理员账户，访问 /admin 页面，选择 Rewrite &#39;.ssh/authorized_keys&#39; file (caution: non-Gogs keys will be lost) 项 ，点击 Run 按钮，如果报错：open /home/git/.ssh/authorized_keys.tmp: permission denied 。否则直接跳至步骤5。 查看日志 gogs.log 文件，发现错误信息：AddPublicKey: addKey: open /home/git/.ssh/authorized_keys: permission denied 。 进入容器内部：docker exec -it gogs /bin/bash ,切换至git用户：su git,然后进入 /home/git/ 目录，更改 .ssh 目录权限：chmod 0700 .ssh 。（此时，该 .ssh 目录内为空） 然后再次访问 /admin 页面，再次执行 Run 操作，提示“所有公钥重新生成成功！”信息。查看容器内的 .ssh/ 目录下生成了一个 authorized_keys 文件。然后更改该文件权限：chmod 0600 authorized_keys 。 最后重启该容器。]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Gogs</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker-Ubuntu-Gogs部署gogs容器过程记录]]></title>
    <url>%2F2017%2F03%2F23%2Fdocker-ubuntu-gogs-deploy%2F</url>
    <content type="text"><![CDATA[Docker Gogs 用更简单的方式部署、升级或迁移Gogs容器服务。 Docker-Ubuntu-Gogs 系列文章主要记录我在Docker下部署Gogs代码管理项目的过程。系列文章包括Gogs容器的部署过程，部署时遇到的问题及解决方法，个性化配置等。 这里底层系统选择了 Ubuntu16.04 版本，之前也曾尝试在 Alpine 系统下来部署Gogs，但安装完成后会报 ./gogs web is not found 之类的错误，暂未找到解决方法。遂最后决定采用Ubuntu来部署。 对于 Alpine 系统下的部署方法，待后期再来完善。 另外，Gogs作者在Github中发布的Gogs容器版本是用Alpine系统来做的，如果比较在意容器的大小，可以直接用之。 测试操作步骤操作记录：Ubuntu16.04 系统 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768docker run -it --name ugg1 -p 3000:3000 -p 8080:22 ubuntu /bin/bashRUN echo "deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse" &gt;&gt; /etc/apt/sources.listapt-get updateapt-get install -y git wget openssh-serveradduser git (and set pwd git)# 拷贝本地的gogs项目zip包到容器中docker cp linux_amd64.zip ugg1:/home/git/gogs.zipunzip gogs.zip#***************cd gogsmkdir -p custom/confmkdir -p logchmod -R 777 customchmod -R 777 logcd ..chown -R git:git gogs#*******************# gosudocker cp gosu-amd64 ugg1:/usr/local/bin/gosuchmod +x /usr/local/bin/gosu# 启动项目cd gogs./gogs web# 启动ssh服务（之前测试时把这项丢了，所以ssh功能一直无法使用）service ssh start service ssh restartgosu git /home/git/gogs/gogs web# 项目文件目录/app gogs-repositories gogs log ssh conf data# 创建数据文件mkdir -p /app/gogs-repositories /app/gogs/log /app/gogs/ssh /app/gogs/data /app/gogs/confchown -R git:git /appln -sf /home/git/gogs/custom/conf/app.ini /app/gogs/conf/app.inichown -R git:git /app$ docker run --name ugg1 -d -p 3002:3000 -p 8090:22 -v /home/tiger/xdk/dfile:/app gg1 123# Link volumed data with app dataln -sf /data/gogs/log ./logln -sf /data/gogs/data ./data 参考自gogs官方github中的dockerfile，使用gosu调用git用户： 12export USER=gitexec gosu $USER /app/gogs/gogs web 问题一：不能使用 gosu 调用 git 用户来启动发现不能使用 gosu 调用 git 用户来启动，gosu git /home/git/gogs/gogs web 会报如下错误： 1gogs 运行系统用户非当前用户：git &gt; 不推荐的解决方法是： 切换到git账户下执行：su - git $ ./gogs web 通过测试，可以采用如下的方式来使用 gosu 调用 git 用户（参考自gogs官方github中的dockerfile）： 12export USER=gitexec gosu $USER /app/gogs/gogs web 问题二：Fail to start SSH server: listen tcp 0.0.0.0:22: bind: permission denied启用内置SSH服务器会报该错误，暂未找到解决方法。 通过测试，将默认的 22 端口改成其他端口即可。 但是 gogs官方的docker配置中建议不要在Docker容器中使用内置的SSH服务器。 问题三：PANIC: session(start): mkdir data: permission denied详细错误信息如下： 1234567891011[Macaron] 2017-03-21 06:05:40: Started GET / for 192.168.137.1[Macaron] PANIC: session(start): mkdir data: permission denied/usr/local/go/src/runtime/panic.go:489 (0x4340bf)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/session/session.go:156 (0x8f478e)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:79 (0x89ba01)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/inject/inject.go:157 (0x87dc92)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/github.com/go-macaron/inject/inject.go:135 (0x87da8b)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:121 (0x89bc62)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/context.go:112 (0x89bb86)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/recovery.go:161 (0x8af50b)/home/vagrant/gopath/src/github.com/gogits/gogs/vendor/gopkg.in/macaron.v1/logger.go:40 (0x89f118) 该问题导致的原因是，当 git 用户运行 ./gogs web 时，会在 gogs 项目的主目录下 ( 这里是 /home/git/gogs）创建一个 data 目录用于存放session缓存等临时文件。如果当前工作的主目录不是在 /home/git/gogs 目录，则git账户就没有权限来创建目录，从而导致权限错误。解决方法是在Dockerfile中指定工作目录 WORKDIR /home/git/gogs 即可。 后经查证，在 Gogs 项目目录下的 custom data 和 log 三个目录是用来存放项目运行期间产生的日志、配置文件、数据等信息的。当Gogs项目需要升级时，直接拷贝这三个目录到新项目目录下即可。这里的 data 目录需要提前创建好。 相关参考 在ubuntu上安装gogs 用Gogs搭建自己的Git服务器 - LibHappy How To Set Up Gogs on Ubuntu 14.04 | DigitalOcean chmod 777 修改权限 - 日光之下无新事 - 博客园 linux - 安装gogs时报错：运行系统用户非当前用户：git -&gt; root。 不知道是什么意思 - SegmentFault Install时注意事项 Database Type 选择 SQLite3 （目前仅测试了sqlite3数据库） Sqlite Database Path 使用固定路径 /app/gogs/data/gogs.db （后期改成默认目录也可以，详见Github） Repository Root Path 使用固定路径 /app/gogs-repositories Run User 使用默认的 git Domain 填写Docker宿主机的主机名或物理地址 类似于 192.168.137.140 SSH Port 不要勾选使用内置SSH服务器（Don’t user Use Builtin SSH Server） 如果你映射Docker外部端口如 10022:22 那么这里填写 10022 HTTP Port 如果映射外部端口 10080:3000 这里仍然使用 3000 Application URL 使用域和公开的HTTP端口值的组合 如 http://192.168.137.140:10080 Log Path 填写固定路径 /app/gogs/log （后期改成默认目录也可以，详见Github） 注意： Dockerfile中必需添加 WORKDIR /home/git/gogs 即必需指定当前工作目录为 gogs 目录下，因为gogs在install完成后会在当前目录下创建一个 data 目录保存 sessions 信息。如果当前目录不是这里，则会报 [Macaron] PANIC: session(start): mkdir data: permission denied 的错误。 成果最终项目见：GitHub - Leafney/ubuntu-gogs: Docker + Ubuntu + Gogs]]></content>
      <categories>
        <category>Ubuntu-Gogs</category>
      </categories>
      <tags>
        <tag>Gogs</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker下配置Elasticsearch容器过程记录]]></title>
    <url>%2F2017%2F03%2F22%2Felasticsearch-container-in-alpine%2F</url>
    <content type="text"><![CDATA[主要记录 Elasticsearch 容器创建流程 目标 Elasticsearch 2.4.x Elasticsearch 5.x alpine 下配置java环境参考自 https://github.com/docker-library/openjdk/blob/master/8-jdk/alpine/Dockerfile 后期创建一个java环境的基础容器。 测试记录下载 elasticsearch.tar.gz 文件并解压到指定目录： 1$ curl -sSL https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.4.0/elasticsearch-2.4.0.tar.gz | tar -zxv -C /usr/share/elasticsearch --strip-components 1 只在 docker run 时执行安装 elasticsearch-analysis-ik 插件在 dockerfile 中的 ENTRYPOINT 命令会在 docker run 或 docker restart 时都执行，这样就导致重复安装插件的问题。 目前采用的方法是在 shell script 文件中 通过判断 plugins 目录下是否存在 elasticsearch-analysis-ik-${IK_ANALYSIS_VERSION}.zip 文件来判断是否已经添加该插件。 另一种方式: 考虑通过 docker exec 在容器启动后来安装。 使用 docker exec 命令执行 shell script 时，有一个疑惑：需要执行的 shell script 文件应该放在容器内部还是可以调用外部即宿主机上的。(后经测试，放在容器内部。) Elasticsearch 集群其中有一台被作为Master，其他为Slave。 配置 elasticsearch.yml （注意配置文件冒号“：”后要有一个空格，否则报错） 12345678910network.host: 10.0.0.1cluster.name: elasticsearch # 集群名称node.name: es-node1 # 节点名称 （同一集群下多个节点名称不同）bootstrap.mlockall: true # node.master: true # 是否作为主节点，每个节点都可以被配置成为主节点，默认值为truenode.data: true # 是否存储数据，即存储索引片段，默认值为truediscovery.zen.ping.unicast.hosts: [&quot;10.0.0.1:9300&quot;, &quot;10.0.0.2:9300&quot;]discovery.zen.minimum_master_nodes: 2 1234567network.host: [&quot;127.0.0.1&quot;, &quot;[::1]&quot;]cluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125; # es_node_1discovery.zen.ping.unicast.hosts: [&quot;10.0.0.1&quot;, &quot;10.0.0.2&quot;, &quot;10.0.0.3&quot;]node.master: truenode.data: false 如何指定自定义配置文件自定义配置文件和默认配置文件的关系指定 配置文件路径： ./bin/elasticsearch -Des.path.conf=/my/conf.yaml 注意： Des.config=/path/to/config/file doesn’t replace $ES_HOME/elasticsearch.conf, just appends to it 详见：-Des.config=/path/to/config/file doesn&#39;t replace $ES_HOME/elasticsearch.conf, just appends to it · Issue #588 · elastic/elasticsearch · GitHub ES 2.4.0 使用如下方式启动 CMD gosu elasticsearch elasticsearch -Epath.conf=&quot;${ELASTICSEARCH_DATA}/config/elastic.yml&quot; 报下面的错误： 1ERROR: Parameter [-Epath.conf=&quot;$&#123;ELASTICSEARCH_DATA&#125;/config/elastic.yml&quot;]does not start with -- 123-Des.path.confbin/elasticsearch -Des.path.conf=/etc/elasticsearch/node1 总结 ：使用 --path.conf=configdir 来指定配置文件所在目录，并且配置文件必需命名为 elasticsearch.yml 才可以。 1$ ./bin/elasticsearch --path.conf=/path/to/conf/dir 详细分析过程如下： 报错分析启动时报如下错误： 12345678910111213141516/ # gosu elasticsearch elasticsearch -Des.path.conf=/app/config/elastic.ymllog4j:WARN No appenders could be found for logger (bootstrap).log4j:WARN Please initialize the log4j system properly.log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.Exception in thread &quot;main&quot; java.lang.IllegalStateException: Unable to access &apos;path.conf&apos; (/app/config/elastic.yml)Likely root cause: java.nio.file.NotDirectoryException: /app/config/elastic.yml at org.elasticsearch.bootstrap.Security.ensureDirectoryExists(Security.java:340) at org.elasticsearch.bootstrap.Security.addPath(Security.java:314) at org.elasticsearch.bootstrap.Security.addFilePermissions(Security.java:247) at org.elasticsearch.bootstrap.Security.createPermissions(Security.java:212) at org.elasticsearch.bootstrap.Security.configure(Security.java:118) at org.elasticsearch.bootstrap.Bootstrap.setupSecurity(Bootstrap.java:212) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:183) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:286) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35)Refer to the log for complete error details. 解决方法： 找到一个讨论中的回答： 123It is no longer possible to specify a custom config file with the CONF_FILE environment variable, or the -Des.config, -Des.default.config, or -Delasticsearch.config parameters.Instead, the config file must be named elasticsearch.yml and must be located in the default config/ directory, unless a custom config directory is specified. Problem in starting a node in ES 2.2.1 - Elasticsearch - Discuss the Elastic Stack Setting changes | Elasticsearch Reference 2.2 | Elastic 找到解决方案： 从文章 Setting changes | Elasticsearch Reference 2.4 中这段： Custom config fileeditIt is no longer possible to specify a custom config file with the CONF_FILE environment variable, or the -Des.config, -Des.default.config, or -Delasticsearch.config parameters.Instead, the config file must be named elasticsearch.yml and must be located in the default config/ directory, unless a custom config directory is specified.The location of a custom config directory may be specified as follows:./bin/elasticsearch –path.conf=/path/to/conf/dir./bin/plugin -Des.path.conf=/path/to/conf/dir install analysis-icuWhen using the RPM or debian packages, the plugin script and the init/service scripts will consult &gt; the CONF_DIR environment variable to check for a custom config location. The value of the CONF_DIR &gt; variable can be set in the environment config file which is located either in /etc/default/elasticsearch or /etc/sysconfig/elasticsearch. 得知，之前的自定义配置文件方法 -Des.path.conf 改为了这种方式 --path.conf ，而且，只需要指定到配置文件所在目录即可。另外，配置文件的名称必须为 elasticsearch.yml 。 1$ gosu elasticsearch elasticsearch --path.conf=/app/config network.host 同时支持 IPV4 和 IPV6 报错报如下错误： 1234567891011Exception in thread &quot;main&quot; java.lang.IllegalArgumentException: bind address: &#123;0.0.0.0&#125; is wildcard, but multiple addresses specified: this makes no sense at org.elasticsearch.common.network.NetworkService.resolveBindHostAddresses(NetworkService.java:132) at org.elasticsearch.transport.netty.NettyTransport.bindServerBootstrap(NettyTransport.java:435) at org.elasticsearch.transport.netty.NettyTransport.doStart(NettyTransport.java:332) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68) at org.elasticsearch.transport.TransportService.doStart(TransportService.java:182) at org.elasticsearch.common.component.AbstractLifecycleComponent.start(AbstractLifecycleComponent.java:68) at org.elasticsearch.node.Node.start(Node.java:278) at org.elasticsearch.bootstrap.Bootstrap.start(Bootstrap.java:222) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:288) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:35) 配置文件内容： 123456789101112# defaultnetwork.host: [&quot;0.0.0.0&quot;, &quot;[::1]&quot;]path.data: /app/datapath.logs: /app/logs# clustercluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125;node.master: truenode.data: true# bootstrap.mlockall: truediscovery.zen.ping.unicast.hosts: [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;] 改为 network.host: 0.0.0.0 后 启动成功。 可查看该讨论: Binding to the wildcard of one address family should not prevent binding to addresses in another family · Issue #20703 · elastic/elasticsearch · GitHub 当加上 bootstrap.mlockall: true 这行时，也会报错。 待探究原因！！！ elasticsearch cluster 配置 unicast.hosts探究上面的配置文件中，设置的 unicast.hosts 值如下 ： 1234discovery.zen.ping.unicast.hosts: [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;]discovery.zen.ping.unicast.hosts: [&quot;172.17.0.4:9300&quot;, &quot;172.17.0.5:9301&quot;] 经测试，使用 [&quot;localhost:9300&quot;, &quot;localhost:9301&quot;] 无效。必须使用明确的IP地址 [&quot;172.17.0.4:9300&quot;, &quot;172.17.0.5:9301&quot;] 后才能互相发现。 通过 访问 http://59.188.76.112:9200/_cluster/health?pretty 能看到是否组成集群模式： 1234567891011121314151617&#123; &quot;cluster_name&quot;: &quot;elasticsearch&quot;, &quot;status&quot;: &quot;green&quot;, &quot;timed_out&quot;: false, &quot;number_of_nodes&quot;: 2, &quot;number_of_data_nodes&quot;: 2, &quot;active_primary_shards&quot;: 0, &quot;active_shards&quot;: 0, &quot;relocating_shards&quot;: 0, &quot;initializing_shards&quot;: 0, &quot;unassigned_shards&quot;: 0, &quot;delayed_unassigned_shards&quot;: 0, &quot;number_of_pending_tasks&quot;: 0, &quot;number_of_in_flight_fetch&quot;: 0, &quot;task_max_waiting_in_queue_millis&quot;: 0, &quot;active_shards_percent_as_number&quot;: 100&#125; 考虑到Docker下容器的ip地址是随机的，容器重启后可能会改变，需要考虑其他确定的方式。 设置成 localhost 参考自 如何使用一个IP搭建ES集群——Docker如你所愿 - 简书 可能的一种方法是在 docker run 时 指定 --add-host=[] 参数 ，待研究！！！ 经测试，使用 localhsot 127.0.0.1 0.0.0.0 docker name 均无效。 经测试，可以设置为相应容器的IP 如 172.17.0.5:9300 。通过命令 : 1docker inspect --format=&apos;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&apos; $CONTAINER_ID 可以获得指定容器的ip地址。但这里的问题是 容器的ip每次重启后都会改变，知道容器ip没什么意义。所以这种方式也失败。 如果不指定容器的IP,但可以指定容器所在宿主机的IP 120.121.xx.xx:9300 ，这样能发现集群。 以下issure中，可以通过docker-compores 来指定容器ip ：待研究！！！ Cannot set up an elasticsearch:2 cluster in docker any more · Issue #68 · docker-library/elasticsearch · GitHub Problems in getting single node cluster working as per your docs · Issue #19 · spujadas/elk-docker · GitHub 另外一种方式，通过 --link 来设置：参考自：dockerfiles/elasticsearch at master · itzg/dockerfiles · GitHub 123456789docker run --name es5 -d -p 9230:9200 -p 9330:9300 e2docker run --name es6 -d --link es5 e2docker run --name es7 -d --link es5 e2docker cp elasticsearch.yml es5:/app/config/elasticsearch.ymldocker cp elasticsearch.yml es6:/app/config/elasticsearch.ymldocker cp elasticsearch.yml es7:/app/config/elasticsearch.ymldocker restart es5 es6 es7 配置文件： 1234567891011# defaultnetwork.host: 0.0.0.0path.data: /app/datapath.logs: /app/logs# clustercluster.name: elasticsearchnode.name: $&#123;HOSTNAME&#125;node.master: truenode.data: truediscovery.zen.ping.unicast.hosts: [&quot;es5:9330&quot;] 这种方式经测试，无效。 报如下错误： 12345678910111213java.net.NoRouteToHostException: Host is unreachable at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method) at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717) at org.jboss.netty.channel.socket.nio.NioClientBoss.connect(NioClientBoss.java:152) at org.jboss.netty.channel.socket.nio.NioClientBoss.processSelectedKeys(NioClientBoss.java:105) at org.jboss.netty.channel.socket.nio.NioClientBoss.process(NioClientBoss.java:79) at org.jboss.netty.channel.socket.nio.AbstractNioSelector.run(AbstractNioSelector.java:337) at org.jboss.netty.channel.socket.nio.NioClientBoss.run(NioClientBoss.java:42) at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108) at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:42) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) at java.lang.Thread.run(Thread.java:745) Docker elasticsearch 集群 https://hub.docker.com/r/itzg/elasticsearch/ https://github.com/Khezen/docker-elasticsearch/tree/2.4 看到网上大部分人都是将集群配置参数通过环境变量的形式在 docker run 时配置，考虑将配置文件暴露在主机目录下是否安全？ 查看集群状态查看集群状态: curl -XGET &#39;http://172.16.212.102:9200/_cluster/health?pretty&#39; 相关参考Elasticsearch集群搭建相关参考 ElasticSearch集群部署文档 elasticsearch2.3.1 集群安装 - 尚浩宇的博客 五角星 配置 How To Set Up a Production Elasticsearch Cluster on Ubuntu 14.04 | DigitalOcean Easy Elasticsearch cluster with docker 1.12 swarm? - General - Docker Forums Running an Elasticsearch cluster with Docker 如何使用一个IP搭建ES集群——Docker如你所愿 - 简书 五角星 docker-elasticsearch-cn/docker-start at master · hangxin1940/docker-elasticsearch-cn · GitHub elasticsearch 集群 宿主机上如何获得 docker container 容器的 ip 地址？ - SegmentFault Elasticsearch容器创建相关参考 GitHub - soldair/docker-alpine-elasticsearch: 130mb ish Elasticsearch container based on alpine linux. GitHub - docker-library/elasticsearch: Docker Official Image packaging for elasticsearch GitHub - kiasaki/docker-alpine-elasticsearch: ElasticSearch container based on Alpine Linux GitHub - docker-library/openjdk: Docker Official Image packaging for Java (openJDK) docker elasticsearch GitHub - itzg/dockerfiles: Contains the various Dockerfile definitions I&#39;m maintaining. 成果源码见：GitHub - Leafney/alpine-elasticsearch: Docker + Alpine + Elasticsearch]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下使用SSH密钥连接Github]]></title>
    <url>%2F2017%2F03%2F03%2Fusing-ssh-key-connection-github-in-linux%2F</url>
    <content type="text"><![CDATA[在 Linux 系统下如何通过 SSH 密钥来连接 GitHub (Mac系统下设置方法相同)。 引申 Linux下 ：Linux下使用SSH密钥连接Github Windows下：使用SSH密钥连接Github Ubuntu 系统初始化配置git环境测试系统版本 : Ubuntu 16.04 LTS 更新软件源123$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list &amp;&amp; \echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list &amp;&amp; \echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-updates main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 安装git依赖12$ apt-get update$ apt-get install git 设置时区123$ ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime$ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone$ dpkg-reconfigure -f noninteractive tzdata Alpine 系统初始化配置git环境测试系统版本 : Alpine 3.5 更新软件源12$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.5/main&quot; &gt;&gt; /etc/apk/repositories$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.5/community&quot; &gt;&gt; /etc/apk/repositories 安装依赖The ssh-keygen command is part of OpenSSH (package “openssh”). 12$ apk update$ apk add git openssh 设置时区123$ apk add tzdata$ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime$ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone Mac 系统初始化配置git环境Mac系统上安装git,可以直接从git网站下载安装包,访问 Git - Downloads 安装. 也可以通过 homebrew 进行安装: 1$ brew install git 设置git账户执行如下两条命令设置git账户的用户名和密码： 1234$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;youremail@domain.com&quot;$ git config --list 生成SSH公钥SSH 公钥默认储存在账户的主目录下的 ~/.ssh 目录。先确认是否已经有一个公钥了： 12$ cd ~/.ssh/bin/sh: cd: can&apos;t cd to /root/.ssh 主要是看是否存在 id_dsa 或 id_rsa 文件。有 .pub 后缀的文件就是 公钥，另一个文件则是密钥。 创建新的SSH密钥如果已经存在公钥，可跳过这步。如果没有，使用 ssh-keygen 来创建： 12$ cd ~$ ssh-keygen -t rsa -C &quot;youremail@domain.com&quot; 示例：(xxxxxx@126.com 为我的账户邮箱) 12345678910111213141516171819202122~ # ssh-keygen -t rsa -C &quot;xxxxxx@126.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/root/.ssh/id_rsa): # 直接回车，则将密钥按默认路径及文件名进行存储。此时也可以输入特定的文件名Created directory &apos;/root/.ssh&apos;.Enter passphrase (empty for no passphrase): # 根据提示，你需要输入密码和确认密码。可以不填，设置为空值，直接回车Enter same passphrase again: Your identification has been saved in /root/.ssh/id_rsa.Your public key has been saved in /root/.ssh/id_rsa.pub.The key fingerprint is:SHA256:yFt14TcP0H+ixy9VKiILPPJ6DVevkKgrbxVFqk7mn5k xxxxxx@126.comThe key&apos;s randomart image is:+---[RSA 2048]----+| o. || . . o. || o . o +. || .... ... ..++|| . o .So . o+|| + o Bo= . + + .|| = *.* + o o || ++o o o . . .|| E=++ . |+----[SHA256]-----+ 查看生成的文件： 123$ cd ~/.ssh~/.ssh $ lsid_rsa id_rsa.pub 文件 id_rsa.pub 就是公钥。 在 GibHub 中添加你的公钥复制公钥 id_rsa.pub 文件中的内容。 我这里使用 XShell 来登录的linux服务器，可以直接复制出来。或在 vim 下，可通过命令 ggVG 全选，+y 复制选中内容到+寄存器，也就是系统的剪贴板，供其他程序使用。 登陆Github网站，选择 Settings –&gt; SSH and GPG keys 菜单，点击 New SSH key 按钮。粘贴你的密钥到 Key 输入框中并设置 Title 信息，点击 Add SSH key 按钮完成。 连接测试测试 SSH keys 是否设置成功，执行如下命令： 1$ ssh -T git@github.com 当提示如下信息时，说明正常连通了github: 1Hi xxxxxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 如果你是第一次设置连接github.com,会询问你是否继续,输入 yes 即可,这样就会将连接地址记录在本地: 123456$ ssh -T git@github.comThe authenticity of host &apos;github.com (192.30.253.112)&apos; can&apos;t be established.RSA key fingerprint is SHA256:nThbg6kXUpxxxxxxxxARLviKw6E5SY8.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added &apos;github.com,192.30.253.112&apos; (RSA) to the list of known hosts.Hi xxxxxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 然后就可以将本地的项目用github来管理了。 更新日志 2017-10-27 - 完善”连接测试”内容; 添加Mac系统下安装git配置]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>GitHub</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下修改时区]]></title>
    <url>%2F2017%2F02%2F23%2Fmodify-timezone%2F</url>
    <content type="text"><![CDATA[一般通过默认方式安装的linux系统显示的都是UTC时间，这样导致一些依赖时间的程序就会出现时差问题。下面介绍在Ubuntu和Alpine系统下如何更改UTC时区为CST时区。 Alpinealpine 下修改UTC时间为CST时间 (测试通过)123$ apk add tzdata $ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime $ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone Docker + Alpine 下修改utc时间为cst时间Dockerfile : 1234RUN apk update &amp;&amp; apk add ca-certificates &amp;&amp; \ apk add tzdata &amp;&amp; \ ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone UbuntuUbuntu 下手动修改配置 (图形化界面)1$ sudo dpkg-reconfigure tzdata 或： 1$ sudo tzselect Ubuntu下通过命令更改（已测试）123$ sudo ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime$ sudo echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone$ sudo dpkg-reconfigure -f noninteractive tzdata 经测试，如果不加第一行，系统重启后又恢复UTC时间了 Docker + Ubuntu 下修改UTC时间为CST时间Dockerfile: 1234# Setting timezoneRUN ln -sf /usr/share/zoneinfo/Asia/ShangHai /etc/localtime &amp;&amp; \ echo &quot;Asia/Shanghai&quot; &gt; /etc/timezone &amp;&amp; \ dpkg-reconfigure -f noninteractive tzdata 相关参考 docker 中设置时区 | 水能载舟 亦可赛艇 Ubuntu: 以命令行方式修改时区 docker 中设置时区 - 作业部落 Cmd Markdown 编辑阅读器]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04配置RabbitMQ运行环境]]></title>
    <url>%2F2017%2F02%2F21%2Finstallation-rabbitmq-on-ubuntu%2F</url>
    <content type="text"><![CDATA[该文章主要记录在 Ubuntu 16.04.1 LTS 系统下安装及配置 RabbitMQ 的方法。 更新软件源1234sudo echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt; /etc/apt/sources.listsudo echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial-security main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.listsudo apt-get update 安装Erlang依赖123456cd /tmpwget http://packages.erlang-solutions.com/ubuntu/erlang_solutions.ascsudo apt-key add erlang_solutions.ascsudo apt-get updatesudo apt-get install erlangsudo apt-get install erlang-nox 安装RabbitMQ12345sudo echo &quot;deb http://www.rabbitmq.com/debian/ testing main&quot; &gt;&gt; /etc/apt/sources.listsudo wget https://www.rabbitmq.com/rabbitmq-release-signing-key.ascsudo apt-key add rabbitmq-release-signing-key.ascsudo apt-get updatesudo apt-get install rabbitmq-server 管理RabbitMQ服务管理服务可以使用 rabbitmqctl 或系统服务 service 或者 systemctl 来管理. rabbitmqctl : 1$ sudo rabbitmqctl [status|start|stop|reset] systemctl : 1$ sudo systemctl [status|start|stop|restart] rabbitmq-server service : 1$ sudo service rabbitmq-server [status|start|stop|restart] 如果 status 状态显示无法连接rabbitmq服务，需要先启动该服务。 12345678910111213141516171819202122$ sudo rabbitmqctl statusStatus of node rabbit@localhost ...Error: unable to connect to node rabbit@localhost: nodedown$ sudo rabbitmqctl start# 或者$ sudo service rabbitmq-server start/restart$ sudo rabbitmqctl statusStatus of node rabbit@localhost ...[&#123;pid,9286&#125;, &#123;running_applications,[&#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.6.6&quot;&#125;, &#123;mnesia,&quot;MNESIA CXC 138 12&quot;,&quot;4.13.3&quot;&#125;, &#123;os_mon,&quot;CPO CXC 138 46&quot;,&quot;2.4&quot;&#125;, &#123;rabbit_common,[],&quot;3.6.6&quot;&#125;, &#123;xmerl,&quot;XML parser&quot;,&quot;1.3.10&quot;&#125;, &#123;ranch,&quot;Socket acceptor pool for TCP protocols.&quot;, &quot;1.2.1&quot;&#125;, ... ... 在Docker下管理注意：在Ubuntu系统的 Docker 下 ，使用 systemctl 命令会报错，所以在docker下还是推荐使用 service 来管理。 12345678910111213141516root@6b16517eab27:/tmp# systemctlFailed to connect to bus: No such file or directoryroot@6b16517eab27:/tmp# service rabbitmq-server statusStatus of node rabbit@6b16517eab27 ...[&#123;pid,12184&#125;, &#123;running_applications, [&#123;rabbitmq_management,&quot;RabbitMQ Management Console&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbitmq_web_dispatch,&quot;RabbitMQ Web Dispatcher&quot;,&quot;3.6.6&quot;&#125;, &#123;webmachine,&quot;webmachine&quot;,&quot;1.10.3&quot;&#125;, &#123;mochiweb,&quot;MochiMedia Web Server&quot;,&quot;2.13.1&quot;&#125;, &#123;amqp_client,&quot;RabbitMQ AMQP Client&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbitmq_management_agent,&quot;RabbitMQ Management Agent&quot;,&quot;3.6.6&quot;&#125;, &#123;rabbit,&quot;RabbitMQ&quot;,&quot;3.6.6&quot;&#125;, ... ... So the systemctl can not run inside docker, right? thanks! Running systemctl in container fails with &quot;Failed to get D-Bus connection&quot; · Issue #2296 · docker/docker · GitHub systemd and systemctl within Ubuntu Docker images - Stack Overflow RabbitMQ Web管理接口启用rabbitmq-management启用rabbitmq-management插件： 1$ sudo rabbitmq-plugins enable rabbitmq_management 12345678910$ sudo rabbitmq-plugins enable rabbitmq_managementThe following plugins have been enabled: mochiweb webmachine rabbitmq_web_dispatch amqp_client rabbitmq_management_agent rabbitmq_managementApplying plugin configuration to rabbit@6b16517eab27... started 6 plugins. 重启RabbitMQ: 1$ sudo systemctl restart rabbitmq-server 使用浏览器访问 http://localhost:15672 ，使用默认的 guest/guest 用户登录。 使用guest账户远程访问注意：使用远程访问或在Ubuntu系统的Docker下使用所在服务器的地址访问时会报权限错误： 1&#123;error: &quot;not_authorised&quot;, reason: &quot;User can only log in via localhost&quot;&#125; 这是因为 rabbitmq从3.3.0开始禁止使用 guest/guest 权限通过除 localhost 外的访问。 如果想使用 guest/guest 通过远程机器访问，需要在rabbitmq配置文件 (/etc/rabbitmq/rabbitmq.config) 中设置 loopback_users为[] 。 /etc/rabbitmq/rabbitmq.config (不存在先创建) 文件完整内容如下（注意后面的半角句号）： 1[&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;]. 操作步骤如下： 1234567# ls /etc/rabbitmq/enabled_plugins$ sudo vim /etc/rabbitmq/rabbitmq.config [&#123;rabbit, [&#123;loopback_users, []&#125;]&#125;].$ sudo service rabbitmq-server restart 创建新账户如果不想使用默认的 guest 账户，可以创建一个新的具有管理员权限的账户，如创建一个 test/test 账户操作如下： 123rabbitmqctl add_user test testrabbitmqctl set_user_tags test administratorrabbitmqctl set_permissions -p / test &quot;.*&quot; &quot;.*&quot; &quot;.*&quot; RabbitMQ - Access Control (Authentication, Authorisation) in RabbitMQ Can&#39;t access RabbitMQ web management interface after fresh install - Stack Overflow RabbitMQ 3.3.1 can not login with guest/guest - Stack Overflow rabbitmq问题之HTTP access denied: user &#39;guest&#39; - User can only log in via localhost - 布雷泽 - 博客园 相关链接 How To Install RabbitMQ on Ubuntu 16.04 - idroot Ubuntu 16.04 安装 RabbitMQ]]></content>
      <tags>
        <tag>RabbitMQ</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git使用技巧整理]]></title>
    <url>%2F2017%2F02%2F07%2Fgit-use-skills%2F</url>
    <content type="text"><![CDATA[一次添加多个文件1$ git add . 为什么用 . 不用 * In order to add the files that are not in the gitignore file, use git add . in the place of git add * This will stop confusing the unix system since means all ( including the ignored ones ) while . means the ones relative to the active action 强制添加文件1git add -f aaa.exe 一般在添加一个被忽略的文件时，会提示如下错误： 1234$ git add phantomjs.exeThe following paths are ignored by one of your .gitignore files:phantomjs.exeUse -f if you really want to add them. 遇到这种情况时候需要使用 git add -f 命令强制添加这个文件。 详见：git强制添加(add)文件]]></content>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04安装Docker及配置镜像加速器]]></title>
    <url>%2F2017%2F01%2F14%2Fubuntu-install-docker-and-configure-mirror-accelerator%2F</url>
    <content type="text"><![CDATA[最近将虚拟机中的Ubuntu系统从14.04更新到了16.04.1版本，又要重新安装Docker服务，在安装的时候发现Docker的官方安装教程又有了更新，之前的安装方法已经过时。 过时的安装方法之前官网中提供的安装方法为： 1$ curl -sSL https://get.docker.com/ | sudo sh 现在如果再执行该命令，会直接报错。 官方推荐安装方法查看系统内核Docker需要安装在Linux 64位系统下，内核版本在 3.10 以上。可以通过 uname -r 来查看内核信息： 12$ uname -r4.4.0-31-generic 更新源，安装CA证书12$ sudo apt-get update$ sudo apt-get install apt-transport-https ca-certificates 导入 GPG 密钥123$ sudo apt-key adv \ --keyserver hkp://ha.pool.sks-keyservers.net:80 \ --recv-keys 58118E89F3A912897C070ADBF76221572C52609D 添加docker源根据当前系统版本，添加docker源命令： 1$ echo &quot;&lt;REPO&gt;&quot; | sudo tee /etc/apt/sources.list.d/docker.list 只要将 &lt;REPO&gt; 替换成相应系统的源地址即可。 我这里当前系统Ubuntu16.04，源地址为：deb https://apt.dockerproject.org/repo ubuntu-xenial main，所以只需如下命令： 1$ echo &quot;deb https://apt.dockerproject.org/repo ubuntu-xenial main&quot; | sudo tee /etc/apt/sources.list.d/docker.list 其他版本系统源地址如下： Ubuntu version Repository Precise 12.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-precise main Trusty 14.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-trusty main Wily 15.10 deb https://apt.dockerproject.org/repo ubuntu-wily main Xenial 16.04 (LTS) deb https://apt.dockerproject.org/repo ubuntu-xenial main 更新源列表1$ sudo apt-get update 验证 APT 能否正确获取执行如下命令会从docker官方仓库中列出所有docker的可安装版本： 12345678910111213141516$ apt-cache policy docker-enginedocker-engine: Installed: null Candidate: 1.12.6-0~ubuntu-xenial Version table: *** 1.12.6-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 100 /var/lib/dpkg/status 1.12.5-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 1.12.4-0~ubuntu-xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages 1.12.3-0~xenial 500 500 https://apt.dockerproject.org/repo ubuntu-xenial/main amd64 Packages ... ... 安装docker默认会安装推荐的版本 Candidate 项列出的，也是最新的版本 1$ sudo apt-get install -y docker-engine 启动docker服务1$ sudo service docker start 验证在命令行下输入 docker ,如提示docker的 [OPTIONS] 说明，则表示docker服务已经安装成功了。 12345678910111213141516171819$ dockerUsage: docker [OPTIONS] COMMAND [arg...] docker [ --help | -v | --version ]A self-sufficient runtime for containers.Options: --config=~/.docker Location of client config files -D, --debug Enable debug mode -H, --host=[] Daemon socket(s) to connect to -h, --help Print usage -l, --log-level=info Set the logging level --tls Use TLS; implied by --tlsverify --tlscacert=~/.docker/ca.pem Trust certs signed only by this CA --tlscert=~/.docker/cert.pem Path to TLS certificate file --tlskey=~/.docker/key.pem Path to TLS key file ... ... 将当前用户添加到docker的用户组Docker安装成功后，如果想查看docker的信息，执行 docker info 命令时可能会提示如下信息： 12$ docker infoCannot connect to the Docker daemon. Is the docker daemon running on this host? 这是因为必需以管理员权限或使用 sudo 来运行命令才可以。为了以后执行命令时不用每次都必需添加 sudo，可以将当前用户加入到docker用户组中。 创建 docker 分组1$ sudo groupadd docker 将当前用户添加到组1$ sudo usermod -aG docker $USER 注意：这里不用更改 $USER 这个参数，$USER 这个环境变量就是指当前用户名 重启系统更改完成后，还需要重启系统才能看到效果。 1$ sudo reboot 创建一个测试容器可通过如下命令来创建一个测试容器： 1$ docker run hello-world 输出： 123Hello from Docker.This message shows that your installation appears to be working correctly.... 配置阿里云Docker镜像加速器打开 开发者平台 – 管理中心 – 加速器 。可以看到 “您的专属加速器地址” 即 https://xxxxxxx.mirror.aliyuncs.com 。 注意：这里以 Ubuntu 16.04 系统为例，其他系统请到上述页面中查看相应操作命令。 配置Docker加速器通过 docker info 命令可以知道上面安装好的Docker的版本为 1.12.6 。所以请通过修改daemon配置文件 /etc/docker/daemon.json (没有时新建该文件) 来使用加速器： 12345678910sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-&apos;EOF&apos;&#123; &quot;registry-mirrors&quot;: [&quot;https://xxxxxxx.mirror.aliyuncs.com&quot;]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker 注意事项针对于Docker版本在1.10以下的情况，可以使用如下的配置方法： 12345678sudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/mirror.conf &lt;&lt;-&apos;EOF&apos;[Service]ExecStart=/usr/bin/docker daemon -H fd:// --registry-mirror=https://xxxxxxx.mirror.aliyuncs.comEOFsudo systemctl daemon-reloadsudo systemctl restart docker 但是该方法并不适用于1.12.0版本之后的Docker上。因为Docker的可执行文件名称从 docker 改成了 dockerd。如果使用了以上脚本，可能会报如下的错误： 12$ sudo systemctl restart dockerJob for docker.service failed because the control process exited with error code. See &quot;systemctl status docker.service&quot; and &quot;journalctl -xe&quot; for details. 所以在配置加速器时一定要按照相应版本来设置。 还要注意一点：上文代码段中给出的镜像加速器地址中的 xxxxxxx 为阿里云在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关参考 Install Docker on Ubuntu - Docker How To Install and Use Docker on Ubuntu 16.04 | DigitalOcean ubuntu16.04安装docker - 程序园 Ubuntu 16.04安装docker加速器后无法启动docker-问答-云栖社区-阿里云]]></content>
      <tags>
        <tag>Docker</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Flask中使用SQLAlchemy]]></title>
    <url>%2F2017%2F01%2F06%2Fuse-sqlalchemy-by-flask%2F</url>
    <content type="text"><![CDATA[在Flask中使用SQLAlchemy操作数据库。 安装 flask-sqlalchemy1$ pip install flask 1$ pip install flask-sqlalchemy 基础你所有模型的基类叫做 db.Model 。它存储在你必须创建的 SQLAlchemy 实例上。 在 Flask-sqlalchemy中，表名已自动设置好，除非自己重载它：eg: 1__tablename__ = &apos;students&apos; #指定表名 Column类型 类型名 Python 类型 说明 Integer int 整数 String(size) str 有最大长度的字符串 Text str 长 unicode 文本 Float float 存储浮点值 Boolean bool 存储布尔值 Date datetime.date 日期 Time datetime.time 时间 DateTime datetime.datetime 日期和时间 PickleType 任何python对象 存储一个持久化 Python 对象 LargeBinary str 存储任意大的二进制数据 常用字段 选项名 说明 示例 primary_key 设置主键 primary_key=True unique 是否唯一 unique=True index 是否创建索引 index=True nullable 是否允许为空 nullable=True default 设置默认值 default=datetime.datetime.utcnow 更详细的配置可参考 Flask Web Development —— 数据库（上） - young - SegmentFault 连接URI格式1dialect+driver://username:password@host:port/database Mysql mysql://scott:tiger@localhost/mydatabase Postgres postgresql://scott:tiger@localhost/mydatabase SQLite sqlite:////absolute/path/to/foo.db Flask-SQLAlchemy Sqlite连接路径问题1sqlite:////tmp/test.db Sqlite连接字符串中的/斜杠说明：三斜杠为相对路径，四斜杠为绝对路径。 12&apos;sqlite:////tmp/test.db&apos; #表示指向绝对路径在Ｔｍｐ目录的test.db文件&apos;sqlite:///Data/test.db&apos; #表示指向相对路径在当前Py文件同目录的Data目录下test.db文件 Flask小记一：Flask-SQLAlchemy Sqlite连接路径问题 - 不折腾难受斯基 过滤器 过滤器 说明 filter 把过滤器添加到原查询上，返回一个新查询 filter_by 把等值过滤器添加到原查询上，返回一个新查询 limit 使用指定的值限制返回的结果数量，返回一个新查询 offset 便宜原查询返回的结果， 返回一个新查询 order_by 根据指定条件对原查询结果进行排序，返回一个新查询 group_by 根据指定条件对原查询结构进行分组，返回一个新查询 执行器 方法 说明 all 以列表形式返回查询的所有结果 first 返回查询的第一个结果，如果没有结果，则返回 None first_or_404 返回查询的第一个结果，如果没有结果，则终止请求，返回 404 错误输出 get 返回指定主键对应的行，如果没有对应的行，则返回 None get_or_404 返回指定主键对应的行，如果没找到指定的主键，则终止请求，返回 404 错误输出 count 返回查询结果的数量 paginate 返回一个 Paginate 对象，它包含指定范围内的结果 简单示例入门示例参考自官方入门教程示例代码 Quickstart Flask-SQLAlchemy Documentation (2.1) flsksql.py 1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom flask_sqlalchemy import SQLAlchemyapp=Flask(__name__)app.config[&apos;SQLALCHEMY_DATABASE_URI&apos;]=&apos;sqlite:///test.db&apos; # 连接当前项目同目录下的test.db数据库文件app.config[&apos;SQLALCHEMY_TRACK_MODIFICATIONS&apos;]=Truedb=SQLAlchemy(app)class User(db.Model): &quot;&quot;&quot;docstring for User&quot;&quot;&quot; __tablename__=&apos;users&apos; id=db.Column(db.Integer,primary_key=True) username=db.Column(db.String(80),unique=True) email=db.Column(db.String(64),unique=True) def __init__(self, username,email): self.username=username self.email=email def __repr__(self): return &apos;&lt;User %r&gt;&apos; % self.username app.py 123456789101112131415161718192021222324252627282930313233343536373839404142# coding:utf-8from flask import Flaskfrom flsksql import dbfrom flsksql import Userif __name__ == &apos;__main__&apos;: # 初始化数据库 # db.create_all() # 新增 # user1=User(&apos;abc&apos;,&apos;abc@124.com&apos;) # user2=User(&apos;def&apos;,&apos;def@129.com&apos;) # db.session.add(user1) # db.session.add(user2) # 使用commit提交更改 # db.session.commit() # 查询所有数据信息 # users=User.query.all() # print(users) # 条件查询 # admin=User.query.filter_by(username=&apos;abc&apos;).first() # print(admin) # 模糊查询 # user2_query=User.query.filter(User.username.endswith(&apos;f&apos;)).first() # print(user2_query) # 删除 # u3=User.query.first() # print(u3.username) # db.session.delete(u3) # db.session.commit() # 更改 # u4=User.query.first() # u4.username=u&apos;专升本&apos; # 中文必须为unicode类型，而不是str类型 # db.session.commit() 通过上下文的方式-init_app()database.py–数据操作方法1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom flask_sqlalchemy import SQLAlchemydb=SQLAlchemy()def create_app(config_name=None): app=Flask(__name__) # 在此处加载配置文件 if config_name is not None: # app.config.from_object() # 默认的config.py app.config.from_pyfile(config_name) # 通过配置文件名称加载配置文件 db.init_app(app) # 在此处加载蓝图设置 with app.app_context(): # 添加数据对象的引用 from models import * # 初始化数据库 db.create_all() return app models.py–Model实体123456789101112131415161718192021222324# coding:utf-8from database import dbclass User(db.Model): &quot;&quot;&quot;docstring for User&quot;&quot;&quot; __tablename__=&apos;users&apos; id=db.Column(db.Integer,primary_key=True) username=db.Column(db.String(80)) email=db.Column(db.String(64)) def __init__(self, username,email): self.username=username self.email=emailclass Address(db.Model): &quot;&quot;&quot;docstring for Address&quot;&quot;&quot; id=db.Column(db.Integer,primary_key=True) name=db.Column(db.String(32)) def __init__(self, name): self.name=name config.py–sql配置文件123DEBUG=TrueSQLALCHEMY_DATABASE_URI=&apos;sqlite:///testabc.db&apos;SQLALCHEMY_TRACK_MODIFICATIONS=True app.py–项目1234567891011121314151617181920212223242526# coding:utf-8from flask import Flaskfrom database import dbfrom database import create_appfrom models import User,Addressapp=create_app(&apos;config.py&apos;)@app.route(&apos;/&apos;)def index(): # user1=User(&apos;aaa&apos;,&apos;aaa@124.com&apos;) # user2=User(u&apos;马云&apos;,&apos;mayun@111.com&apos;) add1=Address(&apos;beijing motuoluola&apos;) # db.session.add(user1) db.session.add(add1) db.session.commit() return &quot;create complate&quot;@app.route(&apos;/show&apos;)def show(): u=User.query.filter(User.email.startswith(&apos;m&apos;)).first() return u.usernameif __name__ == &apos;__main__&apos;: app.run() 项目目录123456flaskdemo app.py database.py models.py config.py testabc.db init_app() 相关参考 【Flask】Flask和SQLAlchemy：init_app - 阿秀的学习笔记 - 博客频道 - CSDN.NET Flask and SQLAlchemy: init_app &middot; Blog Introduction into Contexts &#8212; Flask-SQLAlchemy Documentation (2.1) 一对多、多对多关系一对多待完善。 多对多待完善。 文中所用各类库版本1234Flask==0.12Flask-SQLAlchemy==2.1Jinja2==2.8.1SQLAlchemy==1.1.4 相关参考 Flask-SQLAlchemy &mdash; Flask-SQLAlchemy 0.16 documentation–中文版 Flask-SQLAlchemy &mdash; Flask-SQLAlchemy Documentation (2.1)–英文版 （这两个文档比对着参考，0.16版中有些方法已经过时了，代码按照2.1的来，中文释义参考0.16版的） 在 Flask 中使用 SQLAlchemy &mdash; Flask 0.10 documentation flask-sqlalchemy 简单笔记 - 简书 Flask学习记录之Flask-SQLAlchemy - agmcs - 博客园 Flask-SQLAlchemy 学习总结 - python 学习 - SegmentFault Flask Web Development —— 数据库（上） - young - SegmentFault 这个配置说明比较详细 使用 Flask 框架写用户登录功能的Demo时碰到的各种坑（一）——创建应用 - cjnmy36723 - 博客园 Flask-SQLAlchemy–GitBook]]></content>
      <tags>
        <tag>Flask</tag>
        <tag>SQLAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python下操作SQLAlchemy]]></title>
    <url>%2F2017%2F01%2F06%2Fuse-sqlalchemy-by-python%2F</url>
    <content type="text"><![CDATA[Python中通过SQLAlchemy操作数据库。 安装通过pip安装SQLAlchemy 1$ pip install sqlalchemy 初始化数据库连接12# 初始化数据库连接engine=create_engine(&apos;sqlite:///./cnblogblog.db&apos;,echo=True) 其中，echo=True 表示 是否将执行过程中的sql语句进行输出显示 常用数据库连接写法整理常用-直接拷贝 sqlite内存：engine = create_engine(&#39;sqlite:///:memory:&#39;, echo=True) sqlite文件: engine=create_engine(&#39;sqlite:///./cnblogblog.db&#39;,echo=True) mysql+pymysql：engine = create_engine(&quot;mysql+pymysql://username:password@hostname:port/dbname&quot;,echo=True) mssql+pymssql: engine = create_engine(&#39;mssql+pymssql://username:password@hostname:port/dbname&#39;,echo=True) 1&gt;&gt;&gt; from sqlalchemy import create_engine create_engine() 用来初始化数据库连接。SQLAlchemy用一个字符串表示连接信息： 1&apos;数据库类型+数据库驱动名称://用户名:口令@机器地址:端口号/数据库名&apos; sqlite 内存 示例 engine = create_engine(&#39;sqlite:///:memory:&#39;, echo=True) sqlite 文件 示例 engine=create_engine(&#39;sqlite:///./cnblogblog.db&#39;,echo=True) mysql通用 engine = create_engine(&#39;mysql+mysqlconnector://root:password@localhost:3306/test&#39;) mysql+pymysql 示例 engine = create_engine(&quot;mysql+pymysql://username:password@hostname/dbname&quot;, encoding=&quot;utf8&quot;, echo=True) postgresql 示例 engine = create_engine(&#39;postgresql://scott:tiger@localhost:5432/mydatabase&#39;) PostgreSQL 12345678# defaultengine = create_engine(&apos;postgresql://scott:tiger@localhost/mydatabase&apos;)# psycopg2engine = create_engine(&apos;postgresql+psycopg2://scott:tiger@localhost/mydatabase&apos;)# pg8000engine = create_engine(&apos;postgresql+pg8000://scott:tiger@localhost/mydatabase&apos;) MySQL 1234567891011# defaultengine = create_engine(&apos;mysql://scott:tiger@localhost/foo&apos;)# mysql-pythonengine = create_engine(&apos;mysql+mysqldb://scott:tiger@localhost/foo&apos;)# MySQL-connector-pythonengine = create_engine(&apos;mysql+mysqlconnector://scott:tiger@localhost/foo&apos;)# OurSQLengine = create_engine(&apos;mysql+oursql://scott:tiger@localhost/foo&apos;) Oracle 123engine = create_engine(&apos;oracle://scott:tiger@127.0.0.1:1521/sidname&apos;)engine = create_engine(&apos;oracle+cx_oracle://scott:tiger@tnsname&apos;) MS SQL 12345# pyodbcengine = create_engine(&apos;mssql+pyodbc://scott:tiger@mydsn&apos;)# pymssqlengine = create_engine(&apos;mssql+pymssql://scott:tiger@hostname:port/dbname&apos;) SQLite 12345678910111213# sqlite://&lt;nohostname&gt;/&lt;path&gt;# where &lt;path&gt; is relative:engine = create_engine(&apos;sqlite:///foo.db&apos;)#Unix/Mac - 4 initial slashes in totalengine = create_engine(&apos;sqlite:////absolute/path/to/foo.db&apos;)#Windowsengine = create_engine(&apos;sqlite:///C:\\path\\to\\foo.db&apos;)#Windows alternative using raw stringengine = create_engine(r&apos;sqlite:///C:\path\to\foo.db&apos;)#memoryengine = create_engine(&apos;sqlite://&apos;) 详见官网文档：Engine Configuration 如何设置初始化表结构时字段的 主键 自增 等属性sqlite中如果设置主键自增，还需要添加 __table_args__ 参数，示例如下： 12345class Person(Base): __tablename__ = &quot;person&quot; __table_args__ = &#123;&apos;sqlite_autoincrement&apos;: True&#125; id=Column(Integer,primary_key=True,autoincrement=True) sqlalchemy - Pylons, SQlite and autoincrementing fields - Stack Overflow 设置表结构的 不可空 默认值 唯一 等属性1234567891011# 定义User对象class User(Base): &quot;&quot;&quot;Users table&quot;&quot;&quot; # 表的名字 __tablename__=&apos;users&apos; __table_args__=&#123;&apos;sqlite_autoincrement&apos;: True&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name=Column(String(32),nullable=False) age=Column(Integer,default=0) password=Column(String(64),unique=True) 插入中文数据直接插入中文数据，可能会报如下错误信息： sqlalchemy.exc.ProgrammingError: (sqlite3.ProgrammingError) You must not use 8-bit bytestrings unless you use a text_factory that can interpret 8-bit bytestrings (like text_factory = str). It is highly recommended that you instead just switch your application to Unicode strings. 相应的解决方法是：将 str 类型的中文转成 unicode 类型再插入即可。 示例代码如下: 1234567# 添加一条数据def addUserForZhCn(): session=DBSession() new_user=User(name=u&apos;关羽2&apos;,password=&apos;12322233&apos;) session.add(new_user) session.commit() session.close() 参考自： Python 官方文档中不建议使用这种方式：use of sys.setdefaultencoding() has always been discouraged，在文件头写上 # coding: utf-8 之类的注释并且在 Unicode 字符串前加上 u 就可以了。 Flask Sqlalchemy中文模糊搜索错误 Mysql 指定表的引擎和编码格式123456789101112from sqlalchemy import Column, Integer, Stringclass User(BaseModel): __tablename__=&apos;users&apos; __table_args__=&#123; &quot;mysql_engine&quot;:&quot;InnoDB&quot;, # 表的引擎 &quot;mysql_charset&quot;:&quot;utf8&quot; # 表的编码格式 &#125; id=Column(&quot;id&quot;,Integer,primary_key=True,autoincrement=True) name=Column(&quot;name&quot;,String(50),nullable=False) age=Column(&quot;age&quot;,Integer,default=0) 如果记录存在则修改，不存在则添加1session.merge() 模型的属性名称和表的字段名称不一致12id=Column(&quot;id&quot;,Integer,primary_key=True,autoincrement=True)name=Column(&quot;name&quot;,String(50),nullable=False) 增删改 查询增删改需要 commit 操作 : 1234session=DBSession()duser=session.query(User).filter(User.id==2).delete()session.commit()session.close() 查询不需要 commit 操作: 1234session=DBSession()quser=session.query(User).filter(User.id==4).one()print(&apos;name:&apos;,quser.name)session.close() first() 和 one() 的区别query.first()：返回第一个元素query.one()有且只有一个元素时才正确返回 first()方法限制并仅作为标量返回结果集的第一条记录 one()方法，完整的提取所有的记录行，并且如果没有明确的一条记录行(没有找到这条记录)或者结果中存在多条记录行，将会引发错误异常NoResultFound或者MultipleResultsFound。 当没有数据行返回时，使用 one() 方法会报错，可以使用 one_or_none() 方法来代替，当没有数据时，会返回 None 而不是异常。 执行sql语句绑定参数也可以用基于字符串的SQL指派，使用冒号来标记替代参数，然后再使用params()方法指定相应的值。 12session.query(User).filter(&quot;id&lt;:value and name=:name&quot;).\params(value=224, name=&apos;fred&apos;).order_by(User.id).one() execute() 方法 1234567891011121314151617s=DBSession()# 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数# s.execute(&apos;INSERT INTO users (name, age, password) VALUES (?, ?, ?)&apos;,(&apos;bigpang&apos;,2,&apos;1122121&apos;)) # 这样执行报错 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (:aa, :bb, :cc)&apos;,(&#123;&apos;aa&apos;:&apos;bigpang2&apos;,&apos;bb&apos;:22,&apos;cc&apos;:&apos;998&apos;&#125;))# s.commit()# 这样执行成功res=s.execute(&apos;select * from users where age=:aaa&apos;,&#123;&apos;aaa&apos;:4&#125;)# print(res[&apos;name&apos;]) # 错误# print(res.name) # 错误# print(type(res)) # 错误for r in res: print(r[&apos;name&apos;]) s.close() 可参考：python - How to execute raw SQL in SQLAlchemy-flask app - Stack Overflow 执行sql语句 高级 执行sql语句，可以使用传统的 connection 方式，也可以使用 session 方式 sqlalchemy下的传统connection方式，执行sql语句时不需要 cursor 光标，执行增删改直接生效，执行sql语句不需要 commit 操作。 sqlalchemy下的传统connection方式，参数形式与传统方式相同，使用 ? 占位，元祖形式传值 sqlalchemy下的session方式，执行增删改需要 commit 操作。 sqlalchemy下的session方式，参数形式为 dict, 在sql语句中使用 :key 占位，dict形式传值 示例代码123456789101112131415161718192021222324252627282930313233# **传统 connection方式**# 创建一个connection对象，使用方法与调用python自带的sqlite使用方式类似# 使用with 来创建 conn，不需要显示执行关闭连接# with engine.connect() as conn:# res=conn.execute(&apos;select * from users&apos;)# data=res.fetchone()# print(&apos;user is %s&apos; %data[1])# 与python自带的sqlite不同，这里不需要 cursor 光标，执行sql语句不需要commit。如果是增删改，则直接生效，也不需要commit.# **传统 connection 事务**with engine.connect() as conn: trans=conn.begin() try: r1=conn.execute(&quot;select * from users&quot;) print(r1.fetchone()[1]) r2=conn.execute(&quot;insert into users (name,age,password) values (?,?,?)&quot;,(&apos;tang&apos;,5,&apos;133444&apos;)) trans.commit() except: trans.rollback() raise# **session**session=DBSession()session.execute(&apos;select * from users&apos;)session.execute(&apos;insert into users (name,age,password) values (:name,:age,:password)&apos;,&#123;&quot;name&quot;:&apos;dayuzhishui&apos;,&apos;age&apos;:6,&apos;password&apos;:&apos;887&apos;&#125;)# 注意参数使用dict，并在sql语句中使用:key占位# 如果是增删改，需要 commitsession.commit()# 用完记得关闭，也可以用 withsession.close() 详情可见：sqlalchemy学习笔记 - python学习笔记 - SegmentFault 完整测试代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228# coding:utf-8from sqlalchemy import create_enginefrom sqlalchemy.ext.declarative import declarative_basefrom sqlalchemy import Column, Integer, Stringfrom sqlalchemy.orm import sessionmaker# ***************************# 初始化数据库连接engine=create_engine(&apos;sqlite:///./cnblogblog.db&apos;,echo=True)# 创建对象的基类Base=declarative_base()# 创建会话类DBSession=sessionmaker(bind=engine)# ******************# 定义User对象class User(Base): &quot;&quot;&quot;Users table&quot;&quot;&quot; # 表的名字 __tablename__=&apos;users&apos; __table_args__=&#123;&apos;sqlite_autoincrement&apos;: True&#125; # 表结构 id=Column(Integer,primary_key=True,autoincrement=True) name=Column(String(32),nullable=False) age=Column(Integer,default=0) password=Column(String(64),unique=True)class Blog(Base): &quot;&quot;&quot;docstring for Blog&quot;&quot;&quot; __tablename__=&apos;blogs&apos; id=Column(Integer,primary_key=True) title=Column(String(100)) desc=Column(String(500))class Tips(Base): &quot;&quot;&quot;docstring for Tips&quot;&quot;&quot; __tablename__=&apos;tips&apos; id=Column(Integer,primary_key=True) name=Column(String(32))# ***********************# 添加一条数据def newUser(): # 创建会话对象 session=DBSession() new_user=User(name=&apos;Jery&apos;,password=&apos;123&apos;) session.add(new_user) session.commit() session.close()# 添加一条数据def addUserForZhCn(): session=DBSession() new_user=User(name=u&apos;关羽2&apos;,password=&apos;12322233&apos;) session.add(new_user) session.commit() session.close()# 新增多条数据def addmoreUser(): session=DBSession() session.add_all([ User(name=&apos;guanyu&apos;,age=4,password=&apos;11111&apos;), User(name=&apos;zhangfei&apos;,password=&apos;2233&apos;), User(name=&apos;zhenji&apos;,password=&apos;44556&apos;) ]) session.commit() session.close()# 查询def queryUser(): session=DBSession() quser=session.query(User).filter(User.id==4).one() print(&apos;name:&apos;,quser.name) session.close()# 删除def deleteUser(): session=DBSession() duser=session.query(User).filter(User.id==2).delete() session.commit() session.close()# 执行sql语句def SQlUser(): s=DBSession() # 不能用 `?` 的方式来传递参数 要用 `:param` 的形式来指定参数 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (?, ?, ?)&apos;,(&apos;bigpang&apos;,2,&apos;1122121&apos;)) # 这样执行报错 # s.execute(&apos;INSERT INTO users (name, age, password) VALUES (:aa, :bb, :cc)&apos;,(&#123;&apos;aa&apos;:&apos;bigpang2&apos;,&apos;bb&apos;:22,&apos;cc&apos;:&apos;998&apos;&#125;)) # s.commit() # 这样执行成功 res=s.execute(&apos;select * from users where age=:aaa&apos;,&#123;&apos;aaa&apos;:4&#125;) # print(res[&apos;name&apos;]) # 错误 # print(res.name) # 错误 # print(type(res)) # 错误 for r in res: print(r[&apos;name&apos;]) s.close()# 执行sql语句def SQlUser2(): # **传统 connection方式** # 创建一个connection对象，使用方法与调用python自带的sqlite使用方式类似 # 使用with 来创建 conn，不需要显示执行关闭连接 # with engine.connect() as conn: # res=conn.execute(&apos;select * from users&apos;) # data=res.fetchone() # print(&apos;user is %s&apos; %data[1]) # 与python自带的sqlite不同，这里不需要 cursor 光标，执行sql语句不需要commit。如果是增删改，则直接生效，也不需要commit. # **传统 connection 事务** with engine.connect() as conn: trans=conn.begin() try: r1=conn.execute(&quot;select * from users&quot;) print(r1.fetchone()[1]) r2=conn.execute(&quot;insert into users (name,age,password) values (?,?,?)&quot;,(&apos;tang&apos;,5,&apos;133444&apos;)) trans.commit() except: trans.rollback() raise # **session** session=DBSession() session.execute(&apos;select * from users&apos;) session.execute(&apos;insert into users (name,age,password) values (:name,:age,:password)&apos;,&#123;&quot;name&quot;:&apos;dayuzhishui&apos;,&apos;age&apos;:6,&apos;password&apos;:&apos;887&apos;&#125;) # 注意参数使用dict，并在sql语句中使用:key占位 # 如果是增删改，需要 commit session.commit() # 用完记得关闭，也可以用 with session.close()# 更多操作def TestUser(): session=DBSession() # test1 # 使用merge方法，如果存在则修改，如果不存在则插入（只判断主键，不判断unique列） # t1=session.query(User).filter(User.name==&apos;zhenji&apos;).first() # t1.age=34 # session.merge(t1) # session.commit() # test2 # merge方法，如果数据库中没有则添加 # t2=User() # t2.name=&apos;haha&apos; # session.merge(t2) # session.commit() # test3 # 获取第2-3项 # tUser=session.query(User)[1:3] # for u in tUser: # print(u.id) # test4 # if __name__ == &apos;__main__&apos;: # 删除全部数据库 # Base.metadata.drop_all(engine) # 初始化数据库 # Base.metadata.create_all(engine) # 删除全部数据库 # Base.metadata.drop_all(engine) # 删除指定的数据库 # 如删除 Blogs表 # 详见 ：http://stackoverflow.com/questions/35918605/how-to-delete-a-table-in-sqlalchemy # Blog.__table__.drop(engine) # 新增数据 # newUser() # 新增多条数据 # addmoreUser() # 新增数据含中文 # addUserForZhCn() # 查询数据 # queryUser() # 删除 # deleteUser() # 测试 # TestUser() # 执行sql语句 # SQlUser() # 执行sql语句2 SQlUser2() print(&apos;ok&apos;) sqlalchemy 教程入门 Test.py 作为一个Pythoner，不会SQLAlchemy ☆ SQLAlchemy ORM教程之一：Create - 简书 ☆ SQLAlchemy ORM教程之二：Query - 简书 ☆ SQLAlchemy ORM教程之三：Relationship - 简书 ☆ 增删改查常用命令 sqlalchemy学习笔记 - python学习笔记 - SegmentFault ☆ SQLAlchemy 使用经验 note/sqlalchemy.md at master · lzjun567/note · GitHub]]></content>
      <tags>
        <tag>Python</tag>
        <tag>SQLAlchemy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统实时监控工具-Glances]]></title>
    <url>%2F2017%2F01%2F05%2Flinux-real-time-monitoring-glances%2F</url>
    <content type="text"><![CDATA[Ubuntu系统下安装通过 apt-get 方式来安装12$ sudo apt-get update$ sudo apt-get install glances 通过 pip 方式来安装(推荐)12$ sudo pip install python-dev$ sudo pip install glances 建议通过 pip 的方式来安装，因为我通过 apt-get 方式安装的 glances 版本为 Glances version 1.7.3 with PsUtil 1.2.1 ，而通过 pip 安装的为 Glances v2.7.1 with psutil v4.3.1 ，旧版本的功能比较简单。 在安装过程中可能出现报错： 1warning: no previously-included files matching &apos;*&apos; found under directory &apos;docs/_build&apos; 首先执行如下命令并尝试再次安装： 1sudo apt-get install libpq-dev python-dev 通过官方给出的方式安装1$ curl -L https://bit.ly/glances | /bin/bash or: 1$ wget -O- https://bit.ly/glances | /bin/bash Alpine系统下安装执行如下命令安装123$ apk update$ apk add python-dev py-pip py2-psutil$ pip install glances 使用安装完成后，可以执行下面的命令启动 Glances： 1$ glances 可以看到类似下面的输出： 12345678910111213141516171819MyServer (Ubuntu 14.04 64bit / Linux 4.4.0-38-generic) Uptime: 1:41:59CPU [ 3.0%] CPU 3.0% nice: 0.0% ctx_sw: 193 MEM 6.5% SWAP 0.0% LOAD 2-coreMEM [ 6.5%] user: 1.3% irq: 0.0% inter: 266 total: 1.95G total: 2.24G 1 min: 0.00SWAP [ 0%] system: 1.3% iowait: 0.0% sw_int: 372 used: 129M used: 0 5 min: 0.00 idle: 97.1% steal: 0.2% free: 1.82G free: 2.24G 15 min: 0.00NETWORK Rx/s Tx/s TASKS 114 (140 thr), 1 run, 113 slp, 0 oth sorted automaticallydocker0 0b 0beth0 75Kb 44Kb CPU% MEM% VIRT RES PID USER NI S TIME+ R/s W/s Command lo 0b 0b 4.7 1.2 377M 23.2M 11918 tiger 0 R 0:01.90 0 0 /usr/bin/python / 0.3 0.1 250M 2.63M 556 syslog 0 S 0:00.18 0 0 rsyslogdDISK I/O R/s W/s 0.0 0.0 0 0 18 root -20 S 0:00.00 0 0 perfdm-0 0 19K 0.0 0.1 23.1M 2.12M 915 root 0 S 0:00.00 0 0 crondm-1 0 0 0.0 0.2 42.4M 3.22M 630 root 0 S 0:00.10 0 0 /lib/systemd/systxvda1 0 0 0.0 0.0 0 0 19 root 0 S 0:00.00 0 0 xenwatchxvda2 0 0 0.0 0.0 0 0 81 root -20 S 0:00.00 0 0 biosetxvda5 0 19K 0.0 0.0 0 0 2 root 0 S 0:00.00 0 0 kthreaddxvdb 0 0 0.0 0.0 0 0 71 root -20 S 0:00.00 0 0 bioset 要退出 Glances 终端，按 ESC 键或 Ctrl + C。 通过browser查看先安装 bottle ，然后通过 -w 参数启动浏览器服务，默认会监听 61208 端口。 更多命令可通过命令 glances --help 查看帮助。 1234$ sudo pip install bottle$ glances -wGlances web server started on http://0.0.0.0:61208/ 然后在浏览器端输入网址即可查看。 相关参考 glances GitHub - nicolargo/glances: Glances an Eye on your system. A top/htop alternative. Glances &mdash; Glances 2.7.1 documentation]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Glances</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序开发体验]]></title>
    <url>%2F2017%2F01%2F05%2Fwx-xiaochengxu-development-experience%2F</url>
    <content type="text"><![CDATA[简易教程官方文档 简易教程-小程序 app.js、app.json、app.wxss 这三个，.js后缀的是脚本文件，.json后缀的文件是配置文件，.wxss后缀的是样式表文件。 app.js是小程序的脚本代码。我们可以在这个文件中监听并处理小程序的生命周期函数、声明全局变量。调用框架提供的丰富的 API，如本例的同步存储及同步读取本地数据。 app.json 是对整个小程序的全局配置。我们可以在这个文件中配置小程序是由哪些页面组成，配置小程序的窗口背景色，配置导航条样式，配置默认标题。注意该文件不可添加任何注释。详见：配置 app.wxss 是整个小程序的公共样式表。 创建页面页面都在 pages 目录下。 微信小程序中的每一个页面的【路径+页面名】都需要写在 app.json 的 pages 中，且 pages 中的第一个页面是小程序的首页。 每一个小程序页面是由同路径下同名的四个不同后缀文件的组成，如：index.js、index.wxml、index.wxss、index.json。.js后缀的文件是脚本文件，.json后缀的文件是配置文件，.wxss后缀的是样式表文件，.wxml后缀的文件是页面结构文件。 页面的样式表是非必要的。当有页面样式表时，页面的样式表中的样式规则会层叠覆盖 app.wxss 中的样式规则。 框架框架提供了自己的视图层描述语言 WXML 和 WXSS，以及基于 JavaScript 的逻辑层框架，并在视图层与逻辑层间提供了数据传输和事件系统，可以让开发者可以方便的聚焦于数据与逻辑上。 响应的数据绑定框架的核心是一个响应的数据绑定系统。 整个系统分为两块视图层（View）和逻辑层（App Service） 文件结构框架程序包含一个描述整体程序的 app 和多个描述各自页面的 page。 一个框架程序主体部分由三个文件组成，必须放在项目的根目录：app.js app.json app.wxss 一个框架页面由四个文件组成，分别是：.js .wxml .wxss .json 配置使用app.json文件来对微信小程序进行全局配置，决定页面文件的路径、窗口表现、设置网络超时时间、设置多 tab 等。 app.json 配置项列表 pages 设置页面路径 window 设置默认页面的窗口表现 tabBar 设置底部 tab 的表现 networkTimeout 设置网络超时时间 debug 设置是否开启 debug 模式 pages 接受一个数组，每一项都是字符串，来指定小程序由哪些页面组成。 对应页面的【路径+文件名】信息 数组的第一项代表小程序的初始页面。 小程序中新增/减少页面，都需要对 pages 数组进行修改 文件名不需要写文件后缀 window设置小程序的状态栏、导航条、标题、窗口背景色。 navigationBarBackgroundColor 导航栏背景颜色，如”#000000” navigationBarTextStyle 导航栏标题颜色，仅支持 black/white navigationBarTitleText 导航栏标题文字内容 backgroundColor 窗口的背景色 backgroundTextStyle 下拉背景字体、loading 图的样式，仅支持 dark/light enablePullDownRefresh 是否开启下拉刷新 false/true tabBar多 tab 应用（客户端窗口的底部有tab栏可以切换页面）, 可以通过 tabBar 配置项指定 tab 栏的表现，以及 tab 切换时显示的对应页面。 tabBar 是一个数组，只能配置最少2个、最多5个 tab，tab 按数组的顺序排序。 color tab 上的文字默认颜色 selectedColor tab 上的文字选中时的颜色 backgroundColor tab 的背景色 borderStyle tabbar上边框的颜色， 仅支持 black/white list tab 的列表，最少2个、最多5个 tab list 属性值： pagePath 页面路径，必须在 pages 中先定义 text tab 上按钮文字 iconPath 图片路径，icon 大小限制为40kb selectedIconPath 选中时的图片路径，icon 大小限制为40kb networkTimeout设置各种网络请求的超时时间。 request wx.request的超时时间，单位毫秒 connectSocket wx.connectSocket的超时时间，单位毫秒 uploadFile wx.uploadFile的超时时间，单位毫秒 downloadFile wx.downloadFile的超时时间，单位毫秒 debug在控制台面板中调试信息以 info 的形式给出，其信息有Page的注册，页面路由，数据更新，事件触发 。 page.json每一个小程序页面也可以使用.json文件来对本页面的窗口表现进行配置。 页面的配置比app.json全局配置简单得多，只是设置 app.json 中的 window 配置项的内容，页面中配置项会覆盖 app.json 的 window 中相同的配置项。 页面的.json只能设置 window 相关的配置项,以决定本页面的窗口表现，无需写 window 这个键。 逻辑层AppApp()App() 函数用来注册一个小程序。接受一个 object 参数，其指定小程序的生命周期函数等。 object 参数说明： onLaunch 当小程序初始化完成时，会触发 onLaunch（全局只触发一次） onShow 当小程序启动，或从后台进入前台显示，会触发 onShow onHide 当小程序从前台进入后台，会触发 onHide 其他 开发者可以添加任意的函数或数据到 Object 参数中，用 this 可以访问 前台、后台定义： 当用户点击左上角关闭，或者按了设备 Home 键离开微信，小程序并没有直接销毁，而是进入了后台；当再次进入微信或再次打开小程序，又会从后台进入前台。 123456789101112App(&#123; onLaunch: function() &#123; // Do something initial when launch. &#125;, onShow: function() &#123; // Do something when show. &#125;, onHide: function() &#123; // Do something when hide. &#125;, globalData: &apos;I am global data&apos;&#125;) App.prototype.getCurrentPage()getCurrentPage() 函数用户获取当前页面的实例。 getApp()全局的 getApp() 函数，可以获取到小程序实例。 注意： App() 必须在 app.js 中注册，且不能注册多个。 不要在定义于 App() 内的函数中调用 getApp() ，使用 this 就可以拿到 app 实例。 不要在 onLaunch 的时候调用 getCurrentPage()，此时 page 还没有生成。 通过 getApp() 获取实例之后，不要私自调用生命周期函数。 PagePage() 函数用来注册一个页面。接受一个 object 参数，其指定页面的初始数据、生命周期函数、事件处理函数等。 object参数说明： data 页面的初始数据 onLoad 生命周期函数–监听页面加载 onReady 生命周期函数–监听页面初次渲染完成 onShow 生命周期函数–监听页面显示 onHide 生命周期函数–监听页面隐藏 onUnload 生命周期函数–监听页面卸载 onPullDownRefreash 页面相关事件处理函数–监听用户下拉动作 其他 开发者可以添加任意的函数或数据到 object 参数中，用 this 可以访问 初始化数据初始化数据将作为页面的第一次渲染。数据必须是可以转成 JSON 的格式：字符串，数字，布尔值，对象，数组。 Page.prototype.setData()setData 函数用于将数据从逻辑层发送到视图层，同时改变对应的 this.data 的值。 注意： 直接修改 this.data 无效 单次设置的数据不能超过 1024 KB setData() 参数格式接受一个对象，以 key，value 的形式表示将 this.data 中的 key 对应的值改变成 value。 页面的路由 文件作用域 在 JavaScript 文件中声明的变量和函数只在该文件中有效； 不同的文件中可以声明相同名字的变量和函数，不会互相影响。 通过全局函数 getApp() 可以获取全局的应用实例 如果需要全局的数据可以在 App() 中设置 模块化模块只有通过 module.exports 才能对外暴露接口。 1234567// common.jsfunction sayHello(name) &#123; console.log(&apos;Hello &apos; + name + &apos;!&apos;)&#125;module.exports = &#123; sayHello: sayHello&#125; 在需要使用这些模块的文件中，使用 require(path) 将公共代码引入。 123456var common = require(&apos;common.js&apos;)Page(&#123; helloMINA: function() &#123; common.sayHello(&apos;MINA&apos;) &#125;&#125;)]]></content>
      <tags>
        <tag>微信小程序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTTP 413 curl 22 The requested URL returned error 413 Request Entity Too Large]]></title>
    <url>%2F2016%2F12%2F30%2Fnginx-request-entity-too-large%2F</url>
    <content type="text"><![CDATA[问题原因在使用gogs时，git push 代码报如下错误： 1error: RPC failed; HTTP 413 curl 22 The requested URL returned error: 413 Request Entity Too Large 经查证，是服务器上的nginx默认情况下只允许上传最大 1m 大小的文件。nginx默认配置如下： 123Syntax: client_max_body_size size;Default: client_max_body_size 1m;Context: http, server, location 解决方法在 nginx 的配置文件 nginx.conf 中的 http 段内，添加 client_max_body_size 配置： 12345http &#123; ... client_max_body_size 50m; ... &#125; 后面的 50m 表示最大允许上传 50M 大小的文件。 然后重新加载 nginx 配置信息： 1$ sudo service nginx reload 相关参考 Module ngx_http_core_module nginx client_max_body_size 的问题 | yanghao&#039;s blog git - Github Push Error: RPC failed; result=22, HTTP code = 413 - Stack Overflow]]></content>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python独立运行环境Virtualenv]]></title>
    <url>%2F2016%2F12%2F28%2Fpython-independent-operating-environment-virtualenv%2F</url>
    <content type="text"><![CDATA[Virtualenv可以为每个Python应用创建独立的开发环境，使他们互不影响，Virtualenv能够做到： 在没有权限的情况下安装新套件 不同应用可以使用不同的套件版本 套件升级不影响其他应用 安装virtualenv使用pip安装（推荐）1$ sudo pip install virtualenv 使用 easy_install 安装：1$ sudo easy_install virtualenv 初始化我通常创建一个包含虚拟名称为 venv 文件夹的项目文件夹: 123456$ mkdir myproject$ cd myproject$ virtualenv venvNew python executable in venv/bin/python2Also creating executable in venv/bin/pythonInstalling setuptools, pip...done. 激活虚拟环境现在，每次需要使用项目时，必须先激活相应的环境。 在Linux系统下执行123456$ ls-- venv$ source ./venv/bin/activate//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ 在Win系统下执行1234&gt; lsvenv/&gt; venv\Scripts\activate.bat(venv) D:\YYYY 你现在就进入你的 virtualenv 虚拟环境了（注意查看你的 shell 提示符已经改变了）。 退出虚拟环境通过 deactivate 命令退出虚拟环境。 virtualenv 命令整理安装1pip install virtualenv 创建1virtualenv &lt;EnvName&gt; *nix1$ source ./venv/bin/activate 此处 venv 为 &lt;EnvName&gt; Win1&gt; venv\Scripts\activate 此处 venv 为 &lt;EnvName&gt; 退出1deactivate 相关参考 virtualenv &mdash; virtualenv 1.7.1.2.post1 documentation]]></content>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux系统下使用Gogs搭建Git Service]]></title>
    <url>%2F2016%2F12%2F26%2Fuse-gogs-to-build-yourself-git-server%2F</url>
    <content type="text"><![CDATA[基本环境搭建 新建用户 Gogs 默认以 git 用户运行（你应该也不会想一个能修改 ssh 配置的程序以 root 用户运行吧？）。运行 sudo adduser git 新建好 git 用户并设置密码。 然后 su - git 切换至 git 用户登录。 具体操作如下： 1$ sudo adduser git 根据提示信息，输入新账户 git 密码，其他用户信息直接敲回车即可。 安装git 因为新创建的用户 git 没有设置管理员权限，所以我们先在 root 账户或其他管理员账户下安装 git : 123$ sudo apt-get update$ sudo apt-get install git$ git --version //检查git是否安装成功 切换到新创建的git用户： 1$ su - git 进入用户git的根目录下： 1$ cd ~ 下载解包 我使用的是预编译的二进制安装包。需要从源码编译的话，请参考一般 Go 语言项目的编译。 数据库采用 Sqlite3 数据库，如想使用Mysql 获取其他数据库，请参考官网的安装方法。 创建gogs应用的解压目录： 1234$ mkdir goapp$ cd goapp$ pwd/home/git/goapp 从 官网 或从 GitHub Tags 下载当前最新的版本 v0.9.13 版，linux amd64 并解压： 1234$ wget https://dl.gogs.io/gogs_v0.9.13_linux_amd64.zip$ unzip gogs_v0.9.13_linux_amd64.zip$ lsgogs gogs_v0.9.13_linux_amd64.zip 进入 gogs 目录： 123$ cd gogs$ lsgogs LICENSE public README.md README_ZH.md scripts templates 创建自定义配置文件目录并修改文件夹权限： 1234$ mkdir custom$ mkdir custom/conf$ sudo chmod -R 777 custom 在当前 git 用户下，如果提示没有 sudo 权限，可以先临时更新为其他用户，更改目录读写权限，改完后再切换回 git 用户： 123$ su root$ sudo chmod -R 777 custom$ su - git 创建日志目录并修改文件夹权限： 123$ mkdir log$ sudo chmod -R 777 log 启动gogs: 1234$ pwd/home/git/goapp/gogs$ ./gogs web 执行命令后，出现 Listen:http://0.0.0.0:3000 提示信息，表示 gogs 启动成功。 然后访问 http://服务器IP:3000/ 来进行安装，填写好表单之后提交就可以了。默认第一个创建的账户为管理员账户。 表单中指定了 Database Settings – Path 为数据库的存放目录。Application General Settings – Repository Root Path 为仓库文件的存放目录。 配置Nginx在管理员账户下执行： 1$ sudo apt-get install nginx 在 /etc/nginx/conf.d 目录下添加 gogsweb.conf 文件，填入如下内容： 12345678server &#123; server_name git.****.com; listen 80; location / &#123; proxy_pass http://127.0.0.1:3000/; &#125;&#125; 然后通过 sudo service nginx restart 重启 nginx 服务。 配置 supervisor 启动在管理员账户下执行： 1$ sudo apt-get install supervisor 在 /etc/supervisor/conf.d 目录下添加 gogsweb.conf 文件，填入如下内容： 12345678910111213141516[program:gogs]directory=/home/git/goapp/gogs/command=/home/git/goapp/gogs/gogs webautostart=trueautorestart=truestartsecs=10stdout_logfile=/home/git/goapp/gogs/log/stdout.logstdout_logfile_maxbytes=1MBstdout_logfile_backups=10stdout_capture_maxbytes=1MBstderr_logfile=/home/git/goapp/gogs/log/stderr.logstderr_logfile_maxbytes=1MBstderr_logfile_backups=10stderr_capture_maxbytes=1MBuser = gitenvironment = HOME=&quot;/home/git&quot;, USER=&quot;git&quot; 以上的配置信息在 gogs 目录下的 Scripts 文件夹下有给出，可参考。 开启 supervisor UI 管理台编辑 /etc/supervisor/supervisor.conf 主配置文件，修改或添加(通过apt-get的方式安装后不包含该配置) 以下内容： 1234[inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; (ip_address:port specifier, *:port for all iface)username=user ; (default is no username (open server))password=123 ; (default is no password (open server)) port 中 *.9001 表示接受任意网络的请求，如果设置成 127.0.0.1 则只接受本地访问请求。 通过通过 sudo supervisorctl reload 重启服务。 重启之后，如果之前的配置也没有问题的话，现在在浏览器上通过域名即可浏览该站点了。 在浏览器中输入 服务器IP:9001 来访问 supervisor UI 的管理端页面。 Gogs的个性化配置 顶部导航菜单中 “帮助” 链接文字，未登录用户不显示 “帮助” 按钮： 目录: gogs\templates\base\head.tmpl 位置： 1&lt;a class=&quot;item&quot; target=&quot;_blank&quot; href=&quot;http://gogs.io/docs&quot; rel=&quot;noreferrer&quot;&gt;&#123;&#123;.i18n.Tr &quot;help&quot;&#125;&#125;&lt;/a&gt; 将 标签下面的改行注释掉。 底部右下角显示 “官方网站” 字样，修改为 “Gogs官方网站”： 目录： gogs\templates\base\footer.tmpl 位置： 1&lt;a target=&quot;_blank&quot; href=&quot;http://gogs.io&quot;&gt;&#123;&#123;.i18n.Tr &quot;website&quot;&#125;&#125;&lt;/a&gt; 更改为：1&lt;a target=&quot;_blank&quot; href=&quot;https://gogs.io&quot;&gt;Gogs&#123;&#123;.i18n.Tr &quot;website&quot;&#125;&#125;&lt;/a&gt; 首页，首页样式改版： 目录： gogs\templates\home.tmpl 为md文件中的a标签链接添加target属性，在新页面打开 在 goapp/gogs/public/js/ 目录下，添加名为 mdlinktarget-1.0.min.js 内容如下： 1$(document).ready(function()&#123;$(&apos;#file-content a[href^=&quot;http&quot;]&apos;).each(function()&#123;$(this).attr(&quot;target&quot;,&quot;_blank&quot;)&#125;)&#125;); 在项目目录 gogs\templates\base 下找到 footer.tmpl 文件，在最下面添加js引用： 1&lt;script src=&quot;&#123;&#123;AppSubUrl&#125;&#125;/js/mdlinktarget-1.0.min.js&quot;&gt;&lt;/script&gt; 参考 Installation - Gogs - Go Git Service 使用 Gogs 搭建自己的 Git 服务器 - My Nook]]></content>
      <tags>
        <tag>Gogs</tag>
        <tag>Git Server</tag>
        <tag>代码管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Docker镜像加速器]]></title>
    <url>%2F2016%2F12%2F26%2Fsetting-docker-mirror-image-accelerator%2F</url>
    <content type="text"><![CDATA[由于“你懂得”的原因，在国内获取Docker镜像时经常因为网络原因而下载失败，有些人会选择“番茄”，但是配置起来着实麻烦。所以选择国内的镜像加速器是目前解决该问题的最好方法。这里我主要介绍阿里云的Docker镜像加速器和DaoCload的镜像加速器的配置方法。 注意：针对于 Ubunt16.04系统下的Docker配置镜像加速器，可直接参考整理的最新文章：Ubuntu16.04安装Docker及配置镜像加速器 配置阿里云Docker镜像加速器打开 官方地址 开发者平台 – 管理中心 – 加速器 。可以看到 “您的专属加速器地址” 即 https://xxxxxxx.mirror.aliyuncs.com 。 Ubuntu系统下如何配置因为我的系统为 Ubuntu 15.04 , 所以这里仅以Ubuntu系统下的配置方法为例，其他系统可参考官网中的说明。 安装或升级Docker这里要求必须是 1.6.0 以上版本的Docker。可以从阿里云的镜像仓库下载 mirrors.aliyun.com/help/docker-engine 1curl -sSL http://acs-public-mirror.oss-cn-hangzhou.aliyuncs.com/docker-engine/internet | sh - 配置Docker加速器如果Ubuntu系统是 12.04 14.04 ，Docker 1.9 以上， 执行： 12echo &quot;DOCKER_OPTS=\&quot;\$DOCKER_OPTS --registry-mirror=https://xxxxxxx.mirror.aliyuncs.com\&quot;&quot; | sudo tee -a /etc/default/dockersudo service docker restart 如果Ubuntu系统是 15.04 16.04 ，Docker 1.9 以上， 执行： 12345678sudo mkdir -p /etc/systemd/system/docker.service.dsudo tee /etc/systemd/system/docker.service.d/mirror.conf &lt;&lt;-&apos;EOF&apos;[Service]ExecStart=ExecStart=/usr/bin/docker daemon -H fd:// --registry-mirror=https://xxxxxxx.mirror.aliyuncs.comEOFsudo systemctl daemon-reloadsudo systemctl restart docker 等待Docker服务重启后，再次下载镜像则非常快了。 配置DaoCload的镜像加速器打开 官方地址 DaoCloud – 产品 – 加速器 – 立即使用 。 Linux系统配置 Docker 加速器命令脚本自动配置 （推荐）DaoCloud也会为你分配一个专属的加速器地址，可以直接拷贝页面中给出的代码： 1# curl -sSL https://get.daocloud.io/daotools/set_mirror.sh | sh -s http://xxxxxx.m.daocloud.io 该脚本可以将 --registry-mirror 加入到你的 Docker 配置文件 /etc/default/docker 中。适用于 Ubuntu14.04、Debian、CentOS6 、CentOS7、Fedora、Arch Linux、openSUSE Leap 42.1，其他版本可能有细微不同。 手动配置也可以自己手动修改。 在 /etc/default/docker 文件底部添加如下内容： 1$ sudo vim /etc/default/docker 添加： 1DOCKER_OPTS=&quot;$DOCKER_OPTS --registry-mirror=http://xxxxxx.m.daocloud.io&quot; 重启Docker服务配置完成后需要重启docker服务。 1$ sudo service docker restart 注意事项 如果你的系统当前登陆用户不是管理员账户的话，记得添加 sudo 以免执行失败。 上文代码段中给出的镜像加速器地址中的 xxxxxxx 为阿里云或DaoCloud在你注册账户后分配的指定地址名称，切记要修改为自己账户的给定地址。 相关链接 阿里云开发者平台 DaoCloud Docker 镜像加速器-博客-云栖社区-阿里云 使用DaoCloud安装Docker和镜像 - 简书]]></content>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Alpine下配置Selenium运行环境]]></title>
    <url>%2F2016%2F10%2F19%2Fconfiguration-the-selenium-running-environment-in-alpine%2F</url>
    <content type="text"><![CDATA[配置环境 Alpine Linux 3.4 安装依赖设置软件安装源1$ echo &quot;http://dl-4.alpinelinux.org/alpine/v3.4/main&quot; &gt;&gt; /etc/apk/repositories 安装依赖包执行以下命令： 123$ apk update$ apk add python py-pip curl unzip$ pip install selenium 支持的浏览器及 WebDriver 驱动这里我以常用的Chrome 和 Firefox 为例，来配置运行环境。 Selenium调用Chrome浏览器Alpine系统下面使用Chrome推荐安装开源的 Chromium 浏览器 安装 Chromium因为在软件库中存在 Chromium 的包，所以可以直接通过 apk 来安装： 1$ apk add chromium 然后还要安装 chromium 的依赖包： 1$ apk add libexif udev 如果没有安装 libexif udev 这两个依赖包，会报如下错误，Chromium浏览器会无法启动： selenium.common.exceptions.WebDriverException: Message: unknown error: Chrome failed to start: crashed 上面命令执行完成后，chromium 浏览器就安装好了。可以通过命令 chromium-browser 来测试： 12$ chromium-browser[54:54:1019/081743:ERROR:browser_main_loop.cc(261)] Gtk: cannot open display: 因为在 Server 系统下没有显示窗口，提示上面的信息说明 chromium 程序可以调用的到，只是无法显示。 安装 ChromeDriverChromeDriver是一个实现了WebDriver与Chromium联接协议的独立服务。 通过 apk 安装我们可以直接通过如下命令来安装 chromedriver 程序： 1$ apk add chromium-chromedriver 测试 ChromeDriver执行 chromedriver 查看是否能正常运行。 123$ chromedriverStarting ChromeDriver 2.22 (5e2d5494d735a71aa5c2e7ef9bf5ce96945e92e9) on port 9515Only local connections are allowed. 当提示 Starting ChromeDriver xxx on port 9515 信息时，说明 ChromeDriver 设置成功。 Selenium调用Firefox浏览器安装 Firefox 浏览器可以通过 apk 直接安装 Firefox 浏览器： 1$ apk add firefox-esr 然后还要安装 firefox 的依赖包： 1$ apk add dbus-x11 ttf-freefont 其中 dbus-x11 中 x11 中是数字1，D-Bus 是一个消息总线，用于在应用程序间发送消息。 如果不安装会报如下错误信息： selenium.common.exceptions.WebDriverException: Message: connection refused 在 geckodriver.log 文件中查看到如下信息: process 116: D-Bus library appears to be incorrectly set up; failed to read machine uuid: Failed to open “/etc/machine-id”: No such file or directorySee the manual page for dbus-uuidgen to correct this issue. D-Bus not compiled with backtrace support so unable to print a backtraceRedirecting call to abort() to mozalloc_abort 其中 ttf-freefont 是一个字体相关的依赖包，如果不安装会报如下错： selenium.common.exceptions.WebDriverException: Message: Failed to decode response from marionette 在 geckodriver.log 文件中查看到如下信息: Crash Annotation GraphicsCriticalError: |[0][GFX1]: no fonts - init: 1 fonts: 0 loader: 0[GFX1]: no fonts - init: 1 fonts: 0 loader: 0^G[162] ###!!! ABORT: unable to find a usable font (serif): file /home/buildozer/aports/community/firefox-esr/src/firefox-45.4.0esr/gfx/thebes/gfxTextRun.cpp[162] ###!!! ABORT: unable to find a usable font (serif): file /home/buildozer/aports/community/firefox-esr/src/firefox-45.4.0esr/gfx/thebes/gfxTextRun.cpp, 可通过命令 firefox 测试 firefox浏览器是否安装成功： 12$ firefoxError: no display specified 同样的，由于没有显示窗口，也会提示 no display 的错误。 安装 geckodriver下载 geckodriver访问站点 geckodriver 下载当前系统对应 geckodriver 程序。 执行如下命令： 123456$ curl https://github.com/mozilla/geckodriver/releases/download/v0.11.1/geckodriver-v0.11.1-linux64.tar.gz -O$ tar -zxvf geckodriver-v0.11.1-linux64.tar.gz$ lsgeckodriver 解压后我们得到了一个 geckodriver 执行程序。 该 geckodriver 压缩包可能由于网络原因下载失败，可通过迅雷等软件下载后拷贝到Linux系统中。 将 geckodriver 放到系统 PATH 目录下我们可以在程序中指定具体的 geckodriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ mv ./geckodriver /usr/local/bin/$ chmod a+x /usr/local/bin/geckodriver 测试 geckodriver执行 geckodriver 查看是否能正常运行。 12$ geckodriver 1476443497207 geckodriver INFO Listening on 127.0.0.1:4444 当提示 Listening on 127.0.0.1:4444 信息时，说明 geckodriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 geckodriver : selenium.common.exceptions.WebDriverException: Message: ‘geckodriver’ executable needs to be in PATH. 安装虚拟显示器 xvfb为什么要用 xvfb??xvfb 这个工具相当于一个wrapper，给应用程序提供虚拟的 X server 执行如下命令安装12$ apk add xvfb$ pip install pyvirtualdisplay 测试 selenium 调用浏览器获取网页Chrome 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 chrome.py ，执行： 12$ python chrome.py博客园 - 开发者的网上家园 Firefox 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Firefox()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 firefox.py ，执行： 12$ python firefox.py博客园 - 开发者的网上家园 Docker实现详情请参考开源项目： Leafney/alpine-selenium-chrome leafney/alpine-selenium-chrome Leafney/alpine-selenium-firefox leafney/alpine-selenium-firefox]]></content>
      <tags>
        <tag>Alpine</tag>
        <tag>Selenium</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下配置Selenium运行环境]]></title>
    <url>%2F2016%2F10%2F19%2Fconfiguration-the-selenium-running-environment-in-ubuntu%2F</url>
    <content type="text"><![CDATA[Selenium，自动化测试工具。 配置环境 Ubuntu 16.04 TLS 安装依赖设置软件安装源1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 也可以改成： 1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt; /etc/apt/sources.list 安装依赖包执行以下命令： 123$ sudo apt-get update$ sudo apt-get install python python-pip curl unzip -y$ sudo pip install selenium 支持的浏览器及 WebDriver 驱动Selenium可以调用Chrome 、Firefox 、Safari 等浏览器。 WebDriver 支持以下的 ChromeDriver EventFiringWebDriver FirefoxDriver HtmlUnitDriver InternetExplorerDriver PhantomJSDriver RemoteWebDriver SafariDriver 这里我以常用的Chrome 和 Firefox 为例，来配置运行环境。 我们需要安装相对应的浏览器和浏览器驱动 WebDriver 。比如 Selenium 无法直接启动 Chrome ，需要用第三方插件 ChromeDriver 来调用。 Selenium调用Chrome浏览器Chrome浏览器我们可以使用官方的 Google Chrome 浏览器 或者 开源的 Chromium 浏览器 安装 Google Chrome执行如下命令安装，这里我们选择的是 google-chrome-stable 版本： 123456$ wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -$ sudo sh -c &apos;echo &quot;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&quot; &gt;&gt; /etc/apt/sources.list.d/google.list&apos;sudo apt-get updatesudo apt-get install google-chrome-stable 详细可访问： UbuntuUpdates-Google Chrome All “google-chrome-stable” versions 或者可以通过以下命令直接下载 *.deb 安装包： x64 – $ curl http://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_54.0.2840.59-1_amd64.deb -O x32 – 32位版本已不可用 安装deb安装包： 1$ dpkg -i google-chrome-stable_54.0.2840.59-1_amd64.deb 安装过程中可能会安装失败，缺少依赖： 12345dpkg: error processing package google-chrome-stable (--install): dependency problems - leaving unconfiguredProcessing triggers for mime-support (3.59ubuntu1) ...Errors were encountered while processing: google-chrome-stable 通过如下命令解决： 1$ apt-get -f install software installation - How to install Google Chrome? - Ask Ubuntu 安装 ChromiumGoogle Chrome isn’t in the repositories - however, Chromium is. 因为在软件库中存在 Chromium 的包，所以可以直接通过 apt-get 来安装： 12$ sudo apt-get update$ sudo apt-get install chromium-browser 未安装Chrome浏览器异常如果未安装 Google-Chrome 或 Chromium 浏览器，会提示如下错误信息： 1selenium.common.exceptions.WebDriverException: Message: unknown error: cannot find Chrome binary 安装 ChromeDriverChromeDriver是一个实现了WebDriver与Chromium联接协议的独立服务。 下载 ChromeDriver访问站点 chromedriver 下载当前系统对应的 chromedriver 程序, 页面中给出了不同Chrome版本对应的 ChromeDriver 程序。 执行命令如下，下载并解压： 123456$ curl http://chromedriver.storage.googleapis.com/2.24/chromedriver_linux64.zip -O$ unzip chromedriver_linux64.zip$ lschromedriver 解压后我们得到了一个 chromedriver 执行程序。 将 ChromeDriver 放到系统 PATH 目录下我们可以在程序中指定具体的 ChromeDriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ sudo mv ./chromedriver /usr/local/bin/$ sudo chmod a+x /usr/local/bin/chromedriver 测试 ChromeDriver执行 chromedriver 查看是否能正常运行。 123$ chromedriver Starting ChromeDriver 2.24.417424 (c5c5ea873213ee72e3d0929b47482681555340c3) on port 9515Only local connections are allowed. 当提示 Starting ChromeDriver xxx on port 9515 信息时，说明 ChromeDriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 ChromeDriver : selenium.common.exceptions.WebDriverException: Message: ‘chromedriver’ executable needs to be in PATH. Please see https://sites.google.com/a/chromium.org/chromedriver/home Selenium调用Firefox浏览器安装 Firefox 浏览器可以通过 apt-get 直接安装 Firefox 浏览器： 1$ sudo apt-get install firefox 未安装Firefox浏览器异常如果未安装 Firefox 浏览器程序，则会提示如下错误： selenium.common.exceptions.WebDriverException: Message: Expected browser binary location, but unable to find binary in default location, no ‘moz:firefoxOptions.binary’ capability provided, and no binary flag set on the command line 安装 geckodriver下载 geckodriver访问站点 geckodriver 下载当前系统对应 geckodriver 程序。 执行如下命令： 123456$ curl https://github.com/mozilla/geckodriver/releases/download/v0.11.1/geckodriver-v0.11.1-linux64.tar.gz -O$ tar -zxvf geckodriver-v0.11.1-linux64.tar.gz$ lsgeckodriver 解压后我们得到了一个 geckodriver 执行程序。 该 geckodriver 压缩包可能由于网络原因下载失败，可通过迅雷等软件下载后拷贝到Linux系统中。 将 geckodriver 放到系统 PATH 目录下我们可以在程序中指定具体的 geckodriver 所在的目录，不指定的话会默认去系统PATH目录下找。为了编程方便，我们将其放到系统PATH目录下。 查看系统目录： 1$ echo $PATH 这里我将其放到 /usr/local/bin/ 目录下，并添加可执行权限： 123$ sudo mv ./geckodriver /usr/local/bin/$ sudo chmod a+x /usr/local/bin/geckodriver 测试 geckodriver执行 geckodriver 查看是否能正常运行。 12$ geckodriver 1476443497207 geckodriver INFO Listening on 127.0.0.1:4444 当提示 Listening on 127.0.0.1:4444 信息时，说明 geckodriver 设置成功。 如果提示如下错误信息，则是在系统PATH下找不到 geckodriver : selenium.common.exceptions.WebDriverException: Message: ‘geckodriver’ executable needs to be in PATH. 安装虚拟显示器 xvfb为什么要用 xvfb??xvfb 这个工具相当于一个wrapper，给应用程序提供虚拟的 X server 执行如下命令安装12$ sudo apt-get install xvfb$ sudo pip install pyvirtualdisplay 测试selenium调用浏览器获取网页Chrome 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 chrome.py ，执行： 12$ python chrome.py博客园 - 开发者的网上家园 Firefox 版本1234567891011121314151617#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Displaydisplay=Display(visible=0,size=(800,800))display.start()driver=webdriver.Firefox()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)title=driver.titleprint(title.encode(&apos;utf-8&apos;))driver.close()display.stop() 将以上代码保存为 firefox.py ，执行： 12$ python firefox.py博客园 - 开发者的网上家园 代码详解12345678910111213141516171819202122#coding:utf-8import timefrom selenium import webdriverfrom pyvirtualdisplay import Display# 设置虚拟显示器的窗口大小display=Display(visible=0,size=(800,800))display.start()driver=webdriver.Chrome()driver.get(&apos;http://www.cnblogs.com/&apos;)time.sleep(5)# 打印网页的标题title=driver.titleprint(title.encode(&apos;utf-8&apos;))# 退出浏览器driver.close()# 关闭虚拟显示器窗口display.stop() Docker实现详情请参考开源项目： 相关参考 ChromeDriver WebDriver - Mozilla | MDN GitHub - mozilla/geckodriver: WebDriver &lt;-&gt; Marionette proxy ☆ python - How do I run Selenium in Xvfb? - Stack Overflow ☆ Selenium2.0]]></content>
      <tags>
        <tag>Selenium</tag>
        <tag>Python</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下安装及配置MySql数据库]]></title>
    <url>%2F2016%2F10%2F06%2Fubuntu-install-mysql-db%2F</url>
    <content type="text"><![CDATA[安装过程测试系统为 Ubuntu 16.04 LTS 更新Ubuntu软件安装源1$ echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ xenial main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 安装mysql-server执行如下命令安装mysql: 12$ sudo apt-get update$ sudo apt-get install mysql-server 安装过程会弹出提示框，输入root用户的密码，这里设置密码为 mysql 。 安装完成后，通过命令 mysql -V 查看mysql版本信息： 12# mysql -Vmysql Ver 14.14 Distrib 5.7.15, for Linux (x86_64) using EditLine wrapper 解决mysql连接错误 ERROR 2002 (HY000)在使用 root 账户连接mysql时，报了如下的 2002 错误： 123# mysql -uroot -pEnter password: ERROR 2002 (HY000): Can&apos;t connect to local MySQL server through socket &apos;/var/run/mysqld/mysqld.sock&apos; (2) 查看 mysql 服务是否启动，执行如下命令查看： 1234# ps -aux |grep mysqldroot 984 0.0 0.0 11276 728 ? S+ 07:23 0:00 grep --color=auto mysqld# ps -aux |grep mysql root 986 0.0 0.0 11276 728 ? S+ 07:23 0:00 grep --color=auto mysql 可见mysql的服务并没有启动，然后我们尝试启动服务： 1234$ sudo service mysql start# service mysql start * Starting MySQL database server mysqld No directory, logging in with HOME=/ mysql的服务居然无法启动。 最终找到原因是当前用户对 /var/run/mysqld 目录没有操作权限导致的。 先查看 /var/run/ 下是否存在 mysqld目录，没有先创建。 执行如下命令： 1$ sudo chown -R mysql:mysql /var/run/mysqld 然后再次尝试启动mysql服务： 1234567891011121314151617$ sudo service mysql start# service mysql status * /usr/bin/mysqladmin Ver 8.42 Distrib 5.7.15, for Linux on x86_64Copyright (c) 2000, 2016, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Server version 5.7.15-0ubuntu0.16.04.1Protocol version 10Connection Localhost via UNIX socketUNIX socket /var/run/mysqld/mysqld.sockUptime: 7 secThreads: 1 Questions: 8 Slow queries: 0 Opens: 105 Flush tables: 1 Open tables: 98 Queries per second avg: 1.142 可以看到mysql服务启动成功了。 网上查找各种解决该问题的方法，也只有这一种方法是根本原因。 所以当再次遇到该问题的时候，先查看一下目录是否有操作权限： 1$ ls -al /var/run/mysqld/ chown命令将指定文件的拥有者改为指定的用户或组 Can’t connect to local MySQL server through socket ‘/var/run/mysqld/mysqld.sock’的解决 新增账户及权限设置第一种方法以管理员身份登陆mysql1$ mysql -uroot -p 输入之前设置的密码，登陆mysql命令模式。 选择 mysql 数据库1mysql&gt; use mysql; 创建用户并设定密码先查看默认存在哪些账户： 12345678910mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root |+-----------+------------------+3 rows in set (0.00 sec) 执行以下命令来创建新用户账户及密码： 1mysql&gt; create user &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;testpassword&apos;; 将 testpassword 替换为你自己的密码。 执行如下命令使操作生效： 1mysql&gt; flush privileges; 示例操作如下： 12345678910111213141516mysql&gt; create user &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 |+-----------+------------------+4 rows in set (0.00 sec) 为新账户创建数据库12mysql&gt; create database testdb;Query OK, 1 row affected (0.03 sec) 为新账户赋予操作新建数据库 testdb 的权限12345mysql&gt; grant all privileges on testdb.* to &apos;testuser1&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec) testdb.* 表示操作 testdb 这个数据库中所有的表 &#39;testuser1&#39;@&#39;localhost&#39; 表示使用账户 testuser1 登陆到 localhost &#39;123456&#39; 表示登陆密码 使用新账户登陆我们在上面的步骤中创建的新用户为 testuse1 密码为 123456 管理的数据库为 testdb。 使用 exit 退出 root 账户的登陆，然后使用新账户登陆： 123456mysql&gt; exitBye$ mysql -u testuser1 -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g. 登陆成功后，查看数据库列表： 12345678mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || testdb |+--------------------+2 rows in set (0.00 sec) 第二种方法 通过GRANT授权的方式新增用户以root账户登录：123$ mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. 新增数据库为新账户创建数据库 testdb2 12mysql&gt; create database testdb2;Query OK, 1 row affected (0.00 sec) 新增账户并设置密码新增账户 testuser2 密码为 123456 管理 testdb2 数据库。 通过 grant all privileges on 语句来操作： 123456789101112131415mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys || testdb || testdb2 |+--------------------+6 rows in set (0.00 sec)mysql&gt; grant all privileges on testdb2.* to &apos;testuser2&apos;@&apos;localhost&apos; identified by &apos;123456&apos;;Query OK, 0 rows affected, 1 warning (0.00 sec) grant all 语句不需要使用 flush privilege; 刷新系统权限表，该操作立即生效。 使用新账户 testuser2 登陆123456789101112131415mysql&gt; exitBye$ mysql -utestuser2 -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || testdb2 |+--------------------+2 rows in set (0.00 sec) 将默认编码改为utf8默认情况下，MySQL的字符集是 latin1 ，因此在存储中文的时候，会出现乱码的情况，所以我们需要把字符集统一改成 UTF-8 。 mysql 默认编码通过如下命令查看mysql默认编码： 123456789101112131415161718192021222324mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | latin1 || character_set_connection | latin1 || character_set_database | latin1 || character_set_filesystem | binary || character_set_results | latin1 || character_set_server | latin1 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.01 sec)+----------------------+-------------------+| Variable_name | Value |+----------------------+-------------------+| collation_connection | latin1_swedish_ci || collation_database | latin1_swedish_ci || collation_server | latin1_swedish_ci |+----------------------+-------------------+3 rows in set (0.00 sec) 更改配置文件一般情况下，在 Ubuntu 14.04 系统中，mysql的配置文件目录为： 1/etc/mysql/my.cnf 在 Ubuntu 16.04 系统下，mysql的配置文件目录为： 123/etc/mysql/my.cnf/etc/mysql/mysql.conf.d/mysqld.cnf 我当前的系统为 Ubuntu16.04 。其实在 ubuntu 16.04 系统中，mysql的配置文件路径也为 /etc/mysql/my.cnf ，只不过这个 my.cnf 是全局配置文件，在该文件内部可以看到如下配置： 123# !includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 具体的配置文件是存放在上面两个目录下的。所以我们可以更改 /etc/mysql/my.cnf 这个文件，也可以更改 /etc/mysql/mysql.conf.d/mysqld.cnf 这个文件。或者也可以自己新增一个扩展名为 *.cnf 的配置文件放在上面包含的两个目录内。 从网上找到各种说法的修改编码为utf-8的方法，经测试后需要修改的配置如下： 12345678910[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect=&apos;SET NAMES utf8&apos;character-set-server=utf8collation-server=utf8_unicode_ci 编辑 /etc/mysql/my.cnf 配置文件，依次添加上面的编码设置。 12345678910111213141516#[client]default-character-set=utf8[mysql]default-character-set=utf8[mysqld]init_connect=&apos;SET NAMES utf8&apos;character-set-server=utf8collation-server=utf8_unicode_ci!includedir /etc/mysql/conf.d/!includedir /etc/mysql/mysql.conf.d/ 然后重启 mysql 服务： 1$ service mysql restart 再次登录mysql命令模式查看默认编码： 123456789101112131415161718192021222324252627$ mysql -uroot -pEnter password: Welcome to the MySQL monitor. Commands end with ; or \g.mysql&gt; show variables like &quot;%character%&quot;;show variables like &quot;%collation%&quot;;+--------------------------+----------------------------+| Variable_name | Value |+--------------------------+----------------------------+| character_set_client | utf8 || character_set_connection | utf8 || character_set_database | utf8 || character_set_filesystem | binary || character_set_results | utf8 || character_set_server | utf8 || character_set_system | utf8 || character_sets_dir | /usr/share/mysql/charsets/ |+--------------------------+----------------------------+8 rows in set (0.00 sec)+----------------------+-----------------+| Variable_name | Value |+----------------------+-----------------+| collation_connection | utf8_general_ci || collation_database | utf8_unicode_ci || collation_server | utf8_unicode_ci |+----------------------+-----------------+3 rows in set (0.00 sec) 可见，我们已经更改成功了。 Change MySQL default character set to UTF-8 in my.cnf? - Stack Overflow 让MySQL服务器被远程访问默认情况下，root账户只能从 localhost 即本机下来访问mysql的服务。而在正式使用时，mysql数据库都是放在远程的数据库服务器上，这样也就需要我们通过远程的方式能够访问到mysql服务。 开启绑定端口编辑配置文件 /etc/mysql/my.cnf 或 /etc/mysql/mysql.conf.d/mysqld.cnf ，将绑定地址行注释掉或者修改为指定IP： 12#注释bind-address# bind-address = 127.0.0.1 注释掉则允许所有ip都能够访问，也可以设置成 0.0.0.0 修改为指定的IP地址，则只允许该IP网段可以访问 修改配置文件后，重启 mysql 服务生效： 1$ service mysql restart 如果这时通过外网连接mysql，在连接时会出现错误 “’Host XXX is not allowed to connect to this MySQL server’ ” ，则还需要修改数据库中用户的访问权限。 修改数据库中账户访问权限这里以 root 账户为例来设置远程访问。 查看root账户可访问权限以 root 账户登录： 12mysql -u root -pEnter password: &lt;enter password&gt; 切换到 mysql 数据库，并查询 user 表中的账户设置： 1234567891011121314151617mysql&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedmysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 || localhost | testuser2 |+-----------+------------------+5 rows in set (0.00 sec) 可以看到，root账户默认下不允许从远程登陆，只能从 localhost 来访问，我们还要为 root 账户添加访问权限。 添加远程访问授权这里有两种方法，一种是将上面的 mysql 数据库中的 user 表里的 host 项，将 localhost 改为 %， 12mysql&gt; use mysql;mysql&gt; update user set host =&apos;%&apos; where user =&apos;root&apos;; 另外一种是为账号 root 添加一个新的远程访问授权。 这里我们采用第二种方法。 通过命令 GRANT ALL PRIVILEGES ON *.* to root@&#39;%&#39; IDENTIFIED BY &#39;put-your-password&#39; WITH GRANT OPTION; 来操作。 执行如下命令： 123456mysql -u root -pEnter password: &lt;enter password&gt;mysql&gt; GRANT ALL PRIVILEGES ON *.* to root@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos; WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES; 再次查看： 123456789101112mysql&gt; select host,user from user;+-----------+------------------+| host | user |+-----------+------------------+| % | root || localhost | debian-sys-maint || localhost | mysql.sys || localhost | root || localhost | testuser1 || localhost | testuser2 |+-----------+------------------+6 rows in set (0.00 sec) 现在再尝试通过外网来连接 mysql 数据库，就能连接成功了。 本地和远程访问使用不同权限或密码在上面的表中我们可以知道，root 账户有两个 host 配置项，一个本地的，一个远程的。其实我们可以将两项设置成不同的密码，以防止本地或远程的密码泄露问题。也可以在 grant 后跟详细的查询条件 select,delete 等，为本地或远程访问设置不同的访问权限。比如： 1mysql&gt; GRANT SELECT,UPDATE,INSERT,DELETE on *.* to root@&apos;%&apos; IDENTIFIED BY &apos;mysql&apos; WITH GRANT OPTION; mysql grant 命令三种常用 - redfox - 博客园 mysql Grant 语法详解 添加特定远程访问权限假设账户 myuser 密码 mypwd grant all privileges on *.* to &#39;myuser&#39;@&#39;localhost&#39; identified by &#39;mypwd&#39; grant all privileges on *.* to &#39;myuser&#39;@&#39;%&#39; identified by &#39;mypwd&#39; grant all privileges on *.* to &#39;myuser&#39;@&#39;10.22.255.18&#39; identified by &#39;mypwd&#39; 说明： 添加一个本地用户 myuser ,一般用于web服务器和数据库服务器在一起的情况 添加一个用户 myuser ,只要能连接数据库服务器的机器都可以使用，这个比较危险，一般不用 在数据库服务器上给 10.22.255.18 机器添加一个用户 myuser，一般用于web服务器和数据库服务器分离的情况 注意：真正使用的时候不会用 grant all PRIVILEGES on *.* ，而是根据实际需要设定相关的权限。 特定访问权限 如果想让账户 myuser 使用 mypwd 从任何主机连接到 mysql 服务器，执行： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;%&apos; IDENTIFIED BY &apos;mypwd&apos; WITH GRANT OPTION; 如果想让账户 myuser 使用密码 123456 从 ip为 123.123.123.123 的主机连接到 mysql 服务器，执行： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;123.123.123.123&apos; IDENTIFIED BY &apos;123456&apos; WITH GRANT OPTION; 即 ‘%’ 表示任何主机。 WITH GRANT OPTION 是啥意思WITH GRANT OPTION 表示具有授予权限的权利。比如 上面的： 1GRANT ALL PRIVILEGES ON *.* to myuser@&apos;%&apos; IDENTIFIED BY &apos;mypwd&apos; WITH GRANT OPTION; 为 root 用户赋予了 ALL PRIVILEGES 的权限，那么 root 账户就可以为其他的账户比如 testuser1 设置不同的权限。]]></content>
      <tags>
        <tag>Ubuntu</tag>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu系统下安装终极Shell-zsh]]></title>
    <url>%2F2016%2F10%2F05%2Fubuntu-install-zsh%2F</url>
    <content type="text"><![CDATA[查看系统 shell终端输入 echo $SHELL ，可以输出当前使用的shell。 终端输入 cat /etc/shells ，可以输出当前系统已经安装的shell。 安装 zsh安装 zsh 需要 git 环境支持，请先确保已安装 git 环境： 1$ sudo apt-get install git 安装 zsh12$ sudo apt-get update$ sudo apt-get install zsh 安装增强插件 oh-my-zsh可以通过 wget 或者 curl 来安装： 12// wget$ wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 12// curl$ curl -L https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh | sh 安装 oh-my-zsh (2017-1-13 Update)上面的命令仍然可以执行。下面的命令是在 Oh My Zsh 官网中查看到的最新安装命令，建议用官网中的推荐安装方法： 12// wget$ sh -c &quot;$(wget https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O -)&quot; 12// curl$ sh -c &quot;$(curl -fsSL https://raw.github.com/robbyrussell/oh-my-zsh/master/tools/install.sh)&quot; 执行完上面的命令后，如果提示如下信息，直接忽略即可，继续执行下面的步骤。 1234Looking for an existing zsh config...Using the Oh My Zsh template file and adding it to ~/.zshrcTime to change your default shell to zsh!Password: chsh: PAM: Authentication failure 将zsh作为默认shell,根据提示输入当前用户的密码,重新登录终端或重启后生效123456$ chsh -s /bin/zsh//或:$ chsh -s `which zsh`$ sudo reboot zsh 主题zsh的默认配置项都在 ~/.zshrc 文件中，例如里面的ZSH_THEME=&quot;robbyrussell&quot; 表示当前zsh的主题为robbyrussell. 配置完之后，我们需要重启终端或打开新的标签，或者用以下命令刷新配置：1source ~/.zshrc oh-my-zsh 提供了数十种主题，我们可以在目录 ~/.oh-my-zsh/themes 中看到他们： 1~/.oh-my-zsh/themes 如果你不知道选哪个好，我们可以设置成随机项： 1ZSH_THEME=&quot;random&quot; oh-my-zsh官方提供的主题如下：Themes · robbyrussell/oh-my-zsh Wiki · GitHub zsh 下的后台程序在 zsh 下，如果有后台运行的程序，此时执行 exit 会提示如下： 12➜ ~ exitzsh: you have running jobs. 在一般的 Bash 下，我们设置后台运行程序用 &amp;: 1$ python cnblog.py &amp; 而在 zsh 下，我们设置后台运行程序则需要用 &amp;!: 1$ python cnblog.py &amp;! StackOverflow上的提示： 123Start the program with—dolphin &amp;!The &amp;! (or equivalently, &amp;|) is a zsh-specific shortcut to both background and disown the process, such that exiting the shell will leave it running. 详见：bash - Exit zsh, but leave running jobs open? - Stack Overflow 相关参考 在Ubuntu上安装zsh Ubuntu 上安装 zsh [Linux] ubuntu安装zsh - TangShangWen - SegmentFault oh-my-zsh]]></content>
      <tags>
        <tag>zsh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下进程管理Supervisor]]></title>
    <url>%2F2016%2F10%2F04%2Fsupervisor-process-management%2F</url>
    <content type="text"><![CDATA[Supervisor Supervisor,是一个进程控制系统，是一个客户端/服务器端系统允许用户在UNIX-LIKE 操作系统中去监控，控制一些进程。Supervisor作为主进程，Supervisor下管理的时一些子进程，当某一个子进程异常退出时，Supervisor会立马对此做处理，通常会守护进程，重启该进程。 Supervisor 有两个主要的组成部分： supervisord，运行 Supervisor 时会启动一个进程 supervisord，它负责启动所管理的进程，并将所管理的进程作为自己的子进程来启动，而且可以在所管理的进程出现崩溃时自动重启。 supervisorctl，是命令行管理工具，可以用来执行 stop、start、restart 等命令，来对这些子进程进行管理。 Supervisor 安装通常除了通过源码的 setup.py 的方式来安装(详见官网文档 Supervisor: A Process Control System &mdash; Supervisor 3.3.0 documentation )，还有以下两种方式： 12$ sudo apt-get install supervisor$ sudo pip install supervisor 但这两种安装方式是有区别的。 通过 pip 的方式安装后不会安装为默认服务，还需要自己将supervisor程序设置为后台服务。而通过 apt-get 的方式安装后就默认创建为了后台服务，可以直接通过 service supervisor restart 的方式来管理。 可见：python - supervisor.conf default location - Stack Overflow 配置文件supervisor的配置文件通常命名为 supervisord.conf。 配置文件检测顺序如下(默认会使用找到的第一个): $CWD/supervisord.conf $CWD/etc/supervisord.conf /etc/supervisord.conf /etc/supervisor/supervisord.conf (since Supervisor 3.3.0) ../etc/supervisord.conf (Relative to the executable) ../supervisord.conf (Relative to the executable) 通过 apt-get install supervisor 方式安装执行 ： 1$ sudo apt-get install supervisor 安装完成后会默认将 supervisord 启动为后台服务： 123$ ps -ef|grep supervisorroot 1455 1 0 15:46 ? 00:00:00 /usr/bin/python /usr/bin/supervisord -c /etc/supervisor/supervisord.conftiger 1470 1298 0 15:46 pts/1 00:00:00 grep --color=auto supervisor 通过 apt-get 安装的 supervisord 程序位于 /usr/bin/ 目录下： 123$ sudo whereis supervisord[sudo] password for tiger:supervisord: /usr/bin/supervisord 安装完成后查看 ls /etc/supervisor/ : 12$ ls /etc/supervisor/conf.d supervisord.conf 我们看到会生成一个默认的 supervisord.conf 配置文件，也可以在 conf.d 目录下创建自己的配置文件。 查看文件 supervisord.conf 内容： 12345678910111213141516171819202122232425262728; supervisor config file[unix_http_server]file=/var/run/supervisor.sock ; (the path to the socket file)chmod=0700 ; sockef file mode (default 0700)[supervisord]logfile=/var/log/supervisor/supervisord.log ; (main log file;default $CWD/supervisord.log)pidfile=/var/run/supervisord.pid ; (supervisord pidfile;default supervisord.pid)childlogdir=/var/log/supervisor ; (&apos;AUTO&apos; child log dir, default $TEMP); the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///var/run/supervisor.sock ; use a unix:// URL for a unix socket; The [include] section can just contain the &quot;files&quot; setting. This; setting can list multiple files (separated by whitespace or; newlines). It can also contain wildcards. The filenames are; interpreted as relative to this file. Included files *cannot*; include files themselves.[include]files = /etc/supervisor/conf.d/*.conf 该默认配置文件中是包含着 conf.d 目录下的所有 *.conf 文件的。我们可以对于不同的项目，使用各自独立的配置文件，放置在 /etc/supervisor/conf.d 目录下。 我们在 conf.d 目录下使用 echo_supervisord_conf 命令来创建一个 hello.conf 配置文件(或者直接通过 vim 创建一个空的 .conf 文件也可)： 12$ tiger@localhost:/etc/supervisor/conf.d$ echo_supervisord_conf &gt; hello.conf-bash: Hello.conf: 权限不够 如果提示没有权限的问题，可以使用下面的命令： 1$ sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisor/conf.d/hello.conf&quot; 查看生成的 hello.conf : 123456789101112131415161718192021222324252627282930;[program:theprogramname];command=/bin/cat ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1 ; number of processes copies to start (def 1);directory=/tmp ; directory to cwd to before exec (def no cwd);umask=022 ; umask for process (default None);priority=999 ; the relative start priority (default 999);autostart=true ; start at supervisord start (default: true);autorestart=unexpected ; whether/when to restart (default: unexpected);startsecs=1 ; number of secs prog must stay running (def. 1);startretries=3 ; max # of serial start failures (default 3);exitcodes=0,2 ; &apos;expected&apos; exit codes for process (default 0,2);stopsignal=QUIT ; signal used to kill process (default TERM);stopwaitsecs=10 ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false ; send stop signal to the UNIX process group (default false);killasgroup=false ; SIGKILL the UNIX process group (def false);user=chrism ; setuid to this UNIX account to run the program;redirect_stderr=true ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10 ; # of stdout logfile backups (default 10);stdout_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stdout_events_enabled=false ; emit events on stdout writes (default false);stderr_logfile=/a/path ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10 ; # of stderr logfile backups (default 10);stderr_capture_maxbytes=1MB ; number of bytes in &apos;capturemode&apos; (default 0);stderr_events_enabled=false ; emit events on stderr writes (default false);environment=A=1,B=2 ; process environment additions (def no adds);serverurl=AUTO ; override serverurl computation (childutils) 我们需要管理的程序只要依照上面的说明进行配置即可： 假如在目录 /home/tiger/py 下有一个需要在后台运行的 Python 程序 hello.py 。日志文件保存在 /home/tiger/py/logs 下。 123456789101112# coding:utf-8import timedef make_log(): while True: time.sleep(2) with open(&apos;hello.log&apos;,&apos;a&apos;) as f: f.write(&apos;hello_&apos;+time.strftime(&quot;%H:%M:%S&quot;)+&apos;\r&apos;)if __name__ == &apos;__main__&apos;: make_log() 我们向上面创建的配置文件 /etc/supervisor/conf.d/hello.conf 中写入如下数据(可把已有的数据清空，分号 ; 开头的表示注释信息)： 12345678910[program:hello] ;服务的名称command=python hello.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/hellopy.log ; log 日志stderr_logfile=/home/tiger/py/logs/hellopy.err ; 错误日志 使文件具有可写权限: 1$ sudo chmod 777 /etc/supervisor/conf.d/hello.conf 通过如下命令启动 supervisor： 1$ sudo supervisord -c /etc/supervisor/supervisord.conf 通过 apt-get 安装的 supervisor 在安装完成后已经作为了后台服务启动了，修改了配置文件后只需要重新加载即可生效。 重新加载配置文件使用命令： 1$ sudo supervisorctl reload 其他操作命令： 1234$ sudo supervisorctl -c /etc/supervisor/supervisord.conf status 查看管理进程状态$ sudo supervisorctl -c /etc/supervisor/supervisord.conf reload 重新载入配置项$ sudo supervisorctl -c /etc/supervisor/supervisord.conf start [all]|[appname] 启动指定/所有程序进程$ sudo supervisorctl -c /etc/supervisor/supervisord.conf stop [all]|[appname] 关闭指定/所有程序进程 注意： supervisor 默认情况下如果不指定要执行的配置文件路径会按照默认的顺序去查询相应的配置文件，按找到的第一个为准。所以，执行以上代码时，精简的代码为： 1$ sudo supervisorctl status 完整的代码为： 1$ sudo supervisorctl -c /etc/supervisor/supervisord.conf status -c 参数指定使用的配置文件目录 更多参数请通过 supervisorctl -h/--help 查看。 测试时发现在 Ubuntu 16.04 系统下通过 apt-get 方式安装的 Supervisor 3.3.0 之前版本(eg:3.2.0.x) 默认不会注册为后台服务，3.3.0.x后的版本会默认注册为后台服务。 待考证 通过 pip install supervisor 的方式安装通过 sudo pip install supervisor 安装完成后不会在 /etc/ 下生成 supervisor 目录及其下的文件。应用程序是存在于 /usr/local/bin/ 目录中: 12$ ls /usr/local/bin/echo_supervisord_conf pidproxy supervisorctl supervisord 可见安装时的脚本如下： 1234567............Installing /usr/local/lib/python2.7/dist-packages/supervisor-3.3.0-nspkg.pth Installing echo_supervisord_conf script to /usr/local/bin Installing pidproxy script to /usr/local/bin Installing supervisorctl script to /usr/local/bin Installing supervisord script to /usr/local/bin 可见通过 pip 安装的 supervisord 程序位于 /usr/local/bin/ 目录下(或者通过如下命令查找)。 123$ sudo whereis supervisord[sudo] password for tiger:supervisord: /usr/local/bin/supervisord 配置文件通常默认配置文件位于 /etc/supervisord.conf。 通过以下命令来创建默认配置文件： 1$ echo_supervisord_conf &gt; /etc/supervisord.conf 如果出现没有权限的问题，可以使用这条命令: 1$ sudo su - root -c &quot;echo_supervisord_conf &gt; /etc/supervisord.conf&quot; 默认的配置文件是下面这样的，但是这里有个坑需要注意：supervisord.pid 以及 supervisor.sock 是放在 /tmp 目录下，但是 /tmp 目录是存放临时文件，里面的文件会被linux系统删除的，一旦这些文件丢失，就无法再通过 supervisorctl 来执行 restart 和 stop 命令了，将只会得到 unix:///tmp/supervisor.sock 不存在的错误。(通过 apt-get 方式安装的配置文件中不是 /tmp 而是/var/run) 1234567891011121314151617181920212223242526272829303132333435363738394041424344[unix_http_server]file=/tmp/supervisor.sock ; (the path to the socket file);chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; (default is no username (open server));password=123 ; (default is no password (open server));[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface);username=user ; (default is no username (open server));password=123 ; (default is no password (open server))[supervisord]logfile=/tmp/supervisord.log ; (main log file;default $CWD/supervisord.log)logfile_maxbytes=50MB ; (max main logfile bytes b4 rotation;default 50MB)logfile_backups=10 ; (num of main logfile rotation backups;default 10)loglevel=info ; (log level;default info; others: debug,warn,trace)pidfile=/tmp/supervisord.pid ; (supervisord pidfile;default supervisord.pid)nodaemon=false ; (start in foreground if true;default false)minfds=1024 ; (min. avail startup file descriptors;default 1024)minprocs=200 ; (min. avail process descriptors;default 200);umask=022 ; (process file creation umask;default 022);user=chrism ; (default is current user, required if root);identifier=supervisor ; (supervisord identifier, default is &apos;supervisor&apos;);directory=/tmp ; (default is not to cd during start);nocleanup=true ; (don&apos;t clean up tempfiles at start;default false);childlogdir=/tmp ; (&apos;AUTO&apos; child log dir, default $TEMP);environment=KEY=&quot;value&quot; ; (key value pairs to add to environment);strip_ansi=false ; (strip ansi escape codes in logs; def. false); the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as http_username if set;password=123 ; should be same as http_password if set;prompt=mysupervisor ; cmd line prompt (default &quot;supervisor&quot;)...... 将默认配置文件中的以下项进行修改： 123456789101112131415;file=/tmp/supervisor.sock;修改为 `/var/run` 目录file=/var/run/supervisor.sock;logfile=/tmp/supervisord.log;修改为 `/var/log` 目录logfile=/var/log/supervisord.log;pidfile=/tmp/supervisord.pid;修改为 `/var/run` 目录pidfile=/var/run/supervisord.pid;serverurl=unix:///tmp/supervisor.sock;修改为 `/var/run` 目录serverurl=unix:///var/run/supervisor.sock 然后在配置文件中添加启动的程序配置项： 12345678910[program:hello] ;服务的名称command=python hello.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/hellopy.log ; log 日志stderr_logfile=/home/tiger/py/logs/hellopy.err ; 错误日志 启动 supervisord执行 supervisord 命令，将会启动 supervisord 进程，同时我们在配置文件中设置的进程也会相应启动。 使用如下命令来启动: 1$ sudo supervisord -c /etc/supervisord.conf 示例操作命令： 123456789tiger@localhost:~/py$ ps -ef | grep supervisortiger@localhost:~/py$ sudo supervisord -c /etc/supervisord.conftiger@localhost:~/py$ ps -ef | grep supervisorroot 7363 1 0 11:42 ? 00:00:00 /usr/bin/python /usr/local/bin/supervisord -c /etc/supervisord.conftiger@localhost:~/py$ ps -ef | grep hellotiger 7364 7363 0 11:42 ? 00:00:00 python hello.py 我们使用 supervisord 来启动管理进程，之后所有的操作都用 supervisorctl 来控制。 (default /etc/supervisord.conf) supervisorctl 命令介绍123456789101112# appname 为 [program:x] 里的 x$ sudo supervisorctl start [appname]|[all] 启动指定/所有程序进程$ sudo supervisorctl stop [appname]|[all] 停止指定/所有程序进程$ sudo supervisorctl status 查看管理所有进程状态$ sudo supervisorctl status [appname] 查看管理指定进程状态$ sudo supervisorctl reload 载入最新的配置文件，停止原有进程并按新的配置启动、管理所有进程$ sudo supervisorctl update 根据最新的配置文件，启动新配置或有改动的进程，配置没有改动的进程不会受影响而重启$ sudo supervisorctl restart [appname] 重启某个进程$ sudo supervisorctl shutdown 关闭所有管理进程$ sudo supervisorctl start/stop/restart/status groupworker: 管理所有属于名为 groupworker 这个分组的进程$ sudo supervisorctl start/stop/restart/status groupworker:name1 管理分组里指定的进程 注意：显示用 stop 停止掉的进程，用 reload 或者 update 都不会自动重启。 该问题待考证 示例操作命令： 123456tiger@localhost:~/py$ sudo supervisorctl statushello RUNNING pid 7382, uptime 0:01:50tiger@localhost:~/py$ sudo supervisorctl stop hellohello: stoppedtiger@localhost:~/py$ sudo supervisorctl statushello STOPPED Jul 27 11:47 AM 开机自动启动 Supervisord通过 pip 安装的 Supervisord 默认情况下并没有被安装成服务，它本身也是一个进程。我们可以使用安装脚本将supervisord设置为服务。 1234567891011# 下载脚本 (需要root权限)$ sudo su - root -c &quot;sudo curl https://gist.githubusercontent.com/howthebodyworks/176149/raw/d60b505a585dda836fadecca8f6b03884153196b/supervisord.sh &gt; /etc/init.d/supervisord&quot;# 设置该脚本为可以执行$ sudo chmod +x /etc/init.d/supervisord# 设置为开机自动运行% sudo update-rc.d supervisord defaults# 试一下，是否工作正常$ sudo service supervisord stop$ sudo service supervisord start# 查看supervisord进程$ sudo ps -ef| grep supervisor 注意：下载了 supervisord.sh 文件后，请核对好里面的配置参数和本地文件所在目录是否一致(主要是以下部分)： 12345678910 ...# PATH should only include /usr/* if it runs after the mountnfs.sh scriptPATH=/sbin:/usr/sbin:/bin:/usr/binDESC=&quot;Description of the service&quot;NAME=supervisordDAEMON=/usr/local/bin/supervisordDAEMON_ARGS=&quot;&quot;PIDFILE=/var/run/$NAME.pidSCRIPTNAME=/etc/init.d/$NAME ... 详细安装方法及脚本文件见下面两个链接说明： python - How to automatically start supervisord on Linux (Ubuntu) - Server Fault an init.d script for supervisord · GitHub 还有第二种方法将supervisor随系统启动而启动，Linux 在启动的时候会执行 /etc/rc.local 里面的脚本，所以只要在这里添加执行命令即可： 12345# 如果是 Ubuntu 添加以下内容（这里要写全路径，因为此时PATH的环境变量未必设置）/usr/local/bin/supervisord -c /etc/supervisord.conf# 如果是 Centos 添加以下内容/usr/bin/supervisord -c /etc/supervisord.conf 测试 supervisor 管理的进程能自动重启将 supervisor 管理的进程用 kill 命令杀掉，看是否能够自动重启。 1234567tiger@localhost:~/py$ ps -ef | grep hellotiger 7364 7363 0 11:42 ? 00:00:00 python hello.pytiger 7368 1255 0 11:42 pts/0 00:00:00 grep --color=auto hellotiger@localhost:~/py$ kill 7364tiger@localhost:~/py$ ps -ef | grep hellotiger 7382 7363 2 11:45 ? 00:00:00 python hello.pytiger 7384 1255 0 11:45 pts/0 00:00:00 grep --color=auto hello 使用 include在配置文件的最后，有一个 [include] 的配置项。我们可以 include 某个文件夹下的所有配置文件，这样就能为每个进程或相关的几个进程的配置单独写成一个文件。 配置文件的后缀名可以为 .conf 或 .ini。 在 /etc/supervisord.conf 末尾添加如下： 12[include]files = /etc/supervisord.d/*.conf 我们在 /home/tiger/py 目录下再建立一个 world.py 的python程序来做测试。 然后在 /etc 目录下创建 supervisord.d 目录，添加一个 world.conf 配置文件，写入如下配置信息。 12345678910[program:world] ;服务的名称，后面操作会用到command=python world.py ; supervisor启动命令directory=/home/tiger/py ; 项目的文件夹路径user=tiger ; 进程执行的用户身份autostart=true ; 是否自动启动autorestart=true ; 是否自动重启startsecs=1 ; 自动重启间隔;log日志文件的位置stdout_logfile=/home/tiger/py/logs/worldpy.log ; log 日志stderr_logfile=/home/tiger/py/logs/worldpy.err ; 错误日志 然后重新加载配置文件： 1$ sudo supervisorctl reload 查看运行状态： 12345678$ sudo supervisorctl statushello RUNNING pid 1549, uptime 0:00:28world RUNNING pid 1548, uptime 0:00:28$ sudo supervisorctl stop hellohello: stopped$ sudo supervisorctl statushello STOPPED Jul 27 04:53 PMworld RUNNING pid 1573, uptime 0:00:21 这样我们就通过不同的配置文件来管理不同的程序进程了。 Supervisor UI 管理台：在默认配置文件中我们可以找到下面的配置项： 1234;[inet_http_server] ; inet (TCP) server disabled by default;port=127.0.0.1:9001 ; (ip_address:port specifier, *:port for all iface);username=user ; (default is no username (open server));password=123 ; (default is no password (open server)) 去除 [inet_http_server] 和 port=127.0.0.1:9001 前面的分号，然后执行 sudo supervisorctl reload 重新加载配置文件。之后在浏览器中访问 http://localhost:9001 就能查看到Web版的进程管理界面了。 注意：如果设置为 port=127.0.0.1:9001，则只能在本机访问；如果为 port=*:9001 则可以在外网进行访问。 注意：;[inet_http_server] 这个前面的分号必须去掉，要不然不管用。 Supervisor 集群管理集中进程管理，可在一台机器下管理多台机器的进程。 详见：Supervisor集群管理开发 文档 XML-RPC API Documentation &mdash; Supervisor 3.3.0 documentation supervisord 的 XML-RPC API 使用说明 - yexiaoxiaobai - SegmentFault Supervisor集群管理WEB UI (monitor) - WisZhou的想到啥写啥 - 博客频道 - CSDN.NET GitHub - WisZhou/supervisord-monitor: Supervisord Monitoring Tool GitHub - luxbet/supervisorui: Supervisor multi-server dashboard unix:///var/run/supervisor.sock no such file某些情况下，可能会出现如下错误：unix:///var/run/supervisor.sock no such file 对于该问题，我的操作是，执行命令： 1$ sudo supervisord unix:///var/run/supervisor.sock no such file #480 注意：被监控的进程要以非daemon方式运行该问题暂未研究。略。 supervisor深入研究之 多进程略。 supervisor深入研究之 group 分组管理略。 supervisor调用 virtualenv 环境中的python项目配置 .conf 文件时，加上 environment 参数，指定 virtualenv 的目录: 123456789command = /home/www/flasky/env/bin/gunicorn -w 2 -b 0.0.0.0:8080 --max-requests 2000 --log-level debug --name %(program_name)s &quot;app:create_app(&apos;development&apos;)&quot;directory = /home/www/flaskyenvironment=PATH=&quot;/home/www/flasky/env/bin&quot;, GEVENT_RESOLVER=&quot;ares&quot;user = rootnumprocs=1autostart=falseautorestart=true...... 相关链接 Python 进程管理工具 Supervisor 使用教程 - restran - 博客园 Python 进程管理工具 Supervisor 使用教程 | 淡水网志 python - How to automatically start supervisord on Linux (Ubuntu) - Server Fault ubuntu下supervisor安装与使用笔记 - 为程序员服务 使用 supervisor 管理进程 - 李林克斯 使用Supervisor简化进程管理工作 - EverET.org python - supervisor.conf default location - Stack Overflow supervisor的配置文件查询目录 linux 后台进程管理利器supervisor - youxin - 博客园 Supervisor使用教程 | Snow Memory ☆ Linux进程管理工具supervisor安装及使用 | cpper ☆ Supervisor: A Process Control System &mdash; Supervisor 3.3.0 documentation 官方文档 How To Install and Manage Supervisor on Ubuntu and Debian VPS | DigitalOcean supervisor初体验 - 简书 使用 supervisor 管理进程 - 李林克斯 排版好看 supervisord 部署 Flask &#8211; Angiris Council 好 Supervisor手册 - GitBook supervisord 部署 Flask virtualenv wrapper]]></content>
      <tags>
        <tag>Supervisor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Shadowsocks轻松实现科学上网]]></title>
    <url>%2F2016%2F10%2F02%2Fuse-shadowsocks-to-have-better-internet-experience%2F</url>
    <content type="text"><![CDATA[由于个人对百度的厌恶，平时上网很少用百度搜索。而又因为众所周知的原因，在国内要想用Google来上网着实是要费一翻心思的。所以也只能退而求其次，用微软的Bing来查询一些资料。 前几天刚刚把我在香港的云服务器进行了系统更换，从Windows Server换成了Linux系统，想起之前曾看过的使用Shadowsocks实现代理上网的文章，所以就想要亲自实现一下。 shadowsocks是一个著名的轻量级socket代理，原始版本是基于Python编写，后来又有了Go语言版本。不过该版本在Github上的源代码由于“你懂得”的原因，已经被开发者删除了。 这里我推荐安装的是 shadowsocks-libev 版本。shadowsocks-libev 是一个 shadowsocks 协议的轻量级实现，是 shadowsocks-android, shadowsocks-ios 以及 shadowsocks-openwrt 的上游项目。其特点如下： 体积小巧，静态编译并打包后只有 100 KB 高并发，基于 libev 实现的异步 I/O，以及基于线程池的异步 DNS，同时连接数可上万。 基于C语言实现，内存占用小（600k左右），低 CPU 消耗 shadowsocks-libev 的安装我的云服务器系统为 Ubuntu 14.04 TFS 通常 shadowsocks-libev 版本有两种安装方式，从源码安装和通过软件源来安装。这里我推荐使用源码安装的方式。 从源码安装 (Ubuntu/Debian系统下)安装必须的包12345$ sudo apt-get udpate$ mkdir shadowsocks-libev &amp;&amp; cd shadowsocks-libev$ sudo apt-get install build-essential autoconf libtool libssl-dev gawk debhelper dh-systemd init-system-helpers pkg-config asciidoc xmlto apg libpcre3-dev 安装过程会需要一些时间。 通过Git下载源码1$ git clone https://github.com/shadowsocks/shadowsocks-libev.git 然后生成deb包并安装，依照以下步骤依次执行(如果出错请检查系统或者之前的步骤)： 1234567$ cd shadowsocks-libev$ dpkg-buildpackage -b -us -uc -i$ cd ..$ sudo dpkg -i shadowsocks-libev*.deb 在上面的第三步 cd .. 后，可以看到目录下编译生成了三个 *.deb 文件，我这里的是： libshadowsocks-libev-dev_2.5.3-1_amd64.deb libshadowsocks-libev2_2.5.3-1_amd64.deb shadowsocks-libev_2.5.3-1_amd64.deb 上面的步骤操作完成后，我们就已经安装成功了 shadowsocks-libev 。 通过如下命令来查看运行状态： 12$ sudo service shadowsocks-libev status * shadowsocks-libev is not running 通过deb包安装的方式默认会开启自启。 直接从作者提供的软件源安装（Ubuntu/Debian）由于作者更新源码后并不一定及时更新这些预编译的包，所以无法保证最新版本，但操作步骤比较简单。 先添加GPG Key1$ wget -O- http://shadowsocks.org/debian/1D27208A.gpg | sudo apt-key add - 配置安装源，在/etc/apt/sources.list末尾添加12345# Ubuntu 14.04 or above$ deb http://shadowsocks.org/ubuntu trusty main# Debian Wheezy, Ubuntu 12.04 or any distribution with libssl &gt; 1.0.1$ deb http://shadowsocks.org/debian wheezy main 执行安装12$ apt-get update$ apt-get install shadowsocks-libev 这里我在 配置 wget -O- http://shadowsocks.org/debian/1D27208A.gpg | sudo apt-key add - 时无法连接到 http://shadowsocks.org 站点，所以这种方法我就没有继续测试。 shadowsocks-libev 一键安装待完善，详见：https://github.com/iMeiji/shadowsocks_install/wiki/shadowsocks-libev-%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85 配置与启动配置文件shadowsocks-divev 生成的默认配置文件在目录 /etc/shadowsocks-libev 下，找到 config.json 文件并编辑： 将配置信息： 12345678&#123; &quot;server&quot;:&quot;127.0.0.1&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIryahoa&quot;, &quot;timeout&quot;:60, &quot;method&quot;:null&#125; 修改为如下： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8388, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIryahoa&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 其中： server ：主机域名或者IP地址，尽量填IP (可以为服务器实际的IP地址或 0.0.0.0 ) server_port ：服务器监听端口 local_port: 客户端连接端口 password ：密码 timeout ：连接超时时间，单位秒。要适中 method ：加密方式 默认为table,其他有rc4,rc4-md5,aes-128-cfb, aes-192-cfb, aes-256-cfb,bf-cfb, camellia-128-cfb, camellia-192-cfb,camellia-256-cfb, cast5-cfb, des-cfb 注意： 如果客户端有OpenWRT路由器等设备，推荐 rc4-md5 ，性能更好；否则可以选用安全性更好的 aes-256-cfb 等。 server 配置项表示主机的域名或IP地址，这里默认情况下是 127.0.0.1 但不建议设置成 127.0.0.1 ，测试时发现无法正确连通。你可以设置成 0.0.0.0 或 真实的服务器所在的IP地址。修改配置文件重启后生效。 默认的客户端的IP地址为 127.0.0.1 启动上面有提到，通过deb包安装后就默认启动了，通过如下命令来控制： 1234$ sudo service shadowsocks-libev start$ sudo service shadowsocks-libev stop$ sudo service shadowsocks-libev status$ sudo service shadowsocks-libev restart 安装后的shadowsocks程序名为 ss-server ，程序目录为 /usr/bin/ss-server 。 查看 ss-server 的启动信息： 123456$ sudo service shadowsocks-libev status * shadowsocks-libev is not running$ ps ax |grep ss-server40160 ? Ss 0:00 /usr/bin/ss-server -c /etc/shadowsocks-libev/config.json -a root -u -f /var/run/shadowsocks-libev/shadowsocks-libev.pid -u40162 ? S+ 0:00 grep --color=auto ss-server 注意其中有 -u，表示会通过udp的方式进行连接。 通过 netstat -lnp 可以查看 ss-server 监听的端口： 12345678910$ netstat -lnp(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:8388 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::80 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - udp 0 0 0.0.0.0:8388 0.0.0.0:* - 可以看到 ss-server 通过 tcp 和 udp 两种方式监听了 8388 端口。 shadowsocks 客户端的设置shadowsocks 默认支持多种客户端。可以从 Shadowsocks - Clients 下载对应平台的客户端软件。 windows 客户端windows用户可以从 Releases · shadowsocks/shadowsocks-windows · GitHub 下载安装包。解压后得到 Shadowsocks.exe 程序。 运行，配置 服务器地址 服务器端口 密码 加密方式 即可。按照配置文件中的设置，默认监听客户端所在本地系统 127.0.0.1 的 1080 端口。 更加详细的内容可以参考如下文章： Shadowsocks Windows 使用说明 · shadowsocks/shadowsocks-windows Wiki · GitHub Chrome+SwitchyOmega实现科学上网待续。。。 shadowsocks-libev 的多用户配置C语言编写的shadowsocks客户端/服务端软件shadowsocks-libev并不像go版本或python版本的shadowsocks客户端/服务端软件那样直接支持多实例配置，具体可以查看如下说明： please support multi-port config.json · Issue #5 shadowsocks-libev 版本默认不支持在同一个配置文件 config.json 中一次设置多个端口和密码，如果想要设置多个，可以通过添加多个配置文件来实现。 方式一先停止 ss-server 服务： 12345$ sudo service shadowsocks-libev status * shadowsocks-libev is running$ sudo service shadowsocks-libev stop$ sudo service shadowsocks-libev status * shadowsocks-libev is not running 然后，拷贝一份原来的配置文件，自定义新的文件名，只要保证扩展名为 .json 即可，我这里命名为 configuser1.json ： 123$ cd /etc/shadowsocks-libev$ sudo cp config.json configuser1.json$ sudo vim configuser1.json 修改配置参数中的端口号，密码等： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8398, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIrya3oyt&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 然后启动 ss-server 服务： 123$ sudo service shadowsocks-libev start$ sudo service shadowsocks-libev status * shadowsocks-libev is running 执行如下命令添加新的配置文件设置 ： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 注意将其中的 *** 替换为你的配置文件名称。 方式二如果你嫌上面的“停止-拷贝已有配置文件-重启”操作太麻烦，也可以直接新建一个json配置文件，然后填入如下配置信息： 12345678&#123; &quot;server&quot;:&quot;0.0.0.0&quot;, &quot;server_port&quot;:8398, &quot;local_port&quot;:1080, &quot;password&quot;:&quot;OikIrya3oyt&quot;, &quot;timeout&quot;:60, &quot;method&quot;:&quot;aes-256-cfb&quot;&#125; 注意 server_port 要设置成新的端口号。 然后直接执行如下命令即可： 1$ setsid ss-server -c /etc/shadowsocks-libev/***.json -u 查看启动信息： 1234$ ps ax |grep ss-server40103 ? Ss 0:00 ss-server -c /etc/shadowsocks-libev/configuser1.json -u40160 ? Ss 0:00 /usr/bin/ss-server -c /etc/shadowsocks-libev/config.json -a root -u -f /var/run/shadowsocks-libev/shadowsocks-libev.pid -u40162 ? S+ 0:00 grep --color=auto ss-server 可以看到比之前多了一条后台服务。 通过 netstat -lnp 来查看 ss-server 是否监听了多个端口： 123456789101112$ netstat -lnp(No info could be read for &quot;-p&quot;: geteuid()=1000 but you should be root.)Active Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program nametcp 0 0 0.0.0.0:8388 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:8398 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN - tcp 0 0 0.0.0.0:22 0.0.0.0:* LISTEN - tcp6 0 0 :::80 :::* LISTEN - tcp6 0 0 :::22 :::* LISTEN - udp 0 0 0.0.0.0:8388 0.0.0.0:* - udp 0 0 0.0.0.0:8398 0.0.0.0:* - 这样，就实现了监听多个端口，实现多用户连接了。如果想要停止新增的监听端口，只需要重启shadowsocks服务就又恢复默认，只会监听的 config.json 中配置的端口了。 相关链接 shadowsocks libev ☆ shadowsocks client Shadowsocks Windows 使用说明]]></content>
      <tags>
        <tag>Google</tag>
        <tag>Shadowsocks</tag>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新安装Ubuntu系统后的必要设置]]></title>
    <url>%2F2016%2F10%2F01%2Ffirst-install-ubuntu-need-config%2F</url>
    <content type="text"><![CDATA[以下为我在重装Linux系统后进行的一些必要的操作，特此记录。 ubuntu 14.04 升级到 16.04如果直接执行 # do-release-upgrade 升级命令，会遇到：需要的依赖关系未安装 的报错信息： 1The required dependency &apos;apt (&gt;= 1.0.1ubuntu2.13)&apos; is not installed. 我们需要先更新 apt 到 1.0.1ubuntu2.13 以上才能进行升级操作。 通过以下操作来更新： 保持软件源指向 14.04(trusty) 不变 sudo apt-get update &amp;&amp; sudo apt-get upgrade 此时 apt 应已升级到 1.0.1ubuntu2.13，可以继续 do-release-upgrade 了。 总结需要执行的命令如下： 123# sudo apt-get update# sudo apt-get upgrade# sudo do-release-upgrade 操作完成后，重启系统即可：# sudo reboot 。 更新软件包及升级系统到最新的内核更新软件包刚装完linux系统后，软件及内核版本都比较低，需要先更新一下： 刚装完后系统版本为： Ubuntu 16.04.1 LTS 因为我的服务器在香港，所以能连接到ubuntu官方的软件源，如果你的系统是在国内，可能需要更新一下软件源，以免下载太慢或更新失败，设置软件源： 1# echo &quot;deb http://cn.archive.ubuntu.com/ubuntu/ trusty main restricted universe multiverse&quot; &gt;&gt; /etc/apt/sources.list 其他系统可参考 ：Ubuntu 源列表 执行如下命令进行更新： 12# sudo apt-get update# sudo apt-get upgrade 更新后的系统显示： 1Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 3.16.0-30-generic x86_64) 升级系统内核升级内核版本，执行如下命令： 1# sudo apt-get install linux-generic-lts-xenial linux-image-generic-lts-xenial 安装完成后重启： 1# sudo reboot 登陆后我们可以看到，内核已经更新了： 1Welcome to Ubuntu 14.04.5 LTS (GNU/Linux 4.4.0-38-generic x86_64) Ubuntu新增普通管理员账户并设置管理员权限在Linux系统下，$ 是普通管理员命令标识，# 是系统管理员命令标识 更改已有用户账户密码我们可以使用 passwd 命令来更改账户的命令，执行后输入两次新密码即可。例如为 root 账户修改密码： 1$ sudo passwd root 新增用户账户可以通过 adduser 命令来新增账户： 1$ sudo adduser username 同样的需要输入两次密码，其他的设置项直接按回车即可。 新创建的用户只有普通用户权限，如果想要安装软件或更新软件包，还需要赋予账户管理员权限才行。 使新增用户具有 root 权限–命令法(不推荐)在网上查看为新增用户账户可以通过如下的命令来添加管理员权限，但我在实际操作后并没有生效，所以这里暂不推荐该方法。 1sudo usermod -G root username 要添加新用户到 sudo，最简单的方式就是使用 usermod 命令。运行 : 1$sudo usermod -G root username 然而，如果用户已经是其他组的成员，你需要添加 -a 这个选项，象这样： 1$sudo usermod -a -G root username 这里暂作记录，待以后找到为何无效的原因再来修改。 使新增用户具有 root 权限–修改文件法(推荐)使用新创建的用户账户登陆。这里我新建的用户是 tiger 账户。执行更新命令： 123456789tiger@MyServer:~$ apt-get updateE: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)E: Unable to lock directory /var/lib/apt/lists/E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?tiger@MyServer:~$ sudo apt-get update[sudo] password for tiger: tiger is not in the sudoers file. This incident will be reported.tiger@MyServer:~$ 报错信息：tiger is not in the sudoers file. This incident will be reported. 表名我们新建的账户 tiger 在 sudoers 文件中并没有指定权限，所以也就无法以管理员权限执行命令。 执行下面的操作： 先切换回 root 账户下(注意 su - 后面的 - 和后面的账户名之间有一个空格)： 1tiger@MyServer:~$ su - root 为文件 /etc/sudoers 添加写权限，默认情况下该文件为只读属性。执行命令：# chmod u+w /etc/sudoers 。 然后编辑该文件，找到这一行 : 1root ALL=(ALL:ALL) ALL 在下面按照同样的格式添加: 1xxx ALL=(ALL:ALL) ALL (这里的xxx是你要设置的用户名)，然后保存退出。 撤销文件的写权限，执行命令：# chmod u-w /etc/sudoers 。 完整的命令如下： 1234567891011121314151617181920212223242526root@MyCloudServer:/home/tiger# chmod u+w /etc/sudoersroot@MyCloudServer:/home/tiger# vim /etc/sudoersroot@MyCloudServer:/home/tiger# ls -al /etc/sudoers -rw-r----- 1 root root 770 Sep 28 02:15 /etc/sudoersroot@MyCloudServer:/home/tiger# chmod u-w /etc/sudoersroot@MyCloudServer:/home/tiger# su - tigertiger@MyCloudServer:~$ apt-get updateE: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)E: Unable to lock directory /var/lib/apt/lists/E: Could not open lock file /var/lib/dpkg/lock - open (13: Permission denied)E: Unable to lock the administration directory (/var/lib/dpkg/), are you root?tiger@MyCloudServer:~$ sudo apt-get updateGet:1 http://security.ubuntu.com trusty-security InRelease [65.9 kB]Ign http://us.archive.ubuntu.com trusty InRelease Get:2 http://us.archive.ubuntu.com trusty-updates InRelease [65.9 kB]Get:3 http://security.ubuntu.com trusty-security/main Sources [120 kB] Get:4 http://us.archive.ubuntu.com trusty-backports InRelease [65.9 kB] Get:5 http://security.ubuntu.com trusty-security/restricted Sources [4,064 B] Hit http://us.archive.ubuntu.com trusty Release.gpg Get:6 http://security.ubuntu.com trusty-security/universe Sources [42.5 kB]Get:7 http://us.archive.ubuntu.com trusty-updates/main Sources [383 kB]Get:8 http://security.ubuntu.com trusty-security/multiverse Sources [2,749 B]...... 这样，我们就为新创建的账户 tiger 设置了管理员权限，执行命令时就可以通过 sudo 来提权了。 参考： xx is not in the sudoers file 问题解决【转载】 - evasnowind - 博客园 Ubuntu技巧之 is not in the sudoers file解决方法_Linux教程_Linux公社-Linux系统门户网站 Ubuntu sudo Error:unable to resolve host为新增用户设置了管理员权限后，每次执行 $ sudo xxxx 命令时都会弹出下面一条信息： 1Ubuntu sudo Error:unable to resolve host 这种情况是 系统的主机名和配置文件中的主机名不一致造成的。 编辑 /etc/hostname 更改主机名(hostname)主机名是在命令行中 tiger@MyServer:~$ @符合后面的。 编辑 /etc/hosts 文件中： 123127.0.0.1 localhost127.0.1.1 ubuntu 更改 ubuntu 为你的 hostname 的名称。 结果为： 1234567127.0.0.1 localhost127.0.1.1 myhostname# The following lines are desirable for IPv6 capable hosts::1 localhost ip6-localhost ip6-loopbackff02::1 ip6-allnodesff02::2 ip6-allrouters 然后重启系统。sudo reboot 。必需重启之后才有效。 ubuntu 下修复使用sudo命令后出现主机名字不能解析的错误：Fix Ubuntu sudo Error:unable to resolve host - wzb56的资料库 - 博客频道 - CSDN.NET Ubuntu 14.04 修改时区在系统下通过 date 命令查看时间，可能会与本地的之间不一致。 比如 我当前系统的时间为 2016-10-5 15:53:54 而 服务器的时间为 Wed Oct 5 03:58:37 EDT 2016 。按理说，Linux系统在重启后会自动同步时间的，而这种情况可能是时区不一致的原因。 执行下面命令，并按照提示选择 “Asia/Shanghai”： 1# sudo dpkg-reconfigure tzdata 选择完成后，会输出如下结果： 123Current default time zone: &apos;Asia/Shanghai&apos;Local time is now: Wed Oct 5 16:01:12 CST 2016.Universal Time is now: Wed Oct 5 08:01:12 UTC 2016. 再次查看时间： 12tiger@MyServer:~$ dateWed Oct 5 16:02:13 CST 2016 Ubuntu 14.04 修改时区 - MyPy的个人页面 - 开源中国社区 Linux 下切换用户su 和 su - 的区别 12su abcsu - abc 注意，su - 在 - 和账户名后面还有一个空格分隔。 （总结）Linux下su与su -命令的本质区别 linux - Why do we use su - and not just su? - Unix &amp; Linux Stack Exchange Ubuntu下SSH能连接而SFTP不能连接ssh能够连接而sftp不能连接的解决方法 用FileZilla一直不能登录远程的服务器，ssh的登录就OK 1# locate sftp-server locate一下ftp-server，发现目录跟配置文件中的不同 1# vi /etc/ssh/sshd_config 1234# Allow client to pass locale environment variablesAcceptEnv LANG LC_*#Subsystem sftp /usr/lib/openssh/sftp-server 上面的 locate 查看到的列表，我更改成了如下的设置： 1234# Allow client to pass locale environment variablesAcceptEnv LANG LC_*Subsystem sftp /usr/lib/sftp-server 即把它默认成第二个改成了列表中的第一项。 然后重启ssh服务： 1sudo service ssh restart 再次尝试，则能够正常连接了。]]></content>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker+Flask搭建微信公众平台之一]]></title>
    <url>%2F2016%2F09%2F24%2Fdocker-and-flask-build-wechat-public-platform-first%2F</url>
    <content type="text"><![CDATA[之前申请的个人公众号在申请通过后用.NET开发了一版比较简单的交互逻辑功能，最近在知乎中看到有关Python开发微信公众号的文章，正好前几天也在学习Docker技术，所以就想研究一下在Docker下如何用Flask配置微信公众平台的开发环境。 因为我的公众号是 个人号且是未认证 的，可获得的权限有限，所以目前我只做了消息的发送和接收相关的功能，更多功能后期再考虑加入。 下面测试Demo是申请的微信公众平台的测试号来开发的。 环境配置 主系统 为 Win10 宿主机 为 在 Win10 下的 Hyper-V 虚拟机中安装的 Ubuntu 14.04 LTS 系统 宿主机ip地址为 http://192.168.137.219/ 测试Docker容器 为在 宿主机 下安装的 Ubuntu 14.04 LTS 系统 使用的软件是 Sublime Text 和 Xshell 4 、FileZilla Python环境为 2.7.12 这里提一点，如果你不知如何配置Docker环境，或从未接触过Docker技术，在我之后的文章中我会有详细的介绍，欢迎关注。 安装流程配置 Flask 运行环境在 宿主机中，当前的账户为 tiger。在主目录下创建 xweixin 目录，添加的 Flask 程序为 app.py 文件。 启动一个前台运行的容器，将宿主机目录 xweixin 映射到容器的 weixin 目录： 1docker run -it --name weixin01 -p 80:80 -v /home/tiger/xweixin:/weixin ubuntu /bin/bash 查看容器中主目录下是否存在 weixin 目录，及该目录下是否存在 app.py 文件： 12$ ls ****** weixin 注意： 下面的操作主要在 测试Docker容器 中进行，因为在Docker中默认是 root 账户，所以下面的命令前面都没有加 sudo 。 设置安装源： 1$ echo &quot;deb http://archive.ubuntu.com/ubuntu/ precise universe&quot; &gt;&gt; /etc/apt/sources.list 更新，安装python ： 123$ apt-get update$ apt-get install python -y # 默认安装的是 2.7.12 安装 virtualenv : (由于是在容器内操作，只用来搭建Flask的运行环境，所以可以不安装虚拟环境) 1$ apt-get install python-virtualenv 安装 pip ： 1$ apt-get install python-pip -y 安装 flask: 1$ pip install Flask 安装 vim ：(主要用于查看) 1$ apt-get install vim 总结上面的操作：从 Win10 系统创建 flask 程序 app.py 后，通过 SFTP 传输到 宿主计算机的 /home/tiger/xweixin 目录下，该目录直接映射到了容器的 /weixin 目录。 app.py 内容 ： 123456789from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) 在容器中执行 python app.py 运行。 在 主系统Win10 下访问 宿主机 的ip地址 http://192.168.137.219/，看到输出 Hello World! 说明Flask配置成功。 使用 ngrok 实现外网访问ngrok.exe 程序可以从 ngrok - download 下载。 在 主系统Win10 下使用 CMD 命令运行 ngrok 工具，执行如下命令： 1&gt; ngrok http 192.168.137.219:80 后面的 ip地址不要带 http:// , 端口号不要丢。 可以看到 ngrok 生成了一个 外网可以访问到的地址 http://c62f4a09.ngrok.io/ ,在浏览器中打开，看到输出 Hello World! 说明可以实现外网访问了。 搭建微信公众平台处理逻辑准备工作由于 ngrok 每次重新启动就会重新分配一个新的域名地址，所以我们在启动ngrok之后，就不需要再去管它了。Flask中启用了 debug=True 的选项后，每次更新文件 app.py 都会自动重新加载(除非程序报错导致异常退出)，所以这样下来我们只需要负责修改 app.py 改完了上传到宿主机，直接刷新即可，不需要再进行重启ngrok，重新执行 python app.py启动程序等操作，非常方便。 修改 app.py 的框架，假设网站的二级目录 /weixin 来实现我们的微信公众平台的接口操作。 123456789101112131415161718# coding:utf-8&quot;&quot;&quot;微信公众平台&quot;&quot;&quot;from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;# 微信公众平台接口@app.route(&apos;/weixin&apos;)def weixin_interface(): return &quot;这是微信接口&quot;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) 通过 ngrok 分配的域名为 http://d0dd1f96.ngrok.io/weixin ,该域名用于之后填入 微信公众平台 的接口配置的URL处(此时如果尝试添加，在微信公众平台页面一直会报配置错误的问题，因为在点击确定后微信会向我们的服务器发送验证消息，只有验证通过后才能保存)。 处理逻辑在 Flask 中通过不同的 method 处理微信的验证请求和交互请求12345678# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 else: # 处理逻辑交互 设置微信验证请求 - 验证消息的确来自微信服务器修改 weixin_interface 代码如下: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546....省略....from flask import Flaskfrom flask import requestimport hashlibimport time# 配置参数X_TOKEN=&apos;leafney&apos; #这里改写你在微信公众平台里输入的token....省略....# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 # 接收参数 wx_signature=request.args.get(&apos;signature&apos;) wx_timestamp=request.args.get(&apos;timestamp&apos;) wx_nonce=request.args.get(&apos;nonce&apos;) wx_echostr=request.args.get(&apos;echostr&apos;) # 自己的token wx_token=X_TOKEN # 字典序排序 w_list=[wx_token,wx_timestamp,wx_nonce] w_list.sort() # sha1加密算法 w_sha1=hashlib.sha1() map(w_sha1.update,w_list) w_hashcode=w_sha1.hexdigest() # 如果是来自微信的请求，则返回echostr if w_hashcode == wx_signature: return wx_echostr else: # 处理逻辑交互 pass 因为我用的是微信的测试号来进行配置，将程序上传并启动之后，在 “测试号配置” 页面中的 “接口配置信息” 处 填入 URL 和 Token 然后点击 “确定” 。 如果程序接入成功，会提示 “配置成功” ，否则可以在之前配置的 测试Docker容器 下查看调试信息，来进行相应的修改。 实现业务逻辑​当普通微信用户向公众账号发消息时，微信服务器将POST消息的XML数据包到开发者填写的URL上。 接收消息内容，在 Flask 中可以使用 request.data 来获取： 1xml_data=request.data 根据微信公众平台开发文档的说明 接收普通消息 - 微信公众平台开发者文档 我们可以通过 MsgType 参数来区分接收的消息的类型， 例如文本消息的数据包如下： 12345678&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;1348831860&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[this is a test]]&gt;&lt;/Content&gt;&lt;MsgId&gt;1234567890123456&lt;/MsgId&gt;&lt;/xml&gt; ToUserName 表示消息的接收者 FromUserName 表示消息的发送者 CreateTime 表示消息创建的时间戳 MsgType 表示消息的类型 Content 表示消息的内容 MsgId 表示消息的id，可以用来对消息排重 我们可以使用 lxml 来解析xml文档，获取相应的参数值。 添加引用： 12import lxmlfrom lxml import etree 解析得到所需的参数： 1234567wx_xml=etree.fromstring(xml_data) # 进行xml解析print(etree.tostring(wx_xml,pretty_print=True)) # 获取请求内容# 获取请求参数wx_msgType=wx_xml.find(&apos;MsgType&apos;).textwx_fromUser=wx_xml.find(&apos;FromUserName&apos;).text # 微信公众号wx_toUser=wx_xml.find(&apos;ToUserName&apos;).text # 用户 在向微信服务器回复消息时，也要按照微信的规定来返回特定XML结构的数据，详细可见 被动回复用户消息 - 微信公众平台开发者文档 ，比如回复文本消息格式如下： 1234567&lt;xml&gt;&lt;ToUserName&gt;&lt;![CDATA[toUser]]&gt;&lt;/ToUserName&gt;&lt;FromUserName&gt;&lt;![CDATA[fromUser]]&gt;&lt;/FromUserName&gt;&lt;CreateTime&gt;12345678&lt;/CreateTime&gt;&lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt;&lt;Content&gt;&lt;![CDATA[你好]]&gt;&lt;/Content&gt;&lt;/xml&gt; 在向微信端回复消息时，ToUserName 和 FromUserName 我们可以从接收时的消息内容中来得到，只需要把接收者和发送者的角色互换一下即可，Content 为我们要回复的内容。 详细的处理代码如下： 123456789101112131415161718192021# 根据请求类型来返回不同的处理结果if wx_msgType == &apos;text&apos;: # 文本消息 # 获取文本消息内容 wx_content=wx_xml.find(&apos;Content&apos;).text content=wx_content.encode(&apos;utf-8&apos;) print(content) if content == &apos;天气&apos;: # return &apos;北京天气挺好的！&apos; # 注意回复消息时，接收者和发送者的位置要互换一下 return TextReply(wx_fromUser,wx_toUser,u&apos;北京天气挺好的！&apos;).render() else: return TextReply(wx_fromUser,wx_toUser,wx_content).render()elif wx_msgType == &apos;image&apos;: return &apos;success&apos;else: return &apos;success&apos; 消息模板： 123456789101112131415161718192021class TextReply(object): &quot;&quot;&quot;回复文本消息&quot;&quot;&quot; TEMPLATE=u&quot;&quot;&quot; &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[&#123;target&#125;]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[&#123;source&#125;]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;&#123;time&#125;&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[&#123;content&#125;]]&gt;&lt;/Content&gt; &lt;/xml&gt; &quot;&quot;&quot; def __init__(self, target,source,content): self.target=target self.source=source self.content=content self.time=int(time.time()) def render(self): return TextReply.TEMPLATE.format(target=self.target,source=self.source,time=self.time,content=self.content) 至此，接收回复文本消息的功能我们就做好了，上传到 宿主机 的 xweixin 目录下即可。 在运行代码之前，先要安装依赖包 lxml ,不然会报 No module named lxml 的错误。 安装 lxml先安装 lxml 的依赖包： 1$ apt-get install python-dev libxml2-dev libxslt1-dev zlib1g-dev 再安装 lxml : 1$ pip install lxml 完整的代码实现app.py (主程序) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788# coding:utf-8&quot;&quot;&quot;微信公众平台&quot;&quot;&quot;from flask import Flaskfrom flask import requestimport hashlibimport lxmlfrom lxml import etreeimport time # 消息返回模板from reply import TextReply# 配置参数X_TOKEN=&apos;leafney&apos; #这里改写你在微信公众平台里输入的tokenapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;# 微信公众平台接口@app.route(&apos;/weixin&apos;,methods=[&apos;GET&apos;,&apos;POST&apos;])def weixin_interface(): # return &quot;这是微信接口&quot; if request.method==&apos;GET&apos;: # 处理验证 # 接收参数 wx_signature=request.args.get(&apos;signature&apos;) wx_timestamp=request.args.get(&apos;timestamp&apos;) wx_nonce=request.args.get(&apos;nonce&apos;) wx_echostr=request.args.get(&apos;echostr&apos;) # 自己的token wx_token=X_TOKEN # 字典序排序 w_list=[wx_token,wx_timestamp,wx_nonce] w_list.sort() # sha1加密算法 w_sha1=hashlib.sha1() map(w_sha1.update,w_list) w_hashcode=w_sha1.hexdigest() # 如果是来自微信的请求，则返回echostr if w_hashcode == wx_signature: return wx_echostr else: # 处理逻辑交互 xml_data=request.data # 获得post来的数据 wx_xml=etree.fromstring(xml_data) # 进行xml解析 # print(etree.tostring(wx_xml,pretty_print=True)) # 获取请求内容 # 获取请求参数 wx_msgType=wx_xml.find(&apos;MsgType&apos;).text wx_fromUser=wx_xml.find(&apos;FromUserName&apos;).text # 微信公众号 wx_toUser=wx_xml.find(&apos;ToUserName&apos;).text # 用户 # 根据请求类型来返回不同的处理结果 if wx_msgType == &apos;text&apos;: # 文本消息 # 获取文本消息内容 wx_content=wx_xml.find(&apos;Content&apos;).text content=wx_content.encode(&apos;utf-8&apos;) print(content) if content == &apos;天气&apos;: # return &apos;北京天气挺好的！&apos; # 注意回复消息时，接收者和发送者的位置要互换一下 return TextReply(wx_fromUser,wx_toUser,u&apos;北京天气挺好的！&apos;).render() else: return TextReply(wx_fromUser,wx_toUser,wx_content).render() elif wx_msgType == &apos;image&apos;: return &apos;success&apos; else: return &apos;success&apos;if __name__ == &apos;__main__&apos;: app.run(host=&apos;0.0.0.0&apos;,port=80,debug=True) reply.py (消息模板) 123456789101112131415161718192021222324252627# coding:utf-8&quot;&quot;&quot;微信公众平台 消息回复模板&quot;&quot;&quot;import timeclass TextReply(object): &quot;&quot;&quot;回复文本消息&quot;&quot;&quot; TEMPLATE=u&quot;&quot;&quot; &lt;xml&gt; &lt;ToUserName&gt;&lt;![CDATA[&#123;target&#125;]]&gt;&lt;/ToUserName&gt; &lt;FromUserName&gt;&lt;![CDATA[&#123;source&#125;]]&gt;&lt;/FromUserName&gt; &lt;CreateTime&gt;&#123;time&#125;&lt;/CreateTime&gt; &lt;MsgType&gt;&lt;![CDATA[text]]&gt;&lt;/MsgType&gt; &lt;Content&gt;&lt;![CDATA[&#123;content&#125;]]&gt;&lt;/Content&gt; &lt;/xml&gt; &quot;&quot;&quot; def __init__(self, target,source,content): self.target=target self.source=source self.content=content self.time=int(time.time()) def render(self): return TextReply.TEMPLATE.format(target=self.target,source=self.source,time=self.time,content=self.content) 未完待续至此，上面我们就实现了最基本的微信公众号的验证和简单文本消息的接收和回复功能。 之后我会介绍如何来处理复杂的消息内容，图片、语音、图文等等。然后通过一些有趣的小功能来让我们这即使没有特殊权限的公众号也能玩得更有意思，欢迎关注！ PublishTime: 2016-9-24 22:35:16]]></content>
      <categories>
        <category>微信公众平台</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Docker</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSH密钥连接Github]]></title>
    <url>%2F2016%2F09%2F24%2Fusing-ssh-key-connection-github%2F</url>
    <content type="text"><![CDATA[每次向GitHub签入代码时，都要输入用户名和密码，让人感觉非常麻烦。如果使用SSH，通过密钥的方式来连接GitHub，每次提交代码就可以享受不用输入密码的快感了！ 下面我主要介绍在Windows下如何通过 SSH密钥 来连接GitHub。 引申 Linux下：Linux下使用SSH密钥连接Github Windows下：使用SSH密钥连接Github 第一步 查看是否已经存在SSH秘钥(keys)右键打开 Git Bash ,并运行： 1$ cd ~/.ssh 如果提示如下信息为 No such file or directory，则说明不存在SSH秘钥，如果已经存在，可以直接进入第三步。 12$ cd ~/.sshsh.exe&quot;: cd: /c/Users/Xue/.ssh: No such file or directory 如果无提示信息，进入 .ssh 目录执行 ls 命令，可查看本机已经存在的SSH的公钥和私钥。 第二步 创建新的SSH密钥(keys)输入如下命令： 12$ cd ~ # 保证当前路径在 `~` 下，即 `C:/Users/用户名` 目录$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot; # 这将根据你提供的邮箱地址，创建一对密钥 提示信息如下： 12345678910111213141516171819202122$ ssh-keygen -t rsa -C &quot;your_email@example.com&quot;Generating public/private rsa key pair.Enter file in which to save the key (/c/Users/用户名/.ssh/id_rsa): # 直接回车，则将密钥按默认路径及文件名进行存储。此时也可以输入特定的文件名Created directory &apos;/c/Users/用户名/.ssh&apos;.Enter passphrase (empty for no passphrase): # 根据提示，你需要输入密码和确认密码。可以不填，设置为空值，直接回车Enter same passphrase again:Your identification has been saved in /c/Users/用户名/.ssh/id_rsa.Your public key has been saved in /c/Users/用户名/.ssh/id_rsa.pub.The key fingerprint is:6d:40:da:xx:xx:xx:xx:b8:60:4a:bd:61:5f:c5:d6:db your_email@example.comThe key&apos;s randomart image is:+--[ RSA 2048]----+| . .=oo. || . * .=.*o . || . + =oo+.. o || . ..o. o . E || . S o || . || || || |+-----------------+ 然后在目录 ~/.ssh 下，就新创建了两个文件： 123$ cd ~/.ssh$ lsid_rsa id_rsa.pub 第三步 在GitHub账户中添加你的公钥执行如下命令，将公钥的内容复制到系统剪切板中(或直接打开该文件进行复制操作)： 1clip &lt; ~/.ssh/id_rsa.pub 登陆Github网站，选择 Settings –&gt; SSH and GPG keys 菜单，点击 New SSH key 按钮。粘贴你的密钥到 Key 输入框中并设置 Title 信息，点击 Add SSH key 按钮完成。 至此，添加完毕。 第四步 连接测试先保证本地 Git 已设置好git账户的 用户名 和 邮箱 信息： 12$ git config --global user.name &quot;your_username&quot; # 设置用户名$ git config --global user.email &quot;your_email@example.com&quot; # 设置邮箱地址 测试SSH keys 是否设置成功，执行如下命令： 1$ ssh -T git@github.com 提示信息如下： 12345678$ ssh -T git@github.comThe authenticity of host &apos;github.com (192.30.253.113)&apos; can&apos;t be established.RSA key fingerprint is 16:27:xx:xx:xx:xx:xx:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yes # 确认你是否继续连接，输入yesWarning: Permanently added &apos;github.com,192.30.253.113&apos; (RSA) to the list of known hosts.Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. # 出现这句话，说明设置成功 当提示如下信息，说明连通Github成功： 12Hi xxx! You&apos;ve successfully authenticated, but GitHub does not provide shell access. 第五步 将本地项目通过 SSH push 到 GitHub在github新建一个仓库，如 test_ssh 。 执行以下命令： 123456789101112131415## 创建目录$ mkdir test$ cd test## 初始化git仓库$ git init## 创建readme.md文件$ echo &quot;this is a test ssh keys&quot; &gt; README.md## 提交到本地## 提交当前目录下的所有文件$ git add .## 提交记录说明$ git commit -m &quot;add readme.md&quot;## 提交到github$ git remote add origin git@github.com:your_github_name/test_ssh.git$ git push -u origin master 刷新 test_ssh 仓库，就能看到提交的文件了。 如果是本地已经存在的git项目，只需要执行以下命令即可： 123## 提交到github$ git remote add origin git@github.com:your_github_name/test_ssh.git$ git push -u origin master 相关参考文章 使用SSH密钥连接Github【图文教程】 - 轩枫阁 – 前端开发 | web前端技术博客]]></content>
      <tags>
        <tag>GitHub</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用GitHub搭建Hexo静态博客]]></title>
    <url>%2F2016%2F09%2F24%2Fuse-github-to-build-hexo-static-blog%2F</url>
    <content type="text"><![CDATA[说明之前一直在用自己创建的.Net网站来写博客文章，只有简单的CRUD的功能，数据也是从数据库中直接查询的。自从接触了markdown之后，渐渐习惯了用markdown来记录自己在开发过程中遇到的问题和学到的新知识。但由于之前博客中是通过百度的 ueditor 编辑器来编辑文章，不能直接处理markdown，所以后来就一直考虑有没有其他的方法来更方便的管理和发布博客。 自从发现了 Hexo，不得不说这不就是我一直想要找的博客工具吗？ 静态博客的特点如下： 不用数据库 访问速度快 支持markdown，更加注重博客内容 而且部署到 GitHub 上，我们还不需要去配置服务器，非常的方便。 下面详细记录我这个博客的搭建部署流程，希望能帮到有需要的朋友们！ 搭建流程开始前保证已安装： Node.js Linux 下执行如下命令来安装： $ curl https://raw.github.com/creationix/nvm/master/install.sh | sh $ nvm install stable Windows 下可以从 Node.js Download 处选择 Windows Installer 下载msi安装包 Git Linux(Ubuntu) 下执行如下命令来安装： $ sudo apt-get install git-core Windows 下可以从 Git Download 处下载 Git for Windows 安装包 安装Hexo选择一个用来创建博客的目录，在该目录下使用 CMD 命令行窗口，这里推荐使用 Cmder 来代替Windows上默认的命令行。 通过 npm 命令执行： 1&gt; npm install -g hexo-cli 建站执行如下命令，Hexo 将会在指定文件夹中新建所需要的文件 123&gt; hexo init &lt;folder&gt;&gt; cd &lt;folder&gt;&gt; npm install 这里假设我要创建的博客所在目录名为 xblog ,则命令为： 123&gt; hexo init xblog&gt; cd xblog&gt; npm install 生成静态页1&gt; hexo g 该命令的完整格式为: hexo generate 启动服务1&gt; hexo s 该命令的完整格式为： hexo server hexo默认使用 4000 端口进行预览，可以通过浏览器打开 http://localhost:4000/ 查看。如果端口被占用，可以用 hexo s -p 5000 指定端口号为 5000 或者其他未被占用的端口。使用 Ctrl+C 来停止预览。 查看Hexo版本可以通过命令 hexo -v 查看当前hexo的版本信息： 12345678910111213&gt; hexo -vhexo: 3.2.2hexo-cli: 1.0.2os: Windows_NT 10.0.10586 win32 x64http_parser: 2.5.2node: 4.4.0v8: 4.5.103.35uv: 1.8.0zlib: 1.2.8ares: 1.10.1-DEVicu: 56.1modules: 46openssl: 1.0.2g Hexo配置更换主题 theme以主题 NexT 为例，首先下载该主题： 12&gt; cd your-hexo-site (我这里是 `cd xblog`)&gt; git clone https://github.com/iissnan/hexo-theme-next themes/next 在站点站点根目录下打开 _config.yml，找到 theme 字段，将 theme: landscape 改为 theme: next ，然后再次执行 hexo g 来重新生成。 主题设置关于主题的配置可直接参考NexT官网的配置流程 开始使用-NexT ，这里我会把自己在配置时的操作简单记录，仅供大家参考。 在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。 为了描述方便，在以下说明中，将前者称为 站点配置文件， 后者称为 主题配置文件。 选择Scheme借助于 Scheme，NexT 提供了多种不同的外观。目前 NexT 支持三种 Scheme ： Muse - 默认 Scheme，这是 NexT 最初的版本，黑白主调，大量留白 Mist - Muse 的紧凑版本，整洁有序的单栏外观 Pisces - 双栏 Scheme，小家碧玉似的清新 Scheme 的切换通过更改 主题配置文件 ，搜索 scheme 关键字。 你会看到有三行 scheme 的配置，将你需要启用的 scheme 前面注释 # 去掉即可。 123#scheme: Muse#scheme: Mistscheme: Pisces 设置 语言编辑 站点配置文件， 将 language 设置成你所需要的语言。这里我选择了简体中文，配置如下： 1language: zh-Hans 设置 菜单菜单即是你的导航菜单，我们可以设置菜单项的 显示名称和 链接 以及 菜单项对应的图标 。 我们可以在 主题配置文件 中来修改，对应的字段是 menu 。我的配置如下： 123456menu: home: / # 主页 categories: /categories # 分类页 tags: /tags # 标签页 archives: /archives # 归档页 about: /about # 关于页面 菜单项的显示文本放置在 NexT 主题目录下的 languages/{language}.yml （{language} 为你所使用的语言）。 菜单项的图标，对应的字段是 menu_icons。我们可以通过 enable 来控制是否显示图标。 我们也可以添加自己的链接，只要把上面的 名称-链接-图标 三者对应好即可。 请注意键值（如 home）的大小写要严格匹配 设置 头像编辑 站点配置文件， 新增字段 avatar， 值设置成头像的链接地址。 我们可以将自己的头像图片文件上传到主题目录下的 source/uploads/ 目录下(新建uploads目录若不存在) 或 source/images/ 目录下。完整的目录就是 your-hexo-site\themes\next\source\images\ 下。 然后将 avatar 字段配置如下： 12# avatar 个人头像avatar: /images/avatar.jpg 或者也可以使用网络上的头像来进行设置： 1avatar: http://example.com/avatar.png 设置 作者昵称及站点描述编辑 站点配置文件， 设置 author 为你的昵称。 编辑 站点配置文件， 设置 description 字段为你的站点描述。 设置代码高亮主题NexT共提供了5款主题可以选择，默认使用白色的 normal 主题。 normal，night， night blue， night bright， night eighties 在 主题配置文件 中找到 highlight_theme 字段，更改即可。 1highlight_theme: night eighties 开启打赏功能NexT可以支持微信打赏和支付宝打赏，在 主题配置文件 中添加如下字段即可： 1234# 打赏功能reward_comment: 坚持原创技术分享，您的支持将鼓励我继续创作！wechatpay: /images/wechat-reward-image.jpgalipay: /images/alipay-reward-image.jpg 微信个人收款二维码可以从微信APP右上角“+”处，选择 收付款 – 我要收款 – 长按二维码 来获取。支付宝个人收款二维码可以从支付宝APP的右上角“+”处，选择 我的二维码/收款 来获取。 二维码图片可以和头像一样保存在 source/images/ 目录下。 主题栏目设置在上面设置导航菜单时我们已经添加了导航菜单: categories 和 tags ，但在预览时会直接报错，因为我们还没有创建这两个分类页面。 添加「标签」页面「标签」页面将展示站点的所有标签，若你的所有文章都未包含标签，此页面将是空的。 这里先详细介绍两个命令： 123&gt; hexo n about&gt; hexo n page about hexo n 的完整格式为 hexo new ，所以上面的命令也可以写成： 123&gt; hexo new about&gt; hexo new page about 两者的区别是： hexo new xxxx 表示创建一个新的文章页面。在Hexo中, 你写的博客文章会默认存储在 your-hexo-site/source/_posts 下。比如上面的命令 hexo new about 我们就在 your-hexo-site\source\_posts 目录下新建了一个 about.md 的文件。 hexo new page xxxx 表示创建一个新的分类主页面。比如上面的命令 hexo new page about 我们就在 your-hexo-site\source\ 目录下创建了一个名为 about 的目录，该目录下有一个名为 index.md 的文件。 在命令行窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个分类主页面，命名为 tags ： 12&gt; cd your-hexo-site&gt; hexo new page tags 然后打开 your-hexo-site\source\tags 目录下的 index.md 文件，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。 12345---title: 标签date: 2016-09-24 01:05:02type: &quot;tags&quot;--- 注意：如果有启用 多说 或者 Disqus 评论，页面也会带有评论。 若需要关闭的话，请添加字段 comments 并将值设置为 false ，如： 123456---title: 标签date: 2016-09-24 01:05:02type: &quot;tags&quot;comments: false--- 那么我们在新创建的文章页面中要如何来显示标签呢？ 我们可以在文章页面中通过添加 tags 标记来设置文章要显示的标签。 Hexo 中有 Front-matter 这个概念，是文件最上方以 --- 分隔的区域，用于指定个别文件的变量。 Front-matter 支持 “数组” 方式或 “yaml” 方式来设置，如下： 123title: hexo indexdate: 2016-09-24 01:05:02tags: [github,html5,css3] 123456title: hexo indexdate: 2016-09-24 01:05:02tags: - github- html5- css3 添加「分类」页面「分类」页面将展示站点的所有分类，若你的所有文章都未包含分类，此页面将是空的。 和上面配置 tags 的方法一样，我们可以通过命令 hexo new page xxxx 来创建： 12&gt; cd your-hexo-site&gt; hexo new page categories 这里需要注意的一点是，我们命令中的名称 tags 和 categories 是在之前配置导航菜单时在 menu 字段下指定的名称，大小写不能错。 相应的页面类型设置如下： 123456---title: 分类date: 2016-09-24 01:08:49type: &quot;categories&quot;comments: false--- 同样的，在文章页面中，我们可以通过 categories 字段来为文章指定所属的分类： 1234---title: 分类测试文章categories: Testing--- 关于 Hexo 下的文章页面上面已经提到过，我们可以通过 hexo n xxxx 或 hexo new xxxx 来创建新的文章页面，默认会保存在 your-hexo-site\source\_posts 目录下。 一般的文章页面头部的 Front-matter 格式如下： 12345678910111213---title: hexo next # 文章标题date: 2016-09-24 01:08:49 # 文章发布日期tags: [github,html5]tags: - github - html5 # tags 文章的标签，可以通过数组方式或yaml方式指定categories: 前端 # 文章所属分类description: 这里是文章描述，大概140个字左右 # 文章描述---下面是文章正文 ... 需要注意的是 冒号后面与内容直接要有一个空格，否则无法编译生成 正文与 Front-matter 之间要有一个空行 为文章添加描述文字除了指定 description 之外，还可以在正文中通过添加 &lt;!--more--&gt; 标签分隔内容 常见问题 修改配置文件时注意YAML语法，参数冒号:后一定要留一空格 中文乱码请修改文件编码格式为UTF-8 yml文件中所有有空格的字段都用双引号括起来 默认情况下，新建文章的文件名和标题名是相同的，需要注意的是如果文件名是中文，那么生成的链接后面会自动添加末尾斜杠 http://localhost:4000/2016/09/xxxxxxx/ 如果手动去掉该斜杠 / 会直接报错。所以推荐文件名最好用 英文 来写，文章内的标题可以改成中文。 另外，文章文件名中文末尾斜杠 的问题也可以通过配置 Nginx 来解决。(这里暂不讨论该方法) Hexo 中常用命令123456hexo generate (hexo g) # 生成静态文件，会在当前目录下生成一个新的叫做public的文件夹hexo server (hexo s) # 启动本地web服务，用于博客的预览hexo deploy (hexo d) # 部署播客到远端（比如github, heroku等平台）hexo new &quot;postName&quot; # 新建文章hexo new page &quot;pageName&quot; # 新建页面hexo clean # 清理public文件夹 简写形式： 123456hexo n == hexo newhexo g == hexo generatehexo s == hexo serverhexo d == hexo deployhexo d -g # 生成部署hexo s -g # 生成预览 将 Hexo 部署到 Github到 GitHub 新建一个项目，项目名为：你的用户名.github.io 必须为这个名字 Hexo 目前没有自带 Git 部署模块，需手动安装: 1&gt; npm install hexo-deployer-git --save 然后，在 站点配置文件 _config.yml 中设置 deploy 字段： 1234deploy: type: git repository: git@github.com:你的帐号/你的帐号.github.io.git #例如我的：repository: git@github.com:Leafney/Leafney.github.io.git branch: master 注意：这个respository的地址你在GitHub创建同名仓库后，会在页面中给出，直接复制即可。另外，branch 要设置为 master 分支。 在此之前，还要注意你本地的 Git 已经通过 SSH 和你的 GitHub 连接起来了。 如何通过SSH连接GitHub可以查看我的另一篇文章 使用SSH密钥连接Github 来进行设置。 然后执行命令： 123456&gt; hexo clean # 先清理public文件夹&gt; hexo g # 生成&gt; hexo d # 部署# 或通过下面一条命令直接生成并部署&gt; hexo g -d 执行完成之后会在你的博客根目录下生成一个文件夹：.deploy_git， 该目录下的文件会自动被发布到你的 GitHub 上，页面文件在 master 分支下。 然后打开浏览器，输入你的 GitHub pages 的地址 xxxxx.github.io 即可。 PublishTime: 2016-9-24 14:06:00]]></content>
      <categories>
        <category>Hexo博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F09%2F24%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Hello Firends! 现在是北京时间 2016-9-24 1:45:58 ,酝酿了很久的个人博客Hexo版终于要发布上线了！此处应该有掌声！！！ 之前写博客一直用的自己搭建的.net版的网站，只有简单的CRUD的功能，当时只是考虑用来作为自己的一个可以记事的地方，记下自己在开发过程中遇到的问题，学到的新知识等等，并没有考虑要去写一些技术类的文章，去分享。毕竟自己的能力还是有限的。 随着接触越来越多的开源项目，逐渐意识到“分享”确实是一个很有意义的事情。所以决定把自己平时学到的知识、技巧等记录于此，以便能帮助到遇到相关问题的开发朋友们。 博客中的文章会涉及.Net 、Python 、Golang、Linux、前端等相关方面，基本属于全栈，也会涉及到一些前沿的技术。 希望大家多多支持！]]></content>
  </entry>
  <entry>
    <title><![CDATA[Nginx初级入门]]></title>
    <url>%2F2016%2F07%2F03%2Fnginx-introduction%2F</url>
    <content type="text"><![CDATA[安装 1$ sudo apt-get install nginx 在Ubuntu下安装后的文件结构： 所有的配置文件都在 /etc/nginx/ 下 nginx.conf 为主配置文件 sites-available/default 为默认配置文件 程序文件在 /usr/sbin/nginx 下 日志放在了 /var/log/nginx 下 启动脚本 /etc/init.d/nginx 默认的虚拟主机的目录设置在了 /var/www/ 下（参考默认配置文件） 在 nginx.conf 配置文件中，可看到下面两行： 12include /etc/nginx/conf.d/*.conf;include /etc/nginx/sites-enabled/*; 网上找到的自定义配置文件的设置方法为： 我们可以在 /etc/nginx/sites-available 目录下添加自定义配置文件，然后为该文件创建软链接到 /etc/nginx/sites-enabled 目录中。 也可以在 /etc/nginx/conf.d 目录下创建自定义配置文件并以 .conf 为扩展名。 nginx 的启动 暂停 重启 启动 sudo /etc/init.d/nginx start 暂停 sudo /etc/init.d/nginx stop 重启 sudo /etc/init.d/nginx restart nginx 基本的配置文件写法： 123456789101112sever &#123; listen 8080; server_name _; root /home/tiger/myweb/site; index index.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125; 示例文件 web.conf ,所在目录为 /etc/nginx/conf.d : 12345678910111213141516171819202122232425sever &#123; listen 8081; server_name _; root /home/tiger/myweb/site2; index index.html aaa.html; location / &#123; try_files $uri $uri/ =404; &#125;&#125;server &#123; listen 8082; server_name _; # 访问 localhost error_page 404 /404.html; # 指定404错误页 root /home/tiger/myweb/site2/aaa; index abc.html; location / &#123; allow all; &#125;&#125; 查看目录下文件： 1234$ ls /home/tiger/myweb/site2aaa aaa.html$ ls /home/tiger/myweb/site2/aaa404.html abc.html]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Scrapy爬虫初探]]></title>
    <url>%2F2016%2F06%2F27%2Fscrapy-introduction%2F</url>
    <content type="text"><![CDATA[Scrapy 是一个快速的高层次的屏幕抓取和网页爬虫框架，爬取网站，从网站页面得到结构化的数据，它有着广泛的用途，从数据挖掘到监测和自动测试，Scrapy完全用Python实现，完全开源，代码托管在Github上，可运行在Linux，Windows，Mac和BSD平台上，基于Twisted的异步网络库来处理网络通讯，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片。 安装Scrapy1$ sudo pip install Scrapy scrapy依赖 lxml ,请保证已经安装了 lxml 库。 创建初始化项目框架 这里以抓取 http://www.cnbeta.com/topics/9.htm 页面中的文章标题和简介为例，创建项目名称为 cnbetaSpider 。 1$ scrapy startproject cnbetaSpider 该命令将会创建包含下列内容的 cnbetaSpider 目录: 12345678910cnbetaSpider/ scrapy.cfg cnbetaSpider/ __init__.py items.py pipelines.py settings.py spiders/ __init__.py ... 这些文件分别是: scrapy.cfg : 项目的配置文件 cnbetaSpider/ : 该项目的python模块。之后您将在此加入代码。 cnbetaSpider/items.py : 项目中的item文件. cnbetaSpider/pipelines.py : 项目中的pipelines文件. cnbetaSpider/settings.py : 项目的设置文件. cnbetaSpider/spiders/ : 放置spider代码的目录. 定义ItemItem 是保存爬取到的数据的容器。我们需要从网页中提取 文章的标题，链接，描述，对此，在 item 中定义相应的字段。编辑 cnbetaSpider 目录中的 items.py 文件: 123456789import scrapyclass CnbetaspiderItem(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title=scrapy.Field() link=scrapy.Field() desc=scrapy.Field() pass 创建SpiderSpider 是用户编写用于从单个网站(或者一些网站)爬取数据的类。其包含了一个用于下载的初始URL，如何跟进网页中的链接以及如何分析页面中的内容， 提取生成 item 的方法。 为了创建一个 Spider ，您必须继承 scrapy.Spider 类， 且定义以下三个属性: name 指定Spider的名称，唯一 start_urls 包含了Spider在启动时进行爬取的url列表 parse() 接收完成下载后生成的 Response 对象，该方法负责解析返回的数据，提取数据(生成item)以及生成需要进一步处理的URL的 Request 对象。 在目录 cnbetaSpider/spiders 下创建文件 cnbetaspider.py: 12345678910111213141516# coding:utf-8import scrapyclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): filename=response.url.split(&quot;/&quot;)[-2] with open(filename,&apos;wb&apos;) as f: f.write(response.body) 爬取进入项目根目录，执行下列命令启动spider: 1234$ lscnbetaSpider scrapy.cfg# 执行命令$ scrapy crawl cnbeta 第三个参数为 cnbetaspider.py 中的 name 属性值。 执行完成后可在当前目录下看到生成的文件 topics,里面保存的获取到的网页的内容。 提取Scrapy使用了一种基于 XPath 和 CSS 表达式机制: Scrapy Selectors 。详见：选择器(Selectors) &mdash; Scrapy 0.24.1 文档 选择器方法( .xpath() or .css() ) 为了提取真实的原文数据，你需要调用 .extract() 方法： 12&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract()[u&apos;Example website&apos;] 这里给出XPath表达式的例子及对应的含义: /html/head/title : 选择HTML文档中 &lt;head&gt; 标签内的 &lt;title&gt; 元素 /html/head/title/text() : 选择上面提到的 &lt;title&gt; 元素的文字 //td : 选择所有的 &lt;td&gt; 元素 //div[@class=&quot;mine&quot;] : 选择所有具有 class=&quot;mine&quot; 属性的 div 元素 Selector有四个基本的方法: xpath() : 传入xpath表达式，返回该表达式所对应的所有节点的selector list列表 。 css() : 传入CSS表达式，返回该表达式所对应的所有节点的selector list列表. extract() : 序列化该节点为unicode字符串并返回list。 re() : 根据传入的正则表达式对数据进行提取，返回unicode字符串list列表。 分析网页 http://www.cnbeta.com/topics/9.htm 中的文章： 文章列表在 item 元素： 1//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;] 标题： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() 链接： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() 描述： 1xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]/*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() 修改我们之前定义的 cnbetaspider.py 中的 parse() 方法如下： 12345678910111213141516import scrapyclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): for sel in response.xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]&apos;): title=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() link=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() desc=sel.xpath(&apos;*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() print(title,link,desc) 再次执行，能看到爬取到的网站信息被成功输出: 1$ scapy crawl cnbeta 结果将之前设置的 Item 对象引入，使用标准的字典语法来保持获取到的每个字段的值。最终的代码为： 123456789101112131415161718192021222324# coding:utf-8import scrapyfrom cnbetaSpider.items import CnbetaspiderItemclass cnbetaSpider(scrapy.Spider): &quot;&quot;&quot;docstring for cnbetaSpider&quot;&quot;&quot; name=&quot;cnbeta&quot; allowed_domains=[&quot;cnbeta.com&quot;] start_urls=[ &quot;http://www.cnbeta.com/topics/9.htm&quot; ] def parse(self,response): items=[] for sel in response.xpath(&apos;//*[@class=&quot;all_news_wildlist&quot;]/div[@class=&quot;items&quot;]/div[@class=&quot;item&quot;]&apos;): item=CnbetaspiderItem() item[&apos;title&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/text()&apos;).extract() item[&apos;link&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/div[@class=&quot;title&quot;]/a/@href&apos;).extract() item[&apos;desc&apos;]=sel.xpath(&apos;*[@class=&quot;hd&quot;]/*[@class=&quot;newsinfo&quot;]/p/text()&apos;).extract() # yield item items.append(item) return items 如果想把得到的结果保存在临时文件中，可以： 1$ scrapy crawl cnbeta &gt; abc.html 这样就把结果保存在当前目录下的 abc.html 中了。 Scrapy爬虫运行时报错 “Forbidden by robots.txt”解决该问题只需要将 settings.py 文件中的 ROBOTSTXT_OBEY 值改为 False 即可。 1ROBOTSTXT_OBEY = False 相关链接 Scrapy 0.25 文档 &mdash; Scrapy 0.24.1 文档 Scrapy 1.0 文档(未完成,只更新了intro部分,请谨慎参考) &mdash; Scrapy 1.0.5 文档 使用Scrapy抓取数据 爬虫出现Forbidden by robots.txt - 菜鸡瞎讲- 博客频道 - CSDN.NET Scrapy用Cookie实现模拟登录 - 简书]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>爬虫</tag>
        <tag>Scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式搜索引擎ElasticSearch初探]]></title>
    <url>%2F2016%2F06%2F20%2Fdistributed-search-engine-elasticsearch%2F</url>
    <content type="text"><![CDATA[ElasticSearch是一个基于Lucene构建的开源，分布式，RESTful搜索引擎。 任务点 在Ubuntu下安装 在Windows下安装 使用Restful API实现搜索引擎的CURD操作 在Python网站Flask下使用ElasticSearch实现文章搜索 ElasticSearch的Python连接器：Pyes 安装Java (JVM) versionedit Elasticsearch is built using Java, and requires at least Java 7 in order to run. Only Oracle’s Java and the OpenJDK are supported. The same JVM version should be used on all Elasticsearch nodes and clients.We recommend installing the Java 8 update 20 or later, or Java 7 update 55 or later. Previous versions of Java 7 are known to have bugs that can cause index corruption and data loss. Elasticsearch will refuse to start if a known-bad version of Java is used.The version of Java to use can be configured by setting the JAVA_HOME environment variable. Linux(Ubuntu)下安装Installing the oracle JDK1234sudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installerjava -version RPM based distributions123sudo /bin/systemctl daemon-reloadsudo /bin/systemctl enable elasticsearch.servicesudo /bin/systemctl start elasticsearch.service Windows下安装从网站 下载windows下的msi安装包，在cmd命令行进入安装目录，再进入 bin 目录，运行 elasticsearch.bat 。 Ubuntu下配置ElasticSearch环境实录安装Java环境由于ElasticSearch的运行需要Java环境的支持，先安装java环境。由于Ubuntu系统中由于授权问题，默认只安装了OpenJDK的包，通过java和javac可以看到：1234567* default-jdk* ecj* gcj-4.9-jdk* openjdk-8-jdk-headless* gcj-4.8-jdk* gcj-5-jdk* openjdk-9-jdk 根据ElasticSearch官方推荐安装方法： 1234sudo add-apt-repository ppa:webupd8team/javasudo apt-get updatesudo apt-get install oracle-java8-installerjava -version 如果出现如下提示信息，并有进度条显示，则说明运行顺利并正在下载所需文件： 1234567891011HTTP request sent, awaiting response... 200 OKLength: 181367942 (173M) [application/x-gzip]Saving to: ‘jdk-8u91-linux-x64.tar.gz’ 0K ........ ........ ........ ........ ........ ........ 1% 566K 5m8s 3072K ........ ........ ........ ........ ........ ........ 3% 1.15M 3m44s 6144K ........ ........ ........ ........ ........ ........ 5% 1.10M 3m16s 9216K ........ ........ ........ ........ ........ ........ 6% 1002K 3m5s 12288K ........ ........ ........ ........ ........ ........ 8% 715K 3m11s 15360K ........ ........ ........ ........ ........ ........ 10% 624K 3m18s 18432K ........ ........ ........ ........ ........ ........ 12% 417K 3m40s 否则可能由于网络原因或其他问题，会中断下载或报错。 错误一：安装时出现错误：12345678sha256sum mismatch jdk-8u91-linux-x64.tar.gzOracle JDK 8 is NOT installed.dpkg: 处理软件包 oracle-java8-installer (--configure)时出错： 子进程 已安装 post-installation 脚本 返回错误状态 1正在设置 gsfonts-x11 (0.24) ...在处理时有错误发生： oracle-java8-installerE: Sub-process /usr/bin/dpkg returned an error code (1) 可以用该文章中介绍的方法解决，亲测有效：http://www.miaoqiyuan.cn/p/ubuntu-e-sub-process-dpkg-returned-an-error-code 错误二：根据上面的方法执行完命令后，执行 java -version 时只会显示下列输出信息： 123456789tiger@vbox:~$ java -version程序 &apos;java&apos; 已包含在下列软件包中： * default-jre * gcj-4.9-jre-headless * gcj-5-jre-headless * openjdk-8-jre-headless * gcj-4.8-jre-headless * openjdk-9-jre-headless请尝试：sudo apt install &lt;选定的软件包&gt; 即使是重复执行上面的安装方法，结果仍是如此： 123456789101112tiger@vbox:~$ sudo apt-get install oracle-java8-installer正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 oracle-java8-installer 已经是最新版 (8u92+8u91arm-2~really8u91~webupd8~0)。升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 196 个软件包未被升级。tiger@vbox:~$ sudo apt-get install oracle-java8-set-default正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 oracle-java8-set-default 已经是最新版 (8u92+8u91arm-2~really8u91~webupd8~0)。升级了 0 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 196 个软件包未被升级。 根本问题是什么 转到目录/usr/lib/jvm/ 下，可以看到一个名为 java-8-oracle 的目录，但查看该目录却发现里面是空的。所以虽然提示是安装成功了，但却没有可执行的文件，可能是在下载文件时出错了。 由于直接安装错误，下面尝试手动进行安装。 什么情况下表示安装成功，什么情况下表示安装失败通过 java -version 来查看 如果输出如下，则说明 Orancel JDK 安装失败： 12345678root@ubuntu:~# java -versionThe program &apos;java&apos; can be found in the following packages: * default-jre * gcj-4.8-jre-headless * openjdk-7-jre-headless * gcj-4.6-jre-headless * openjdk-6-jre-headlessTry: apt-get install &lt;selected package&gt; 如果输出如下，则说明安装成功： 1234tiger@vbox:/usr/lib/jvm$ java -versionjava version &quot;1.8.0_91&quot;Java(TM) SE Runtime Environment (build 1.8.0_91-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode) Ubuntu下手动安装JDK 到Oracle官网下载对应当前系统的jdk版本 Java SE Development Kit 8 Downloads ： 123456// 下载对应版本jdk压缩包，这里选择 `Linux64`wget http://download.oracle.com/otn-pub/java/jdk/8u91-b14/jdk-8u91-linux-x64.tar.gz// 等待下载完成后，执行：tar zxvf jdk-8u91-linux-x64.tar.gz// 查看 `ls`jdk1.8.0_91 jdk-8u91-linux-x64.tar.gz 将解压后的目录 jdk1.8.0_91 复制到 /usr/lib/jvm 目录里，1sudo cp -r jdk1.8.0_91/ /usr/lib/jvm 配置环境变量： 1sudo vim /etc/profile 在文件的末尾添加以下内容：(注意对应自己的目录路径和jdk的版本号) 1234JAVA_HOME=/usr/lib/jvm/jdk1.8.0_91export JRE_HOME=/usr/lib/jvm/jdk1.8.0_91/jreexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 修改完后，执行 :wq 退出vim ，使用source刷新一下： 1source /etc/profile 然后执行： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849java -version//看到如下信息表示安装成功：tiger@vbox:/usr/lib/jvm$ java -versionjava version &quot;1.8.0_91&quot;Java(TM) SE Runtime Environment (build 1.8.0_91-b14)Java HotSpot(TM) 64-Bit Server VM (build 25.91-b14, mixed mode)//执行 `java`tiger@vbox:/usr/lib/jvm$ java用法: java [-options] class [args...] (执行类) 或 java [-options] -jar jarfile [args...] (执行 jar 文件)其中选项包括: -d32 使用 32 位数据模型 (如果可用) -d64 使用 64 位数据模型 (如果可用) -server 选择 &quot;server&quot; VM 默认 VM 是 server. -cp &lt;目录和 zip/jar 文件的类搜索路径&gt; -classpath &lt;目录和 zip/jar 文件的类搜索路径&gt; 用 : 分隔的目录, JAR 档案 和 ZIP 档案列表, 用于搜索类文件。 -D&lt;名称&gt;=&lt;值&gt; 设置系统属性 -verbose:[class|gc|jni] 启用详细输出 -version 输出产品版本并退出........//执行 `javac`tiger@vbox:/usr/lib/jvm$ javac用法: javac &lt;options&gt; &lt;source files&gt;其中, 可能的选项包括: -g 生成所有调试信息 -g:none 不生成任何调试信息 -g:&#123;lines,vars,source&#125; 只生成某些调试信息 -nowarn 不生成任何警告 -verbose 输出有关编译器正在执行的操作的消息 -deprecation 输出使用已过时的 API 的源位置 -classpath &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -cp &lt;路径&gt; 指定查找用户类文件和注释处理程序的位置 -sourcepath &lt;路径&gt; 指定查找输入源文件的位置 -bootclasspath &lt;路径&gt; 覆盖引导类文件的位置.... .... 下面的步骤未测试，仅供参考 如果到这一步，任然不成功的话，则属于手动配置默认的JDK版本： 1234567891011sudo update-alternatives --install /usr/bin/java java /usr/lib/jvm/java/bin/java 300 sudo update-alternatives --install /usr/bin/javac javac /usr/lib/jvm/java/bin/javac 300 sudo update-alternatives --install /usr/bin/jar jar /usr/lib/jvm/java/bin/jar 300 sudo update-alternatives --install /usr/bin/javah javah /usr/lib/jvm/java/bin/javah 300 sudo update-alternatives --install /usr/bin/javap javap /usr/lib/jvm/java/bin/javap 300 //然后执行sudo update-alternatives --config java// 在通过 java -version 来判断java -version 参考 ： Running as a Service on Linux | Elasticsearch Reference [2.3] | Elastic ubuntu 13.04 安装 JDK - plinx - 博客园 在 Ubuntu 系统上安装 Oracle Java 8 | 半瓶 安装ElasticSearch下载最新安装包： 从 download Elasticsearch free 下载Linux的安装包：1234// 下载$ wget -c https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/zip/elasticsearch/2.3.3/elasticsearch-2.3.3.zip// 解压安装unzip elasticsearch-2.3.3.zip 进入解压后得到的目录 elasticsearch-2.3.3 ，参考官网安装教程 Setup 执行如下命令来运行:1$ bin/elasticsearch 如果上一步的java环境没有安装成功，执行该命令会报如下错误： 1Could not find any executable java binary. Please install java in your PATH or set JAVA_HOME 如果没有出现错误，提示信息中输出 如 [INFO] ..... 等信息，说明运行成功。 再新开一个命令行终端，执行： 1234567891011121314tiger@vbox:~$ curl http://localhost:9200/&#123; &quot;name&quot; : &quot;Rune&quot;, &quot;cluster_name&quot; : &quot;elasticsearch&quot;, &quot;version&quot; : &#123; &quot;number&quot; : &quot;2.3.3&quot;, &quot;build_hash&quot; : &quot;218bdf10790eef486ff2c41a3df5cfa32dadcfde&quot;, &quot;build_timestamp&quot; : &quot;2016-05-17T15:40:04Z&quot;, &quot;build_snapshot&quot; : false, &quot;lucene_version&quot; : &quot;5.5.0&quot; &#125;, &quot;tagline&quot; : &quot;You Know, for Search&quot;&#125;tiger@vbox:~$ 出现上面的提示则说明ElasticSearch安装成功。 ElasticSearch - kid551 - 博客园 默认情况下 Elasticsearch 的 RESTful 服务只有本机才能访问。也就是说无法从主机访问虚拟机中的服务。为了方便调试，可以修改 /config/elasticsarch.yml 文件，加入以下两行： 12network.bind_host: &quot;0.0.0.0&quot;network.publish_host: _non_loopback:ipv4_ 但线上环境切忌不要这样配置，否则任何人都可以通过这个接口修改你的数据。 安装 IK Analysis 处理中文搜索Elasticsearch 自带的分词器会粗暴地把每个汉字直接分开，没有根据词库来分词。为了处理中文搜索，还需要安装中文分词插件。我使用的是 elasticsearch-analysis-ik，支持自定义词库。 首先，下载与 Elasticsearch 匹配的 elasticsearch-analysis-ik 插件：{2.3.3–1.9.3} 12345678// 从github 下载内容git clone https://github.com/medcl/elasticsearch-analysis-ik.gitcd elasticsearch-analysis-ik// 进入指定的 tag v1.9.3git checkout v1.9.3// 当前目录lsconfig LICENSE.txt pom.xml README.md src 要编译 elasticsearch-analysis-ik ,需要安装 Apache Maven 工具： 12345sudo apt-get updatesudo apt-get install maven//查看是否正确安装mvn -v 执行编译： 12345// 当前目录lsconfig LICENSE.txt pom.xml README.md src// 编译mvn package 等待直到出现如下提示时，表示编译成功： 1234567891011[INFO] ------------------------------------------------------------------------[INFO] BUILD SUCCESS[INFO] ------------------------------------------------------------------------[INFO] Total time: 7:43.935s[INFO] Finished at: Sun Jun 19 18:36:59 CST 2016[INFO] Final Memory: 15M/56M[INFO] ------------------------------------------------------------------------//查看目录lsconfig LICENSE.txt pom.xml README.md src target 发现会多出了一个 target 目录，copy and unzip 目录下的文件 target/releases/elasticsearch-analysis-ik-{version}.zip 到 上面安装的 elasticsearch/plugins/ik 目录中，需要新建 ik 目录： 12345// target 目录$ pwdelasticsearch-analysis-ik/target/releases$ ls elasticsearch-analysis-ik-1.9.3.zip 在 elasticsearch-2.3.3/plugins/ 下新建目录ik : 1234$ ls /elastic/elasticsearch-2.3.3/plugins$ mkdir /elastic/elasticsearch-2.3.3/plugins/ik$ ls /elastic/elasticsearch-2.3.3/pluginsik 将上面编译完成的 elasticsearch-analysis-ik-1.9.3.zip 拷贝到 ik 目录并解压： 1234567891011$ cp elasticsearch-analysis-ik-1.9.3.zip ~/elastic/elasticsearch-2.3.3/plugins/ik$ ls /elastic/elasticsearch-2.3.3/plugins/ikelasticsearch-analysis-ik-1.9.3.zip// 解压$ unzip elasticsearch-analysis-ik-1.9.3.zip// 得到如下内容：$ lscommons-codec-1.9.jar elasticsearch-analysis-ik-1.9.3.zipcommons-logging-1.2.jar httpclient-4.4.1.jarconfig httpcore-4.4.1.jarelasticsearch-analysis-ik-1.9.3.jar plugin-descriptor.properties 注意：上面的操作目录请根据个人的目录和所下载的版本号进行修改 如果你觉得上面的编译步骤太繁琐，也可以直接在github页面的release中下载已经编译好的zip文件，直接解压到 ik 目录下即可： 123wget -c https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v1.9.3/elasticsearch-analysis-ik-1.9.3.zipunzip elasticsearch-analysis-ik-1.9.3.zip 重启 elasticsearch 服务即可。 如果看到类似于下面的信息，说明 IK Analysis 插件已经装好了: 1plugins [analysis-ik] 如何以root 账户运行elasticSearch默认情况下，ElasticSearch不允许以root账户运行，会报 don&#39;t run elasticsearch as root. 错误。不过我们也可以强制让其以 root 账户来运行： 1bin/elasticsearch -Des.insecure.allow.root=true 配置同义词 (该部分待测试)Elasticsearch 自带一个名为 synonym 的同义词 filter。为了能让 IK 和 synonym 同时工作，我们需要定义新的 analyzer，用 IK 做 tokenizer，synonym 做 filter。听上去很复杂，实际上要做的只是加一段配置。 打开 ~/elasticsearch-2.3.3/config/elasticsearch.yml 文件，加入以下配置： 123456789101112131415index: analysis: analyzer: ik_syno: type: custom tokenizer: ik_max_word filter: [my_synonym_filter] ik_syno_smart: type: custom tokenizer: ik_smart filter: [my_synonym_filter] filter: my_synonym_filter: type: synonym synonyms_path: analysis/synonym.txt 以上配置定义了 ik_syno 和 ik_syno_smart 这两个新的 analyzer，分别对应 IK 的 ik_max_word 和 ik_smart 两种分词策略。根据 IK 的文档，二者区别如下： ik_max_word：会将文本做最细粒度的拆分，例如「中华人民共和国国歌」会被拆分为「中华人民共和国、中华人民、中华、华人、人民共和国、人民、人、民、共和国、共和、和、国国、国歌」，会穷尽各种可能的组合； ik_smart：会将文本做最粗粒度的拆分，例如「中华人民共和国国歌」会被拆分为「中华人民共和国、国歌」； ik_syno 和 ik_syno_smart 都会使用 synonym filter 实现同义词转换。为了方便后续测试，建议创建 ~/elasticsearch-2.3.3/config/analysis/synonym.txt 文件，输入一些同义词并存为 utf-8 格式。例如： 123ua,user-agent,userAgentjs,javascriptinternet explore=&gt;ie 用Restful api 测试搜索(1) 查看集群健康信息： 1$ curl -X GET http://localhost:9200/_cat/health?v 返回结果为： 12epoch timestamp cluster status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent 1466352115 00:01:55 elasticsearch green 1 1 0 0 0 0 0 0 - 100.0% 返回结果的主要字段意义： cluster：集群名，是在ES的配置文件中配置的cluster.name的值。 status：集群状态。集群共有green、yellow或red中的三种状态。green代表一切正常（集群功能齐全），yellow意味着所有的数据都是可用的，但是某些复制没有被分配（集群功能齐全），red则代表因为某些原因，某些数据不可用。如果是red状态，则要引起高度注意，数据很有可能已经丢失。 node.total：集群中的节点数。 node.data：集群中的数据节点数。 shards：集群中总的分片数量。 pri：主分片数量，英文全称为private。 relo：复制分片总数。 unassign：未指定的分片数量，是应有分片数和现有的分片数的差值（包括主分片和复制分片）。 我们也可以在请求中添加help参数来查看每个操作返回结果字段的意义。 1$ curl -X GET http://localhost:9200/_cat/health?help 1234567891011121314epoch | t,time | seconds since 1970-01-01 00:00:00 timestamp | ts,hms,hhmmss | time in HH:MM:SS cluster | cl | cluster name status | st | health status node.total | nt,nodeTotal | total number of nodes node.data | nd,nodeData | number of nodes that can store datashards | t,sh,shards.total,shardsTotal | total number of shards pri | p,shards.primary,shardsPrimary | number of primary shards relo | r,shards.relocating,shardsRelocating | number of relocating nodes init | i,shards.initializing,shardsInitializing | number of initializing nodes unassign | u,shards.unassigned,shardsUnassigned | number of unassigned shards pending_tasks | pt,pendingTasks | number of pending tasks max_task_wait_time | mtwt,maxTaskWaitTime | wait time of longest task pending active_shards_percent | asp,activeShardsPercent | active number of shards in percent 有了这个东东，就可以减少看文档的时间。ES中许多API都可以添加help参数来显示字段含义，哪些可以这么做呢？每个API都试试就知道了。 当然，如果你觉得返回的东西太多，看着眼烦，我们也可以人为地指定返回的字段。 1elasticsearch green 0 (2) 查看集群中的节点信息 1tiger@vbox:~$ curl -XGET http://localhost:9200/_cat/nodes?v 返回节点的详细信息如下： 123host ip heap.percent ram.percent load node.role master name 10.0.2.15 10.0.2.15 9 90 0.15 d * Bullseye tiger@vbox:~$ (3) 查看集群中的索引信息 123tiger@vbox:~$ curl -XGET http://localhost:9200/_cat/indices?vhealth status index pri rep docs.count docs.deleted store.size pri.store.size yellow open twitter 5 1 1 0 4.1kb 4.1kb 索引（Index）相关API需要一个索引 index 和 type (1) 创建一个新的索引 使用自定义id索引文档 使用PUT请求创建一个索引为twitter类型为tweet的文档。其文档编号为1，文档内容包含title和content : 1234tiger@tiger-vbox:~$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/1?pretty&apos; -d &apos;&#123; &quot;title&quot;:&quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot;:&quot;三星无线充电器为圆行造型&quot;&#125;&apos; 返回信息 123456789101112&#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_version&quot; : 1, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;created&quot; : true&#125; 再添加一篇： 1234$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/2?pretty&apos; -d &apos;&#123; &quot;title&quot;:&quot;范冰冰着花裙亮相青岛，侧颜精致&quot;, &quot;content&quot;:&quot;6月19日，范冰冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot;&#125;&apos; 返回结果： 12345678910111213tiger@vbox:~$ curl -XPUT &apos;http://localhost:9200/twitter/tweet/2?pretty&apos; -d &apos;&#123;&quot;title&quot;:&quot;范冰冰着花裙亮相青岛，侧颜精致&quot;,&quot;content&quot;:&quot;6月19日，范冰 冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot;&#125;&apos;&#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_version&quot; : 2, &quot;_shards&quot; : &#123; &quot;total&quot; : 2, &quot;successful&quot; : 1, &quot;failed&quot; : 0 &#125;, &quot;created&quot; : false&#125; 查看所有文章： 1$ curl -XGET &apos;http://localhost:9200/twitter/tweet/_search?pretty=true&apos; -d &apos;&#123;&quot;query&quot;:&#123;&quot;match_all&quot;:&#123;&#125;&#125;&#125;&apos; 返回结果： 1234567891011121314151617181920212223242526272829303132&#123; &quot;took&quot; : 147, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 2, &quot;max_score&quot; : 1.0, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;2&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;范冰冰着花裙亮相青岛，侧颜精致&quot;, &quot;content&quot; : &quot;6月19日，范冰冰现身青岛某活动，一身花裙甜美亮相，精致侧颜秒杀菲林。&quot; &#125; &#125;, &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 1.0, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot; : &quot;三星无线充电器为圆行造型&quot; &#125; &#125; ] &#125;&#125; 这样会把刚才添加的文章都列出来。 搜索关键词“无线”： 1tiger@vbox:~$ curl -XGET &quot;http://localhost:9200/twitter/tweet/_search?pretty=true&quot; -d &apos;&#123;&quot;query&quot;:&#123;&quot;query_string&quot;:&#123;&quot;query&quot;:&quot;无线&quot;&#125;&#125;&#125;&apos; 1234567891011121314151617181920212223&#123; &quot;took&quot; : 49, &quot;timed_out&quot; : false, &quot;_shards&quot; : &#123; &quot;total&quot; : 5, &quot;successful&quot; : 5, &quot;failed&quot; : 0 &#125;, &quot;hits&quot; : &#123; &quot;total&quot; : 1, &quot;max_score&quot; : 0.0958915, &quot;hits&quot; : [ &#123; &quot;_index&quot; : &quot;twitter&quot;, &quot;_type&quot; : &quot;tweet&quot;, &quot;_id&quot; : &quot;1&quot;, &quot;_score&quot; : 0.0958915, &quot;_source&quot; : &#123; &quot;title&quot; : &quot;三星无线充电技术，值得国产手机去学习吗&quot;, &quot;content&quot; : &quot;三星无线充电器为圆行造型&quot; &#125; &#125; ] &#125;&#125; 检查ik的切词效果，可以执行： 1tiger@tiger-vbox:~$ curl &apos;http://localhost:9200/twitter/_analyze?analyzer=ik_max_word&amp;pretty=true&apos; -d &apos;&#123;&quot;text&quot;:&quot;中华人民共和国国歌&quot;&#125;&apos; 返回结果： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&#123; &quot;tokens&quot; : [ &#123; &quot;token&quot; : &quot;中华人民共和国&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 0 &#125;, &#123; &quot;token&quot; : &quot;中华人民&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 1 &#125;, &#123; &quot;token&quot; : &quot;中华&quot;, &quot;start_offset&quot; : 0, &quot;end_offset&quot; : 2, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 2 &#125;, &#123; &quot;token&quot; : &quot;华人&quot;, &quot;start_offset&quot; : 1, &quot;end_offset&quot; : 3, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 3 &#125;, &#123; &quot;token&quot; : &quot;人民共和国&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 4 &#125;, &#123; &quot;token&quot; : &quot;人民&quot;, &quot;start_offset&quot; : 2, &quot;end_offset&quot; : 4, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 5 &#125;, &#123; &quot;token&quot; : &quot;共和国&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 6 &#125;, &#123; &quot;token&quot; : &quot;共和&quot;, &quot;start_offset&quot; : 4, &quot;end_offset&quot; : 6, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 7 &#125;, &#123; &quot;token&quot; : &quot;国&quot;, &quot;start_offset&quot; : 6, &quot;end_offset&quot; : 7, &quot;type&quot; : &quot;CN_CHAR&quot;, &quot;position&quot; : 8 &#125;, &#123; &quot;token&quot; : &quot;国歌&quot;, &quot;start_offset&quot; : 7, &quot;end_offset&quot; : 9, &quot;type&quot; : &quot;CN_WORD&quot;, &quot;position&quot; : 9 &#125; ]&#125; 说明一下pretty 参数就是让返回的json有换行和缩进，容易阅读，调试时可以加上，开发到程序里就可以去掉了。 相关链接依赖包 GitHub - medcl/elasticsearch-analysis-ik: The IK Analysis plugin integrates Lucene IK analyzer into elasticsearch, support customized dictionary. Linux下安装 使用 Elasticsearch 实现博客站内搜索 | JerryQu 的小站 ☆ 教你成为全栈工程师(Full Stack Developer) 二十四-ES(elasticsearch)搜索引擎安装和使用 - SharEDITor - 关注大数据技术 Running as a Service on Linux | Elasticsearch Reference [2.3] | Elastic The Elastic Stack Download · Get Started in Minutes | Elastic Windows下安装 windows下安装elasticsearch-1.7.1 | 教程网 Running as a Service on Windows | Elasticsearch Reference [2.3] | Elastic Windows下安装Maven参考 Restful Api Python Elasticsearch api - letong - 博客园 ElasticSearch教程（4）——ElasticSearch基于REST的CRUD API - 为程序员服务 实时搜索引擎Elasticsearch（2）——Rest API的使用 - HinyLover的专栏 - 博客频道 - CSDN.NET Document APIs | Elasticsearch Reference [2.3] | Elastic elasticsearch rest api 快速上手 · Issue #5 · sxyx2008/elasticsearch · GitHub 文档 Elasticsearch - 随笔分类 - xingoo - 博客园 使用Python进行Elasticsearch数据索引 | Silent River 安装和使用 Elasticsearch | vpsee.com 实时搜索引擎Elasticsearch（1）——基础概念、安装和运行 - HinyLover的专栏 - 博客频道 - CSDN.NET ☆ Introduction | Elasticsearch权威指南（中文版） ☆ AAAAAAA https://github.com/medcl/elasticsearch-analysis-ik http://blog.csdn.net/xialei199023/article/details/48085125 http://blog.csdn.net/xialei199023/article/details/48227247 https://github.com/elastic/elasticsearch https://www.elastic.co/guide/en/elasticsearch/reference/current/docs.html https://github.com/sxyx2008/elasticsearch/issues/5 http://www.shareditor.com/blogshow/?blogId=36]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ElasticSearch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python操作SQLServer数据库]]></title>
    <url>%2F2016%2F06%2F20%2Fpython-connect-sqlserver%2F</url>
    <content type="text"><![CDATA[pymssqlPython操作SQLServer需要使用 pymssql 模块 Windows系统下的Python类库文件 *.whl文件，需要用 pip install *.whl 的方式来安装。 下载pymssql2.7 library ：pythonlibs 第一次下载了 pymssql-2.1.2-cp27-cp27m-win_amd64.whl 文件，安装时报错，提示如下错误： 12λ pip install pymssql-2.1.2-cp27-cp27m-win_amd64.whlpymssql-2.1.2-cp27-cp27m-win_amd64.whl is not a supported wheel on this platform. 即使成功安装了 pymssql，但是 import pymssql 还是会报错 12import pymssqlImportError: DLL load failed: 找不到指定的模块。 所以又再次下载了 pymssql-1.0.3-cp27-none-win32.whl 文件，再次安装成功。具体原因可能和操作系统或python版本有关，具体待深入研究。 Demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162# coding:utf-8&quot;&quot;&quot;http://www.pymssql.org/en/stable/http://www.lfd.uci.edu/~gohlke/pythonlibs/#pymssql pymssql-1.0.3-cp27-none-win32.whl # 只有这个才能在windows下执行pymssql-2.1.2-cp27-cp27m-win_amd64.whl # 这个不能执行安装 whl文件 执行 `pip install *.whl`异常：不能用 DB-Library (如 ISQL)或 ODBC 3.7 或更早版本将 ntext 数据或仅使用 Unicode 排序规则的 Unicode 数据发送到客 户端。这个问题是数据库中字段为ntext类型，这种类型目前的c-library不支持，需要转为nvchar或text类型才可以。1. 建议：将ntext修改为nvarchar或text.2. 既然不支持ntext但支持text，那么我们只需要在输出时将ntext转换为text就好了 `SELECT cast ( field_name AS TEXT ) AS field_name``select convert(varchar(50),guid) as guid, convert(text,content) as content from news`&quot;&quot;&quot;import pymssqlclass MSSQL: def __init__(self,host,user,pwd,db): self.host=host self.user=user self.pwd=pwd self.db=db def __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) self.conn=pymssql.connect(host=self.host,user=self.user,password=self.pwd,database=self.db,charset=&quot;utf-8&quot;) cur=self.conn.cursor() if not cur: raise(NameError,&quot;连接数据库失败&quot;) else: return cur def ExecQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) resList=cur.fetchall() # 查询完毕后关闭连接 self.conn.close() return resList def ExecNonQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) self.conn.commit() self.conn.close()if __name__==&quot;__main__&quot;: ms=MSSQL(host=&quot;Test-FPC\sqlexpress&quot;,user=&quot;sa&quot;,pwd=&quot;1&quot;,db=&quot;its&quot;) resList=ms.ExecQuery(&quot;select * from [SchemeCategory] where IsShow=1&quot;) for i in resList: print(i[&quot;Name&quot;]) 错误处理在操作是报出了如下异常信息： 不能用 DB-Library (如 ISQL)或 ODBC 3.7 或更早版本将 ntext 数据或仅使用 Unicode 排序规则的 Unicode 数据发送到客 户端。 这个问题是数据库中字段为ntext类型，这种类型目前的 c-library 不支持，需要转为 nvchar 或 text 类型才可以。 建议：将ntext修改为nvarchar或text. 既然不支持ntext但支持text，那么我们只需要在输出时将ntext转换为text就好了 12SELECT cast ( field_name AS TEXT ) AS field_nameselect convert(varchar(50),guid) as guid, convert(text,content) as content from news 使用另一个类库 pyodbc 来操作，未遇到该问题。 相关链接Python操作SQLServer示例 | 大爱利用python简化sql server数据导入导出 - qianlifeng - 博客园 python 使用pymssql连接sql server数据库 - Hello World! pymssql &mdash; pymssql 2.2.0.dev documentationFreeTDS &mdash; pymssql 2.2.0.dev documentationGitHub - pymssql/pymssql: Official home for the pymssql source code.FreeTDS.orgPython Extension Packages for Windows - Christoph Gohlke pyodbcSQL Server ODBC drivers {SQL Server} - released with SQL Server 2000 {SQL Native Client} - released with SQL Server 2005 (also known as version 9.0) {SQL Server Native Client 10.0} - released with SQL Server 2008 {SQL Server Native Client 11.0} - released with SQL Server 2012 [sqlservertests]connection-string=DRIVER={SQL Server};SERVER=localhost;UID=uid;PWD=pwd;DATABASE=db The connection string above will use the 2000/2005 driver, even if SQL Server 2008is installed: 2000: DRIVER={SQL Server} 2005: DRIVER={SQL Server} 2008: DRIVER={SQL Server Native Client 10.0} connection strings1DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password in Python: 1conn = pyodbc.connect(r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos;) 连接字符串的两种写法字符串方式123connSqlServer = pyodbc.connect(&apos;DRIVER=&#123;SQL Server Native Client 10.0&#125;;SERVER=192.106.0.102\instance1;DATABASE=master;UID=sql2008;PWD=password123&apos;)connSqlServer = pyodbc.connect(&apos;DRIVER=&#123;SQL Server Native Client 10.0&#125;;SERVER=192.106.0.102,1443;DATABASE=master;UID=sql2008;PWD=password123&apos;) 关键字方式123456789connSqlServer = pyodbc.connect(driver=&apos;&#123;SQL Server Native Client 10.0&#125;&apos;, server=&apos;192.106.0.102\instance1&apos;, database=&apos;master&apos;, uid=&apos;sql2008&apos;,pwd=&apos;password123&apos;)connSqlServer = pyodbc.connect(driver=&apos;&#123;SQL Server Native Client 10.0&#125;&apos;, server=&apos;192.106.0.102,1443&apos;, database=&apos;master&apos;, uid=&apos;sql2008&apos;,pwd=&apos;password123&apos;) 详见：sql - python pyodbc : how to connect to a specific instance - Stack Overflow 我的写法第一种方式123456789101112131415def __init__(self,driver,server,db,uid,pwd): self.driver=&quot;&#123;&#123;&#123;0&#125;&#125;&#125;&quot;.format(driver) # 两个&#123;表示一个 self.server=server self.db=db self.uid=uid self.pwd=pwddef __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) # r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos; self.conn=pyodbc.connect(driver=self.driver,server=self.server,database=self.db,uid=self.uid,pwd=self.pwd)ms=MSSQLODBC(driver=&quot;SQL Server&quot;,server=&quot;Test-FPC\sqlexpress&quot;,db=&quot;its&quot;,uid=&quot;sa&quot;,pwd=&quot;1&quot;) 第二种方式1self.conn = pyodbc.connect(&apos;DRIVER=&#123;SQL Server&#125;;SERVER=Test-FPC\sqlexpress;PORT=1433;DATABASE=its;UID=sa;PWD=1&apos;) pyodbc Connecting to SQL Server from Windows · mkleehammer/pyodbc Wiki · GitHub sql - python pyodbc : how to connect to a specific instance - Stack Overflow Demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849# coding:utf-8&quot;&quot;&quot;&quot;&quot;&quot;import pyodbcclass MSSQLODBC: def __init__(self,driver,server,db,uid,pwd): self.driver=&quot;&#123;&#123;&#123;0&#125;&#125;&#125;&quot;.format(driver) # 两个&#123;表示一个 self.server=server self.db=db self.uid=uid self.pwd=pwd def __GetConnect(self): if not self.db: raise(NameError,&quot;没有设置数据库信息&quot;) # r&apos;DRIVER=&#123;SQL Server Native Client 11.0&#125;;SERVER=test;DATABASE=test;UID=user;PWD=password&apos; self.conn=pyodbc.connect(driver=self.driver,server=self.server,database=self.db,uid=self.uid,pwd=self.pwd) # self.conn = pyodbc.connect(&apos;DRIVER=&#123;SQL Server&#125;;SERVER=Test-FPC\sqlexpress;PORT=1433;DATABASE=its;UID=sa;PWD=1&apos;) cur=self.conn.cursor() if not cur: raise(NameError,&quot;连接数据库失败&quot;) else: return cur def ExecQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) resList=cur.fetchall() # 查询完毕后关闭连接 self.conn.close() return resList def ExecNonQuery(self,sql): cur=self.__GetConnect() cur.execute(sql.encode(&quot;utf-8&quot;)) self.conn.commit() self.conn.close()if __name__==&quot;__main__&quot;: ms=MSSQLODBC(driver=&quot;SQL Server&quot;,server=&quot;Test-FPC\sqlexpress&quot;,db=&quot;its&quot;,uid=&quot;sa&quot;,pwd=&quot;1&quot;) resList=ms.ExecQuery(&quot;select top 10 * from [MallProductItem]&quot;) for m in resList: print(m[4])]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C#脱离IronPython中执行python脚本]]></title>
    <url>%2F2016%2F06%2F10%2Fcsharp-call-python-without-ironpython-environment%2F</url>
    <content type="text"><![CDATA[给客户安装程序时除了安装 .net framework 还要安装 IronPython ，是不是觉得很麻烦？ 上面这一切都弱爆了，下面我来介绍一种不安装 IronPython 只需要引入几个 IronPython 的 dll 就可以在c#中执行 python 脚本的方法。 1：引入IronPython中的几个dll * `IronPython.dll` * `IronPython.Modules.dll` * `Microsoft.Dynamic.dll` * `Microsoft.Scripting.dll` * `Microsoft.Scripting.Metadata.dll` 2：进入IronPython的Lib文件夹，把Lib中的内容打包成zip，名字任意既可。打包好后放到c#项目下我把它放到了和py文件同一个目录中 3：很关键的一步，程序初始化时执行下段代码 12345678ScriptEngine engine = Python.CreateEngine(); ScriptScope scope = engine.CreateScope(); ScriptSource source = engine.CreateScriptSourceFromString( @&quot;import sys&quot; &quot;\n&quot; @&quot;sys.path.append(&quot;&quot;.\scripts\pythonlib.zip&quot;&quot;)&quot; &quot;\n&quot; @&quot;sys.path.append(&quot;&quot;.\scripts&quot;&quot;)&quot; &quot;\n&quot;); source.Execute(scope); 将zip文件加入python库路径。这样能保证py脚本可以正确搜索到python库的位置。 4：尽情享用脚本语言带来的便利吧。为其他人安装程序时也不用安装讨厌的IronPython环境了。 链接 C#脱离IronPython中执行python脚本-gsbhzh 的个人空间 - 开源中国社区]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[O2O地图应用之判断用户订单地址是否在服务范围内]]></title>
    <url>%2F2016%2F05%2F18%2Fwhether-user-order-address-is-within-service-range%2F</url>
    <content type="text"><![CDATA[需求分析在o2o项目中，经常要用到在用户下单时判断用户所填地址的坐标点是否在服务范围内的情况，这里参考网上的实现方式，用C#来实现，经测试后有效，特此记录。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114public class MapHelper &#123; /// &lt;summary&gt; /// 判断一个坐标点在多边形坐标点的内部还是外部 /// &lt;/summary&gt; /// &lt;param name=&quot;point&quot;&gt;要判断的坐标点&lt;/param&gt; /// &lt;param name=&quot;pts&quot;&gt;多边形坐标点集合&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static bool IsPointInPolygon(Point point, List&lt;Point&gt; pts) &#123; int N = pts.Count; //如果点位于多边形的顶点或边上，也算做点在多边形内，直接返回true bool boundOrVertex = true; //经过点的次数 int intersectCount = 0; double precision = 2e-10; Point p1, p2; Point p = point;//当前点 p1 = pts[0]; for (int i = 1; i &lt;= N; i++) &#123; //如果点在多边形上 if (p.Equals(p1)) &#123; return boundOrVertex; &#125; p2 = pts[(i % N)]; if (p.Lng&lt;Math.Min(p1.Lng,p2.Lng)||p.Lng&gt;Math.Max(p1.Lng,p2.Lng)) &#123; p1 = p2; continue; &#125; if (p.Lng&gt;Math.Min(p1.Lng,p2.Lng)&amp;&amp;p.Lng&lt;Math.Max(p1.Lng,p2.Lng)) &#123; if (p.Lat&lt;=Math.Max(p1.Lat,p2.Lat)) &#123; if (p1.Lng==p2.Lng&amp;&amp;p.Lat&gt;=Math.Min(p1.Lat,p2.Lat)) &#123; return boundOrVertex; &#125; if (p1.Lat==p2.Lat) &#123; if (p1.Lat==p.Lat) &#123; return boundOrVertex; &#125; else &#123; intersectCount++; &#125; &#125; else &#123; double xinters = (p.Lng - p1.Lng) * (p2.Lat - p1.Lat) / (p2.Lng - p1.Lng) + p1.Lat; if (Math.Abs(p.Lat-xinters)&lt;precision) &#123; return boundOrVertex; &#125; if (p.Lat&lt;xinters) &#123; intersectCount++; &#125; &#125; &#125; &#125; else &#123; if (p.Lng==p2.Lng&amp;&amp;p.Lat&lt;=p2.Lat) &#123; Point p3 = pts[(i+1)%N]; if (p.Lng&gt;=Math.Min(p1.Lng,p3.Lng)&amp;&amp;p.Lng&lt;=Math.Max(p1.Lng,p3.Lng)) &#123; intersectCount++; &#125; else &#123; intersectCount += 2; &#125; &#125; &#125; p1 = p2; &#125; if (intersectCount%2==0) &#123; //偶数在多边形外 return false; &#125; else &#123; //奇数在多边形内 return true; &#125; &#125; &#125; public class Point &#123; /// &lt;summary&gt; /// 经度 /// &lt;/summary&gt; public double Lng &#123; get; set; &#125; /// &lt;summary&gt; /// 纬度 /// &lt;/summary&gt; public double Lat &#123; get; set; &#125; &#125; 测试这里我用高德地图标出了北京五环范围的坐标点集合，然后随意选择一个坐标点来进行判断： 坐标点可以用这个工具来获取：高德地图API 五环范围： 香泉桥 116.222208,39.992436 箭亭桥 116.327147,40.02046 上清桥 116.353948,40.02299 顾家庄桥 116.44128,40.020526 东北五环 116.48441,40.013624 平房桥 116.541101,39.942393 东南五环 116.549202,39.851595 旧宫新桥 116.43082,39.785968 狼垈东桥 116.296044,39.777442 宛平桥 116.225062,39.845517 衙门口桥 116.211308,39.894396 西五环 116.212595,39.944705 随机坐标： 林萃桥地铁站 116.37297,40.021857 望京西园四区 116.47086,39.99648 观音禅寺 116.533811,39.880533 俏狐国际 116.299713,39.772619 芳园里小区 116.416336,39.78394 润枫锦尚小区 116.429039,39.790535 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849class Program&#123; static void Main(string[] args) &#123; var Plist = new List&lt;Point&gt; &#123; new Point &#123;Lng=116.222208,Lat= 39.992436&#125;, new Point &#123;Lng=116.327147,Lat= 40.02046&#125;, new Point &#123;Lng=116.353948,Lat= 40.02299&#125;, new Point &#123;Lng=116.44128,Lat= 40.020526&#125;, new Point &#123;Lng=116.48441,Lat=40.013624 &#125;, new Point &#123;Lng=116.541101,Lat= 39.942393&#125;, new Point &#123;Lng=116.549202,Lat= 39.851595&#125;, new Point &#123;Lng=116.43082,Lat=39.785968&#125;, new Point &#123;Lng=116.296044,Lat=39.777442 &#125;, new Point &#123;Lng=116.225062,Lat=39.845517 &#125;, new Point &#123;Lng=116.211308,Lat= 39.894396&#125;, new Point &#123;Lng=116.212595,Lat=39.944705&#125; &#125;; //var p = new Point &#123; Lng = 116.37297, Lat = 40.021857 &#125;; //林萃桥地铁站 内 //var p = new Point &#123; Lng = 116.47086, Lat = 39.99648 &#125;; //望京西园四区 内 //var p = new Point &#123; Lng = 116.533811, Lat = 39.880533 &#125;; //观音禅寺 内 //var p = new Point &#123; Lng = 116.299713, Lat = 39.772619 &#125;; //俏狐国际 外 //var p = new Point &#123; Lng = 116.416336, Lat = 39.78394 &#125;; //芳园里小区 外 var p = new Point &#123; Lng = 116.429039, Lat = 39.790535 &#125;; //润枫锦尚小区 内 bool isin = MapHelper.IsPointInPolygon(p, Plist); if (isin) &#123; Console.WriteLine(&quot;随机点在五环范围内，可以派单&quot;); &#125; else &#123; Console.WriteLine(&quot;随机点不在五环范围内&quot;); &#125; Console.ReadKey(); &#125;&#125; 总结 北京的五环范围毕竟不是一个规则的多边形，可以尽量选择有标志性的坐标点来规范多边形 参考自：百度地图——判断用户是否在配送范围内解决方案 - aheizi - 博客园]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中时间格式转换]]></title>
    <url>%2F2016%2F05%2F17%2Ftime-format-conversion-in-python%2F</url>
    <content type="text"><![CDATA[1234YYYY-MM-DDTHH:MM:SS+HH:MM2016-04-05T13:31:00+08:002014-09-18T10:42:16.126Z 123$ time = &apos;2012-03-01T00:05:55+00:00&apos;$ datetime.strptime(time, &quot;%Y-%m-%dT%H:%M:%S+00:00&quot;)# =&gt; datetime.datetime(2012, 3, 1, 0, 5, 55) strftime() 用于时间格式转换strptime() 用于字符串格式转换 代码段123456789101112131415161718192021222324# 将UTC时间转换为本地时间# 2016-04-04T23:58:00+08:00def _utc_datetime(value): # value为传入的值为UTC时间，如：2016-04-04T23:58:00+08:00 format=&apos;%Y-%m-%d %H:%M:%S&apos; utc_format=&apos;%Y-%m-%dT%H:%M:%S+08:00&apos; local= datetime.strptime(value,utc_format) dt= datetime.strftime(local,format) return dt&apos;&apos;&apos;将unix时间戳转为标准时间格式&apos;&apos;&apos;def _timestamp_datetime(value): format = &apos;%Y-%m-%d %H:%M:%S&apos; # value为传入的值为时间戳(整形)，如：1332888820 value = time.localtime(value) ## 经过localtime转换后变成 ## time.struct_time(tm_year=2012, tm_mon=3, tm_mday=28, tm_hour=6, tm_min=53, tm_sec=40, tm_wday=2, tm_yday=88, tm_isdst=0) # 最后再经过strftime函数转换为正常日期格式。 dt = time.strftime(format, value) return dt 相关链接 答案见这里：Convert UTC time to python datetime - Stack Overflow datetime - [ Python 3零起点教程 ] - 看云 Python中Timestamp、Datetime和UTC时间相互转化的方法 - OPEN 开发经验库 SQLite 日期类型(转) - 深海的小鱼儿 - 博客园 python本地时间与UTC时间转换丶Source新浪博客 Python将UTC时间转化为Local时间 - 降龍 - 博客频道 - CSDN.NET python时间处理之datetime - 码农老毕的学习笔记 - 博客频道 - CSDN.NET Python 时间戳和日期相互转换 - 李林克斯 ☆ Python中Timestamp、Datetime和UTC时间相互转化的方法_python_ThinkSAAS]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python时间差]]></title>
    <url>%2F2016%2F05%2F17%2Ftime-difference-in-python%2F</url>
    <content type="text"><![CDATA[datetime.timedeltadatetime.timedelta对象代表两个时间之间的的时间差，两个date或datetime对象相减时可以返回一个timedelta对象。 构造函数: 1class datetime.timedelta([days[, seconds[, microseconds[, milliseconds[, minutes[, hours[, weeks]]]]]]]) 所有参数可选，且默认都是0，参数的值可以是整数，浮点数，正数或负数。 timedelta 可以和 date，datetime 对象进行加减操作 timedelta.total_seconds() 用于计算秒数。 当前的时间上加一天或一年减一天等操作1234567891011#!/usr/bin/env python # -*- coding:utf-8 -*- from datetime import datetime,timedelta now = datetime.now() yestoday = now - timedelta(days=1) tommorow = now + timedelta(days=1) next_year = now + timedelta(days = 365) 相关链接 Python中时间的处理之——timedelta篇 - Goodspeed - 博客园]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下配置Flask运行环境]]></title>
    <url>%2F2016%2F05%2F09%2Fconfiguring-flask-running-environment-under-ubuntu%2F</url>
    <content type="text"><![CDATA[Virtualenv + Flask + Gunicorn + Supervisor + Nginx 配置假设我所在的当前账户名为 tiger 。 准备python环境123$ sudo apt-get udpate// 安装python 和 pip (如果已经安装可以忽略)$ sudo apt-get install python-dev python-pip -y 创建virtualenv虚拟环境Virtualenv可以为每个Python应用创建独立的开发环境，使他们互不影响，Virtualenv能够做到： 在没有权限的情况下安装新套件 不同应用可以使用不同的套件版本 套件升级不影响其他应用 12//安装或通过执行：$ sudo pip install virtualenv 我通常创建一个包含 venv 文件夹的项目文件夹: 123456$ mkdir myproject$ cd myproject$ virtualenv venvNew python executable in venv/bin/python2Also creating executable in venv/bin/pythonInstalling setuptools, pip...done. 现在，每次需要使用项目时，必须先激活相应的环境。 123456$ ls-- venv$ . venv/bin/activate//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ 你现在进入你的 virtualenv （注意查看你的 shell 提示符已经改变了）。 安装Flask现在可以开始在你的 virtualenv 中安装 Flask 了: 123456789$ pip install Flask//结果：(venv)tiger@VirtualBox:~/xbox/myflask$ pip install FlaskDownloading/unpacking Flask Downloading Flask-0.10.1.tar.gz (544kB): 544kB downloaded ...... Successfully installed Flask Werkzeug Jinja2 itsdangerous MarkupSafeCleaning up... 几秒钟后就安装好了。 退出虚拟环境可通过deactivate退出虚拟环境： 12(venv)tiger@VirtualBox:~/xbox/myflask$ deactivatetiger@VirtualBox:~/xbox/myflask$ 具体可详见：Flask-安装 启动falsk在当前目录下新建一个 hello.py 的文件： 123(venv) $ vim hello.py(venv) $ lsvenv hello.py 创建一个简单的Flask程序： 123456789from flask import Flaskapp = Flask(__name__)@app.route(&apos;/&apos;)def hello_world(): return &apos;Hello World!&apos;if __name__ == &apos;__main__&apos;: app.run() 修改hello.py 的权限： 1(venv) $ chmod a+x hello.py 启动 flask: 1(venv) $ python hello.py 此时，用浏览器访问 http://127.0.0.1:5000 就能看到网页显示 hello world。 配置GunicornGunicorn是用于部署WSGI应用的，任何支持WSGI的都可以，虽说直接执行 python hello.py 这样网站也能跑起来，但那是方便开发而已，在线上环境，还是需要更高效的组件来做。 安装1(venv)$ pip install gunicorn 然后可以执行： 1234567891011gunicorn -w 4 -b 127.0.0.1:8000 hello:app//结果：(venv) $ gunicorn -w 4 -b 127.0.0.1:8000 hello:app[2016-05-08 16:07:36 +0000] [1337] [INFO] Starting gunicorn 19.4.5[2016-05-08 16:07:36 +0000] [1337] [INFO] Listening at: http://127.0.0.1:8000 (1337)[2016-05-08 16:07:36 +0000] [1337] [INFO] Using worker: sync[2016-05-08 16:07:36 +0000] [1342] [INFO] Booting worker with pid: 1342[2016-05-08 16:07:36 +0000] [1343] [INFO] Booting worker with pid: 1343[2016-05-08 16:07:36 +0000] [1344] [INFO] Booting worker with pid: 1344[2016-05-08 16:07:36 +0000] [1345] [INFO] Booting worker with pid: 1345 “hello” is the name of the file (without extension). And “app” is the name of the Flask object. 这里 “hello” 是python文件的名称(不包含扩展名)，冒号后面的”app” 是flask程序中app = Flask(__name__)创建的这个Flask对象的名称。 这里我们用了 8000 的端口进行访问，原先的 5000 并没有启用。 -w表示开启多少个 worker，-b 表示 gunicorn 开发的访问地址 想要结束 gunicorn 只需执行 pkill gunicorn : 123456789(venv) $ pkill gunicorn//结果：[2016-05-08 16:09:28 +0000] [1337] [INFO] Handling signal: term[2016-05-08 16:09:28 +0000] [1344] [INFO] Worker exiting (pid: 1344)[2016-05-08 16:09:28 +0000] [1342] [INFO] Worker exiting (pid: 1342)[2016-05-08 16:09:28 +0000] [1343] [INFO] Worker exiting (pid: 1343)[2016-05-08 16:09:28 +0000] [1345] [INFO] Worker exiting (pid: 1345)[2016-05-08 16:09:29 +0000] [1337] [INFO] Shutting down: Master 我们还可以在一个独立的配置文件中来设置，新增配置文件 gunicorn.conf： 1234567(venv) $ ls-- hello.py hello.pyc venv(venv) $ vim gunicorn.conf//写入下列内容：workers=4bind=&apos;127.0.0.1:8000&apos; 上面使用pkill gunicorn的方式来停止进程，太过于繁琐，因此出现了另外一个神器—supervisor，一个专门用来管理进程的工具，还可以管理系统的工具进程。 SupervisorSupervisor 是用Python实现的一款非常实用的进程管理工具。 安装supervisor1(venv) $ pip install supervisor 常用操作123456## 启动服务$ sudo service supervisor start## 停止服务$ sudo service supervisor stop## 也可以直接 kill pid$ ps -A | grep supervisor 生成supervisor默认配置文件123456(venv) $ echo_supervisord_conf &gt; supervisor.conf## 添加一个`logs`目录，用来后面存放日志：(venv) $ mkdir logs(venv) $ lsgunicorn.conf hello.py hello.pyc logs supervisor.conf venv 修改supervisor配置文件，添加gunicorn进程管理1(venv) $ vim supervisor.conf 在 supervisor.conf 配置文件底部添加：(假设我的工作目录为： /home/tiger/myflask/myproject/ ) 12345678910##文件内容[program:hello] ## 服务的名称，后面操作会用到command=/home/tiger/myflask/myproject/venv/bin/gunicorn hello:app -c /home/tiger/myflask/myproject/gunicorn.conf ; supervisor启动命令directory=/home/tiger/myflask/myproject ; 项目的文件夹路径user=tigerautostart=true ; 是否自动启动autorestart=true ; 是否自动重启##log文件的位置stdout_logfile=/home/tiger/myflask/myproject/logs/gunicorn_supervisor.log ; log 日志stderr_logfile=/home/tiger/myflask/myproject/logs/gunicorn_supervisor.err ; 错误日志 supervisor的基本使用命令 12345supervisord -c supervisor.conf 通过配置文件启动supervisorsupervisorctl -c supervisor.conf status 查看supervisor的状态supervisorctl -c supervisor.conf reload 重新载入 配置文件supervisorctl -c supervisor.conf start [all]|[appname] 启动指定/所有 supervisor管理的程序进程supervisorctl -c supervisor.conf stop [all]|[appname] 关闭指定/所有 supervisor管理的程序进程 添加完上面的内容后，保存退出。执行操作： 当前目录： 12(venv) $ ls-- gunicorn.conf hello.py hello.pyc logs supervisor.conf venv 通过配置文件 启动 supervisor : 1(venv) $ supervisord -c supervisor.conf 查看 supervisor 的状态： 12(venv) $ supervisorctl -c supervisor.conf status-- hello RUNNING pid 1550, uptime 0:04:08 停止 设置的 服务 hello ： 12(venv) $ supervisorctl -c supervisor.conf stop hello -- hello: stopped 再次查看 服务 hello 的状态 ： 12(venv) $ supervisorctl -c supervisor.conf status-- hello STOPPED May 08 05:23 PM 自动启动： 那么，如果想开机时自动启动怎么办呢？或者说，如果机器重启了，那WEB服务就断了。其实呢，也很简单，只要在 /etc/rc.d/rc.local 中加入一句就可以了： 1supervisord -c /home/tiger/myflask/myproject/supervisor.conf 有了Gunicorn、Supervisor，本地的环境的算是搭好了，但是我们需要让VPS上的网站从外网可以访问，这时候需要Nginx。 现在，我们只能在本机上通过http://127.0.0.1:8000 的方式来访问的，但在外网上是无法访问到的。 配置Nginx在安装Nginx之前，要先退出上面步骤中操作所在的venv环境，执行： 1(venv) $ deactivate 安装nginx1$ sudo apt-get install nginx 安装完成后访问localhost可以看到 Welcome to nginx on Ubuntu! 的页面。 nginx 的默认网站目录 /usr/share/nginx/html 常用配置命令1234567##启动服务$ sudo service nginx start##重启和暂停服务$ sudo service nginx restart$ sudo service nginx stop##查看状态$ sudo service nginx status 或下面的命令： 1234$ sudo /etc/init.d/nginx start$ sudo /etc/init.d/nginx stop$ sudo /etc/init.d/nginx restart$ sudo /etc/init.d/nginx status Nginx的配置文件和Supervisor类似，不同的程序可以分别配置，然后被总配置文件include： 123456789101112131415161718192021222324## Nginx的主配置文件地址/etc/nginx/nginx.conf## 新建单独的配置文件## 在conf.d目录下$ sudo vim /etc/nginx/conf.d/helloweb.conf## 然后写入下列内容：server &#123; listen 80; //端口 server_name 192.168.1.144; //访问域名 root /home/tiger/myflack/myproject; access_log /home/tiger/myflask/myproject/logs/nginx_access.log; error_log /home/tiger/myflask/myproject/logs/nginx_error.log; location / &#123; proxy_set_header X-Forward-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; if (!-f $request_filename) &#123; proxy_pass http://127.0.0.1:8000; //这里是flask的gunicorn端口 break; &#125; &#125;&#125; 也可以用下面的最简配置： 12345678910server &#123; listen 80; server_name _; # _表示 localhost root /home/tiger/myflack/myproject; # hello.py 文件所在的目录 location / &#123; proxy_pass http://127.0.0.1:8000; //这里是flask的gunicorn端口 &#125;&#125; 配置完成之后，sudo service nginx restart 重启一下服务。 现在，在浏览器中输入 http://127.0.0.1 即可正常访问。 总结 Flask应用的基本部署依赖包括一个应用容器（比如Gunicorn）和一个反向代理（比如Nginx）。 Gunicorn应该退居Nginx幕后并监听127.0.0.1（内部请求）而非0.0.0.0（外部请求）。 仍有疑问的地方：在虚拟环境下安装的supervisor 并非是全局的，经测试 kill 掉 supervisor 进程后也不会自动重启，或如何随系统启动？该问题待进一步测试 相关链接 virtualenv &mdash; virtualenv 1.7.1.2.post1 documentation GitHub - defshine/flaskblog: Learn python and flask,just a tony blog system Gunicorn - Python WSGI HTTP Server for UNIX 安装 Flask 0.10 documentation Flask + Gunicorn + Nginx 部署 - Ray Liang - 博客园 阿里云ECS上环境搭建(virtualenv+flask+gunicorn+supervisor+nginx) - 菩提本无树 - 博客园 阿里云部署 Flask + WSGI + Nginx 详解 - Ray Liang - 博客园 Supervisor 管理后台守护进程 python web 部署：nginx + gunicorn + supervisor + flask 部署笔记 - 简书 VPS环境搭建详解 (Virtualenv+Gunicorn+Supervisor+Nginx) | BeiYuu.com 基于 Flask 实现 RESTful API | Ross’s Page Ubuntu 14.04 系统基于 Gunicorn 和 Nginx 部署 Flask 应用 | Ross’s Page Flask+Nginx+Gunicorn+Redis+Mysql搭建一个小站 | Alex&#039;s Blog How to Run Flask Applications with Nginx Using Gunicorn &#8211; Onur Güzel * dnsmasq配置域名重定向和dns缓存 | Alex&#039;s Blog 在阿里云CentOS7中配置基于Nginx+Supervisor+Gunicorn的Flask项目 - simpleapples virtualenv 环境下 Django + Nginx + Gunicorn+ Supervisor 搭建 Python Web 部署 | Flask之旅 CentOS 6 下使用 Nginx，Gunicorn 以及 Supervisor 部署 Flask 应用 - 杜顺帆的个人博客 在 Ubuntu 中 Nginx,Gunicorn 部署 Flask | autarch * 阿里云Python+Flask环境搭建]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Flask</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netdata-Linux下性能监视工具]]></title>
    <url>%2F2016%2F05%2F06%2Flinux-performance-monitoring-tool-netdata%2F</url>
    <content type="text"><![CDATA[编译依赖12# Debian/Ubuntu$ sudo apt-get install zlib1g-dev gcc make git autoconf autogen automake pkg-config Install netdata123456# download it - the directory &apos;netdata.git&apos; will be created$ git clone https://github.com/firehol/netdata.git --depth=1cd netdata# build it./netdata-installer.sh 一旦编译安装完毕，netdata 将执行 /usr/sbin/netdata 启动 daemon 程序，并监听本机的 19999 端口。 直接访问：127.0.0.1:19999 即可打开监控界面。 链接 官方安装教程：Installation · firehol/netdata Wiki · GitHub GitHub - firehol/netdata: Real-time performance monitoring, done right! netdata：实时监视 Linux 系统性能]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cURL-命令行下工作的文件传输工具]]></title>
    <url>%2F2016%2F05%2F04%2Flinux-curl%2F</url>
    <content type="text"><![CDATA[cURL是一种命令行工具，作用是发出网络请求，然后得到和提取数据，显示在”标准输出”（stdout）上面。 Linux下安装cURL1$ sudo apt-get install -y curl Windows下安装cURL Windows下默认没有cURL命令，需要安装后才能使用 到网址 curl download 下载curl安装包，我下载的是 curl-7.33.0-win64-ssl-sspi.zip 2013-10-16 04:24 698K 。 解压安装包，只有一个curl.exe文件，在 curl.exe 所在目录下打开 cmd 命令行窗口，就可以直接使用 curl 命令了。 为了让 curl 支持访问 https 的网址，需要下载 OpenSSL ,到 Win32OpenSSL 下载 Win32 OpenSSL v1.0.1t Light 文件。 上面的 2、3、4 步，如果你觉得太麻烦的话，也可以到 cURL - Download 下载 Win64 x86_64 7zip 7.49.0 binary SSL SSH Viktor Szakáts 这一项，下载后压缩包里的bin目录下有三个文件：curl.exe，curl-ca-bundle.crt，libcurl.dll，里面自带了SSL的证书文件。 cURL常用命令整理格式： curl [参数] [URL地址] 参数介绍 缩写 完整命令 示例 释意 -A --user-agent &lt;agent string&gt; demo 指定User-Agent的值 -b --cookie &lt;name=data/file&gt; demo cookie字符串或文件读取位置，使用option来把上次的cookie信息追加到http request里面去 -c --cookie-jar &lt;file name&gt; demo 操作结束后把cookie写入到这个文件中 -C --continue-at &lt;offset&gt; demo 断点续传 -d --data &lt;data&gt; demo HTTP POST方式传送数据 application/x-www-url-encoded -D --dump-header &lt;file&gt; demo 将请求返回的响应信息保存到指定的文件中 -e --referer &lt;URL&gt; demo 指定引用地址，表示从哪里跳转过来的 -E --cert &lt;certificate[:password]&gt; -F --form &lt;name=content&gt; demo HTTP 表单方式提交数据 multipart/form-data -G --get 使用GET方式请求，并将参数拼接在URL的?后面 -H --header &lt;header&gt; demo 指定请求头参数 -I --head demo 仅返回头部信息，使用HEAD请求 -L --location demo 执行重定向操作 3xx --limit-rate &lt;speed&gt; 限制最大传输率 -m --max-time &lt;seconds&gt; 指定处理的最大时长 --max-filesize &lt;bytes&gt; 指定要下载的文件的最大长度，如果超过bytes值，下载并不开始、返回退出码63 -o --output &lt;file&gt; demo 将文件保存为命令行中指定的文件名的文件中 &gt; &gt; 等同于-o,对输出进行转向输出 -O --remote-name demo 使用URL中默认的文件名保存文件到本地 -r --range &lt;range&gt; demo 检索来自HTTP/1.1或FTP服务器字节范围;分块下载 -s --silent demo 减少输出信息,比如进度显示或错误信息 --ssl 使用SSL/TLS方式创建连接请求 -T --upload-file &lt;file&gt; demo 使用PUT方法上传，-T参数指定上传文件 -u --user &lt;user:password&gt; demo 设置服务器的用户和密码 -v --verbose demo 小写的v参数，用于打印更多信息，包括发送的请求信息，这在调试脚本是特别有用 --trace demo 查看更详细的通信过程 --trace-ascii demo 查看更详细的通信过程 -w --write-out &lt;format&gt; demo -x --proxy &lt;[protocol://][user:password@]proxyhost[:port]&gt; demo 指定代理服务器地址和端口，端口默认为1080 -X --request &lt;command&gt; demo 指定GET,HEAD,POST,PUT,DELETE等请求协议 -h --help 使用帮助 -V --version 版本信息 --retry &lt;num&gt; 指定重试次数 示例 -A 指定User-Agent的值 Back To Top1$ curl -A &quot;Mozilla/4.0 (compatible; MSIE 6.0; Windows NT 5.0)&quot; -o page.html http://www.www.baidu.com -b 使用cookie文件(当前目录下的cookie.txt文件) Back To Top 1234// 指定 cookie信息 访问$ curl -b &quot;name=data&quot; http://www.baidu.com// 使用 本地文件中的cookie信息 访问$ curl -b cookie.txt http://www.xxxx.com/api -c 将请求得到的cookie信息保存到本地的 cookie.txt文件中 Back To Top 1$ curl -c cookie.txt http://www.alibaba.com -C 选项可对大文件使用断点续传功能 Back To Top 123456// 当文件在下载完成之前结束该进程$ curl -O http://www.xxx.com/gettext.html// ############# 20.1%// 通过添加-C选项继续对该文件进行下载，已经下载过的文件不会被重新下载$ curl -C -O http://www.xxx.com/gettext.html// ############# 20.1% -d 通过 application/x-www-url-encoded 方式发送POST请求，-d参数以name=value的方式指定参数内容 Back To Top 1234//多个参数用&amp;连接$ curl -d &quot;q=hello&amp;param2=test&quot; http://www.google.com //多个参数分别指定 $ curl -d &quot;action=del&quot; -d &quot;id=12&quot; http://localhost/action.php 注意：-d 后面post 的参数必须用双引号&quot;而不是单引号&#39;括起来，否则会报错 -D 将请求返回的响应信息保存到指定的文件中 Back To Top 1$ curl -D cookie.txt http://www.alibaba.com 注意：-c 仅包含响应头中的cookie信息 -D 包含响应头中的所有响应信息 -e 设置Referer引用地址 Back To Top 1$ curl -e http://localhost http://www.XXXX.com/wp-login.php -F 通过 multipart/form-data 方式发送POST请求，-F参数以name=value的方式指定参数内容；如果值是一个文件，使用name=@file的方式来指定;需要指定上传文件类型时，用type=来指定 Back To Top 123$ curl -F &quot;action=upload&quot; -F &quot;filename=@file.tar.gz&quot; http://localhost/action.php//如果通过代理，上述命令可能会被代理拒绝，需要指定上传文件的MIME类型：$ curl -x proxy.com:8080 -F &quot;action=upload&quot; -F &quot;filename=@file.tar.gz; type=application/octet-stream&quot; http://localhost/action.php -H 指定请求头参数 Back To Top 1$ curl -H &quot;Content-Type:application/json&quot; http://example.com -I 仅返回头部信息，使用HEAD请求 Back To Top 1$ curl -I http://www.baidu.com 注意：使用-I时，接口需要支持Method=HEAD请求，否则会返回405 Method Not Allowed -L 执行重定向操作 Back To Top 1$ curl -L www.baidu.com -o 将文件保存为命令行中指定的文件名的文件中 Back To Top 1234// 将百度首页内容抓到 home.html 中$ curl -o home.html http://baidu.com// 符号`&gt;`和`-o`效果相同$ curl &gt; home.html http://baidu.com -O 使用URL中默认的文件名保存文件到本地 Back To Top 12//将内容保存到 gettext.html 中$ curl -O http://www.xxx.com/gettext.html -r 分段下载 Back To Top 1234//获取前100字节的数据$ curl -r 0-99 http://www.get.this///获取最后500字节的数据$ curl -r -500 http://www.get.this/ -s 减少输出信息 Back To Top 1$ curl -s http://www.get.this/ -T 指定上传文件路径；可以一个-T对应一条Url来表示将一个文件上传到指定的Url;或者同时向一条Url上传多个文件 Back To Top 1234// ftp 上传$ curl -T test.sql ftp://用户名:密码@ip:port/demo/curtain/bbstudy_files///同时上传多个文件$ curl -T &quot;&#123;file1,file2&#125;&quot; http://www.example.com -u 设置服务器的用户和密码 Back To Top 12$ curl -u 用户名:密码 http://www.example.com$ curl -u 用户名:密码 -O http://www.XXXX.com/demo/curtain/bbstudy_files/style.css -v 用于打印更多信息，可以显示一次http通信的整个过程，包括端口连接和http request头信息 Back To Top 1$ curl -v www.baidu.com --trace 查看更详细的通信过程 Back To Top 123$ curl --trace output.txt www.baidu.com//或$ curl --trace-ascii output.txt www.baidu.com -w 获取指定输出内容 Back To Top 1$ curl -m 10 -w &apos;%&#123;http_code&#125;\n&apos; http://wyh.life/ -so /dev/null -x 指定代理服务器地址和端口 Back To Top 1$ curl -u &lt;user&gt;:&lt;passwd&gt; -x &lt;proxy&gt;:&lt;port&gt; http://www.get.this/ -X -X参数可以支持其他动词 Back To Top 12$ curl -X POST www.example.com$ curl -X DELETE www.example.com 相关链接 curl网站开发指南 - 阮一峰的网络日志 CURL常用命令 - 张贺 - 博客园 Curl使用 - 简书 linux curl - 简书 提升开发效率小工具之-curl - 简书 curl命令常用操作 - web开发 - SegmentFault cURL备忘 - 脸滚键盘教™ - SegmentFault Curl使用 · Issue #42 · dongjun111111/blog · GitHub curl - zheng-ji’s Wiki help123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181$ curl --helpUsage: curl [options...] &lt;url&gt;Options: (H) means HTTP/HTTPS only, (F) means FTP only --anyauth Pick &quot;any&quot; authentication method (H) -a, --append Append to target file when uploading (F/SFTP) --basic Use HTTP Basic Authentication (H) --cacert FILE CA certificate to verify peer against (SSL) --capath DIR CA directory to verify peer against (SSL) -E, --cert CERT[:PASSWD] Client certificate file and password (SSL) --cert-status Verify the status of the server certificate (SSL) --cert-type TYPE Certificate file type (DER/PEM/ENG) (SSL) --ciphers LIST SSL ciphers to use (SSL) --compressed Request compressed response (using deflate or gzip) -K, --config FILE Read config from FILE --connect-timeout SECONDS Maximum time allowed for connection -C, --continue-at OFFSET Resumed transfer OFFSET -b, --cookie STRING/FILE Read cookies from STRING/FILE (H) -c, --cookie-jar FILE Write cookies to FILE after operation (H) --create-dirs Create necessary local directory hierarchy --crlf Convert LF to CRLF in upload --crlfile FILE Get a CRL list in PEM format from the given file -d, --data DATA HTTP POST data (H) --data-raw DATA HTTP POST data, &apos;@&apos; allowed (H) --data-ascii DATA HTTP POST ASCII data (H) --data-binary DATA HTTP POST binary data (H) --data-urlencode DATA HTTP POST data url encoded (H) --delegation STRING GSS-API delegation permission --digest Use HTTP Digest Authentication (H) --disable-eprt Inhibit using EPRT or LPRT (F) --disable-epsv Inhibit using EPSV (F) --dns-servers DNS server addrs to use: 1.1.1.1;2.2.2.2 --dns-interface Interface to use for DNS requests --dns-ipv4-addr IPv4 address to use for DNS requests, dot notation --dns-ipv6-addr IPv6 address to use for DNS requests, dot notation -D, --dump-header FILE Write the headers to FILE --egd-file FILE EGD socket path for random data (SSL) --engine ENGINE Crypto engine (use &quot;--engine list&quot; for list) (SSL) -f, --fail Fail silently (no output at all) on HTTP errors (H) --false-start Enable TLS False Start. -F, --form CONTENT Specify HTTP multipart POST data (H) --form-string STRING Specify HTTP multipart POST data (H) --ftp-account DATA Account data string (F) --ftp-alternative-to-user COMMAND String to replace &quot;USER [name]&quot; (F) --ftp-create-dirs Create the remote dirs if not present (F) --ftp-method [MULTICWD/NOCWD/SINGLECWD] Control CWD usage (F) --ftp-pasv Use PASV/EPSV instead of PORT (F) -P, --ftp-port ADR Use PORT with given address instead of PASV (F) --ftp-skip-pasv-ip Skip the IP address for PASV (F) --ftp-pret Send PRET before PASV (for drftpd) (F) --ftp-ssl-ccc Send CCC after authenticating (F) --ftp-ssl-ccc-mode ACTIVE/PASSIVE Set CCC mode (F) --ftp-ssl-control Require SSL/TLS for FTP login, clear for transfer (F) -G, --get Send the -d data with a HTTP GET (H) -g, --globoff Disable URL sequences and ranges using &#123;&#125; and [] -H, --header LINE Pass custom header LINE to server (H) -I, --head Show document info only -h, --help This help text --hostpubmd5 MD5 Hex-encoded MD5 string of the host public key. (SSH) -0, --http1.0 Use HTTP 1.0 (H) --http1.1 Use HTTP 1.1 (H) --http2 Use HTTP 2 (H) --ignore-content-length Ignore the HTTP Content-Length header -i, --include Include protocol headers in the output (H/F) -k, --insecure Allow connections to SSL sites without certs (H) --interface INTERFACE Use network INTERFACE (or address) -4, --ipv4 Resolve name to IPv4 address -6, --ipv6 Resolve name to IPv6 address -j, --junk-session-cookies Ignore session cookies read from file (H) --keepalive-time SECONDS Wait SECONDS between keepalive probes --key KEY Private key file name (SSL/SSH) --key-type TYPE Private key file type (DER/PEM/ENG) (SSL) --krb LEVEL Enable Kerberos with security LEVEL (F) --libcurl FILE Dump libcurl equivalent code of this command line --limit-rate RATE Limit transfer speed to RATE -l, --list-only List only mode (F/POP3) --local-port RANGE Force use of RANGE for local port numbers -L, --location Follow redirects (H) --location-trusted Like &apos;--location&apos;, and send auth to other hosts (H) --login-options OPTIONS Server login options (IMAP, POP3, SMTP) -M, --manual Display the full manual --mail-from FROM Mail from this address (SMTP) --mail-rcpt TO Mail to this/these addresses (SMTP) --mail-auth AUTH Originator address of the original email (SMTP) --max-filesize BYTES Maximum file size to download (H/F) --max-redirs NUM Maximum number of redirects allowed (H) -m, --max-time SECONDS Maximum time allowed for the transfer --metalink Process given URLs as metalink XML file --negotiate Use HTTP Negotiate (SPNEGO) authentication (H) -n, --netrc Must read .netrc for user name and password --netrc-optional Use either .netrc or URL; overrides -n --netrc-file FILE Specify FILE for netrc -:, --next Allows the following URL to use a separate set of options --no-alpn Disable the ALPN TLS extension (H) -N, --no-buffer Disable buffering of the output stream --no-keepalive Disable keepalive use on the connection --no-npn Disable the NPN TLS extension (H) --no-sessionid Disable SSL session-ID reusing (SSL) --noproxy List of hosts which do not use proxy --ntlm Use HTTP NTLM authentication (H) --oauth2-bearer TOKEN OAuth 2 Bearer Token (IMAP, POP3, SMTP) -o, --output FILE Write to FILE instead of stdout --pass PASS Pass phrase for the private key (SSL/SSH) --path-as-is Do not squash .. sequences in URL path --pinnedpubkey FILE/HASHES Public key to verify peer against (SSL) --post301 Do not switch to GET after following a 301 redirect (H) --post302 Do not switch to GET after following a 302 redirect (H) --post303 Do not switch to GET after following a 303 redirect (H) -#, --progress-bar Display transfer progress as a progress bar --proto PROTOCOLS Enable/disable PROTOCOLS --proto-default PROTOCOL Use PROTOCOL for any URL missing a scheme --proto-redir PROTOCOLS Enable/disable PROTOCOLS on redirect -x, --proxy [PROTOCOL://]HOST[:PORT] Use proxy on given port --proxy-anyauth Pick &quot;any&quot; proxy authentication method (H) --proxy-basic Use Basic authentication on the proxy (H) --proxy-digest Use Digest authentication on the proxy (H) --proxy-negotiate Use HTTP Negotiate (SPNEGO) authentication on the proxy (H) --proxy-ntlm Use NTLM authentication on the proxy (H) --proxy-service-name NAME SPNEGO proxy service name --service-name NAME SPNEGO service name -U, --proxy-user USER[:PASSWORD] Proxy user and password --proxy1.0 HOST[:PORT] Use HTTP/1.0 proxy on given port -p, --proxytunnel Operate through a HTTP proxy tunnel (using CONNECT) --pubkey KEY Public key file name (SSH) -Q, --quote CMD Send command(s) to server before transfer (F/SFTP) --random-file FILE File for reading random data from (SSL) -r, --range RANGE Retrieve only the bytes within RANGE --raw Do HTTP &quot;raw&quot;; no transfer decoding (H) -e, --referer Referer URL (H) -J, --remote-header-name Use the header-provided filename (H) -O, --remote-name Write output to a file named as the remote file --remote-name-all Use the remote file name for all URLs -R, --remote-time Set the remote file&apos;s time on the local output -X, --request COMMAND Specify request command to use --resolve HOST:PORT:ADDRESS Force resolve of HOST:PORT to ADDRESS --retry NUM Retry request NUM times if transient problems occur --retry-delay SECONDS Wait SECONDS between retries --retry-max-time SECONDS Retry only within this period --sasl-ir Enable initial response in SASL authentication -S, --show-error Show error. With -s, make curl show errors when they occur -s, --silent Silent mode (don&apos;t output anything) --socks4 HOST[:PORT] SOCKS4 proxy on given host + port --socks4a HOST[:PORT] SOCKS4a proxy on given host + port --socks5 HOST[:PORT] SOCKS5 proxy on given host + port --socks5-hostname HOST[:PORT] SOCKS5 proxy, pass host name to proxy --socks5-gssapi-service NAME SOCKS5 proxy service name for GSS-API --socks5-gssapi-nec Compatibility with NEC SOCKS5 server -Y, --speed-limit RATE Stop transfers below RATE for &apos;speed-time&apos; secs -y, --speed-time SECONDS Trigger &apos;speed-limit&apos; abort after SECONDS (default: 30) --ssl Try SSL/TLS (FTP, IMAP, POP3, SMTP) --ssl-reqd Require SSL/TLS (FTP, IMAP, POP3, SMTP) -2, --sslv2 Use SSLv2 (SSL) -3, --sslv3 Use SSLv3 (SSL) --ssl-allow-beast Allow security flaw to improve interop (SSL) --ssl-no-revoke Disable cert revocation checks (WinSSL) --stderr FILE Where to redirect stderr (use &quot;-&quot; for stdout) --tcp-nodelay Use the TCP_NODELAY option -t, --telnet-option OPT=VAL Set telnet option --tftp-blksize VALUE Set TFTP BLKSIZE option (must be &gt;512) -z, --time-cond TIME Transfer based on a time condition -1, --tlsv1 Use &gt;= TLSv1 (SSL) --tlsv1.0 Use TLSv1.0 (SSL) --tlsv1.1 Use TLSv1.1 (SSL) --tlsv1.2 Use TLSv1.2 (SSL) --trace FILE Write a debug trace to FILE --trace-ascii FILE Like --trace, but without hex output --trace-time Add time stamps to trace/verbose output --tr-encoding Request compressed transfer encoding (H) -T, --upload-file FILE Transfer FILE to destination --url URL URL to work with -B, --use-ascii Use ASCII/text transfer -u, --user USER[:PASSWORD] Server user and password --tlsuser USER TLS username --tlspassword STRING TLS password --tlsauthtype STRING TLS authentication type (default: SRP) --unix-socket FILE Connect through this Unix domain socket -A, --user-agent STRING Send User-Agent STRING to server (H) -v, --verbose Make the operation more talkative -V, --version Show version number and quit -w, --write-out FORMAT Use output FORMAT after completion --xattr Store metadata in extended file attributes -q Disable .curlrc (must be first parameter)]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MVC和WebAPI如何从Filter向Action中传递数据]]></title>
    <url>%2F2016%2F04%2F17%2Ftransfer-data-from-filter-to-action%2F</url>
    <content type="text"><![CDATA[MVC和WebAPI如何从Filter向Action中传递数据 需求最近在策划实现MVC项目中用户身份验证的功能时，考虑用MVC中的Filter过滤器来先从url链接中获取传递过来的token，在Filter中通过token获取用户的信息后，如果用户信息正确，则传递到Controller的Action中进行用户数据的操作。 那么，要如何从Filter中向Action中传递数据呢？ how to pass data from filter to controller? 注意：下面所提到的Filter都指实现ActionFilterAttribute的过滤器 MVC中 从Filter过滤器向Action中传递数据方法一 通过 RouteData 来传值12345//赋值：filterContext.RouteData.Values.Add(&quot;Tname&quot;,UName);//获取： var nm = RouteData.Values[&quot;Tname&quot;]; 测试通过。 详见： ASP.NET MVC Pass object from Custom Action Filter to Action - Stack Overflow 方法二 通过 ActionParameters 来传值另一种方法是通过 ActionParameters 来设置，但在Action中是通过添加参数获取值的： 1234//赋值： filterContext.ActionParameters.Add(&quot;number&quot;, Id);//获取： public ActionResult Index(int number, Person person) 详见： Manipulating Action Method Parameters - You’ve Been Haacked 通过测试，发现这种方法可以隐藏真实的Action方法： 比如：请求的链接是 http://localhost:47760/home/show?id=3&amp;name=abc而实际的Action为： 1public ActionResult Show(string aaa)&#123;&#125; 那么可以通过添加一个 ActionFilterAttribute 过滤器，并设置： 12this.Uname=getquerystring.name;filterContext.ActionParameters[&quot;aaa&quot;] = UName; 这样虽然url中请求的参数时id和name，而实际请求参数是aaa； 而实际的请求链接 http://localhost:47760/home/show?aaa=haha 也是可以访问的。 方法三 通过 HttpContext.Items 来传值1234//Filter中赋值： filterContext.HttpContext.Items[&quot;tname&quot;] = UName+&quot;2324&quot;;//Action中取值： var nm= HttpContext.Items[&quot;tname&quot;]; 测试通过。 通过测试发现好像这种方式比较合适。因为：可看到Items的解释为： 在派生类中重写时，获取一个键/值集合，该集合在 HTTP 请求过程中可以用于在模块与处理程序之间组织和共享数据。 详见： asp.net mvc - Accessing Action Filter&#39;s data in Controller Action - Stack Overflow WebAPI中从Filter向Action中传递数据如何从Filter向Action中传递数据？ 方法一 通过 Request.Properties 来传值1234//Filter中赋值： actionContext.Request.Properties[&quot;id&quot;] =&quot;134&quot;;//Action中获取： var id= Request.Properties[&quot;id&quot;]; 或： 123456//赋值: actionContext.Request.Properties.Add(&quot;mykey&quot;, myObject);//获取： object myObject;Request.Properties.TryGetValue(&quot;mykey&quot;, out myObject);//cast to MyType 测试通过。 详见： asp.net web api - WebApi: how to pass state from filter to controller? - Stack Overflow asp.net web api - Pass an object from ActionFilter.OnActionExecuting() to an ApiController - Stack Overflow 总结MVC 用 : 1filterContext.HttpContext.Items[UnitOfWorkRequestKey] = UnitOfWork; Web API 用 : 1actionContext.Request.Properties[UnitOfWorkRequestKey] = UnitOfWork; 详见： c# - Web API Action Filter - Controller.TempData equivalent? - Stack Overflow]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
        <tag>RestfulApi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Web API中路由中加了action后其他get、post开头的方法如何直接访问]]></title>
    <url>%2F2016%2F04%2F17%2Fwebapi-action-url-extend%2F</url>
    <content type="text"><![CDATA[需求通常我们在访问Web API接口时，默认自带的Action方法为以下这些： 12345public IEnumerable&lt;string&gt; Get()public string Get(int id)public void Post([FromBody]string value)public void Put(int id, [FromBody]string value)public void Delete(int id) 默认的路由表规则为： WebApiConfig.cs文件 12345config.Routes.MapHttpRoute( name: &quot;DefaultApi&quot;, routeTemplate: &quot;api/&#123;controller&#125;/&#123;id&#125;&quot;, defaults: new &#123; id = RouteParameter.Optional &#125;); 匹配的Url为： 动作 HTTP方法 相对路径 获取全部 GET /api/products 指定 id 获取 GET /api/products/id 添加 POST /api/products 更新 PUT /api/products/id 删除 DELETE /api/products/id 特殊需求我们在同一个 Controller 中，有时候可能需要定义多个相同 Method 的 Action 方法，比如： 123public string Get(int id)public string GetList(string name)public string GetPeople(int id) 那么这种情况下，我们就要再添加一个 Route 路由规则，添加一个 {action} 的占位符： 12345 config.Routes.MapHttpRoute( name: &quot;DefaultApiAction&quot;, routeTemplate: &quot;api/&#123;controller&#125;/&#123;action&#125;/&#123;id&#125;&quot;, defaults: new &#123; id = RouteParameter.Optional &#125;); 但这样我们就不能再用之前的那种方式来直接访问默认的Get或Post等方法了，每个Url链接都要加上action名称： 123/api/products/get/api/products/getlist/api/products/post 这样的话我们就觉得反而更麻烦了。 解决方法那是不是有一种什么样的方法能让我们在添加多个相同类型的请求方法时，既能直接访问默认的方法，又能通过添加action名称来访问自定义添加的方法呢？ 其实，我们只要修改路由规则如下即可： 1234567891011121314151617181920using System.Net.Http;using System.Web.Http.Routing; //可用的路由表 config.Routes.MapHttpRoute(&quot;DefaultApiWithId&quot;, &quot;api/&#123;controller&#125;/&#123;id&#125;&quot;, new &#123; id = RouteParameter.Optional &#125;, new &#123; id = @&quot;\d+&quot; &#125;); config.Routes.MapHttpRoute(&quot;DefaultApiWithAction&quot;, &quot;api/&#123;controller&#125;/&#123;action&#125;&quot;); config.Routes.MapHttpRoute(&quot;DefaultApiGet&quot;, &quot;Api/&#123;controller&#125;&quot;, new &#123; action = &quot;Get&quot; &#125;, new &#123; httpMethod = new HttpMethodConstraint(HttpMethod.Get) &#125;); config.Routes.MapHttpRoute(&quot;DefaultApiPost&quot;, &quot;Api/&#123;controller&#125;&quot;, new &#123; action = &quot;Post&quot; &#125;, new &#123; httpMethod = new HttpMethodConstraint(HttpMethod.Post) &#125;); 详细说明见：wcf web api - Single controller with multiple GET methods in ASP.NET Web API - Stack Overflow 再啰嗦一句如果同一种请求方式下，有多个同类型的方法，会请求默认状态下的那个：比如 get方法： 12public string Get()public string GetTop() 如果请求：http://localhost:47760/api/product则访问到的是Get()方法，即使在顺序上GetTop()排在Get()方法前面。]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>ASP.NET</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下的计划任务-Crontab]]></title>
    <url>%2F2016%2F03%2F28%2Fthe-plan-task-in-linux-cronlib%2F</url>
    <content type="text"><![CDATA[Crontab 用于设置周期性被执行的任务的工具 检查cron服务检查crontab工具是否安装 1$ crontab -l 检查crond服务是启动 1$service crond status 注意: 在Ubuntu系统下,查看crontab服务是: service cron status 安装cron12$ sudo apt-get install vixie-cron$ sudo apt-get install crontabs 如果在输入crontab -l之后,提示”no crontab for root“的信息,则说明系统中没有设置crontab,需要先进行设置. crontab是一个文本文件，用来存放你要运行的命令。 执行命令crontab -e,会提示:1234no crontab for root - using an empty oneSelect an editor. ......... 这样的提示,然后选择一个编辑器(这里我选 vim:tiny)即可.然后会进入crontab编辑页面,在编辑页面中直接输入shift+:,然后输入wq保存,一个新的crontab就生成了.然后再执行crontab -l 就能看到刚刚编辑过的crontab文件了. 参考:Linux提示no crontab for root的解决办法Ubuntu下crontab命令的用法 实例执行crontab -e打开crontab文件 写入以下命令: 1*/1 * * * * date &gt;&gt; /tmp/log.txt 表示:每分钟将当前时间写入到tmp目录下的log.txt文件中 查看log.txt文件,执行命令: 1$ tail -f /tmp/log.txt 表示查看log.txt文件的最后几行 查看crontab服务运行状态: 1$ service cron status crontab 配置文件的格式1* * * * * COMMAND 1* 分钟 0~59 2* 小时 0~23 3* 日期 1~31 4* 月份 1~12 5* 星期 1-7 (0或者7表示星期天) 案例 每晚 21:30重启apache 130 21 * * * service httpd restart 每月 1 10 22日的4:45重启apache 145 4 1,10,22 * * service httpd restart 每月1到10日的4:45重启apache 145 4 1-10 * * service httpd restart 用-表示间隔 每隔2分钟重启Apache服务 12*/2 * * * * service httpd restart //偶数分钟内1-59/2 * * * * service httpd restart //奇数分钟内 晚上11点到早上7点之间,每隔一小时重启apache 10 23-7/1 * * * * service httpd retart 每天18点到23点之间每隔30分钟重启apache 120-59/30 18-23 * * * service httpd restart0,30 18-23 * * * service httpd restart 总结 * 表示任何时间都匹配 可以用 A,B,C 表示A或者B或者C时执行命令 可以用 A-B 表示A到B之间时执行命令 可以用 */A 表示每A分钟(小时等)执行一次命令 注意 第三和第五个域之间是”或”的关系:四月的第一个星期天早晨1时59分运行a.sh159 1 1-7 4 * test `date + \%w` -eq &amp;&amp; /root/a.sh Crontab格式 minute hour day month week command 其中： minute：表示分钟，可以是从0到59之间的任何整数。 hour：表示小时，可以是从0到23之间的任何整数。 day：表示日期，可以是从1到31之间的任何整数。 month：表示月份，可以是从1到12之间的任何整数。 week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符： 星号（*）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如*/10，如果用在minute字段，表示每十分钟执行一次。 Crontab定时调用Python脚本 指定python脚本文件中的头信息 #!/bin/sh 相关链接 每天一个linux命令（50）：crontab命令 - peida - 博客园 crontab命令_Linux crontab 命令用法详解：提交和管理用户的需要周期性执行的任务 crontab 中 python 脚本执行失败的解决方法 | CoCo的小黑屋]]></content>
      <categories>
        <category>开发笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Crontab</tag>
      </tags>
  </entry>
</search>
